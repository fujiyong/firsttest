我的google账号  fujiyong2000@gmail.com  yaxin


WIFI 13622228504
ftp \\192.168.1.182     user:user
git fu_ji_yong fujy6789
bug fu_ji_yong pass@2019

google youtube  fujiyong2000@gmail.com  sr


测试机	121.9.227.91	22124	root	pass@2019
数据库	192.168.1.102	5432	postgres	pass@2018
ipfs1	192.168.1.106	22	root	13622228504
ipfs2	192.168.1.178	22	root	13622228504
ipfs3	192.168.1.127	22	root	13622228504
以太坊1	120.79.97.248	22	root	SuperVDS*2020@2805
以太坊2	120.78.173.134	22	root	Svdsdev2019*$()
以太坊3	39.108.104.133	22	root	Svdsdev2019*$()
测试机  192.168.1.128  root/orangepi  orangepi  

git clone http://fu_ji_yong:fujy6789@git.isecsp.com/frank/ocelot-api-gateway.git

zsh操作指南
http://www.skywind.me/blog/archives/2060

S*vds%%2020*()02191848$



alias | grep -E "b\."
echo $DIFOSS_ENV_BASE/.privacy/__init__.sh
b.privacy


https://www.npmjs.com/package/windows-build-tools  npm安装windows编译工具

linux命令  column -t
            for i in 0 1 2 3 4 5 6 7 8 9; do iostat | column -t; sleep 1; done
            for i in {0..9} ; do iostat 1 1 | column -t; sleep 1; done
            vmstat 1 10 | while read line
            do
                echo "$line" | column -t
            done

            在终端直接执行在a.sh中定义的函数say():  chmod +x a.sh && source a.sh && say
            last     最后登录信息,每个用户可以多行
            lastlog  最后各个用户的登录信息,每个登录用户一行

软件 web        hbuilder 
     数据库客   dbeave  pgadmin
     cmder     设置分屏
     markdonw  typora
     截图       snipaste

     nodejs进程管理  pm2  process manager

     mac      dash参考文档


https://www.cnblogs.com/the-tops/p/7600985.html
知识点
    git fetch --all  //所有分支
    确定自己所在分支 git pull origin master && git log -p -1   //-p 以patch方式  
    git shortlog
    git log 
            --stat 
            -p


             符号位     指数位     尾数位
    float    1          8         23
    double   1          11        52

    mkdir -pv a/b/c
    realpath $file
    ssh user@hostname/ip

    在命令行上参数上有些--符号,表示--跟在--之后的就不再是不确定参数,即参数不再是变量,而是确定量
    --             indicates the unambiguous end of options    #man awk 

    vi  set cursorline
        set cursorcolumn   https://github.com/nathanaelkane/vim-indent-guides





mist 以太坊节点/钱包
metamask chrome插件方式的以太坊节点、钱包， 可以连接到本地或实际的
truffle  以太坊开发框架，内置了只能合约的编译 链接 部署
remix   智能合约开发环境
whisper 集成进以太坊的非实时消息系统

ganache 在公链上测试部署dapp或只能合约需要消耗gas， 使用ganache可以创建本地区块链


npm install -g truffle  && truffle --version 


git clone http://fu_ji_yong:fujy6789@git.isecsp.com/frank/ocelot-api-gateway.git



npm
    npm init
    npm adduser && npm publish

    npm install [-g] $pkg@tag/version
    npm uninstall $pkg
    npm update [-g] $pkg
    npm search $pkg

    npm list -g  //查看安装的全局包的版本
    npm list $pkg //查看某个包的版本

    npm cache clear 清空本地缓存，用于使用相同的版本号发布

    npm unpublish $pkg@version 取消某版本的发布

    npm install -g cnpm --registry=https://registry.npm.taobao.org //淘宝的npm镜像

    npm run 可以查看package.json里有哪些可以通过npm run start|stop|test|dev|debug等命令

nodejs
    创建工程 cd projDir && npm init 会产生package.json文件
    添加依赖库  在package.json中的dependencies中添加 然后npm install 就可
    启动程序
        命令行 node --use_strict a.js  //让node为所有的js开启strict模式  这也是vscode launch.json文件中的配置
        命令行 npm start               //在package.json中配置"scripts": {"start": "node app.js"}

a.js
    // @ts-check 或者在jsconfig.json中添加{"compilerOptions": {"checkJs": true},"exclude": ["node_modules"]}
    //npm i @types/第三方库名  //为第三方库安装类型声明文件.d.ts

    数据类型
        bool    0 NaN null undefined
        Number  NaN  isNaN(NaN)
        string  多行时``  +  模板字符串`${x}`                    length  下标引用[0]/substring()      indexOf(str)

        array  [] new Array()  元素类型可以不同, 可以越组访问/赋值 length  下标引用[0]/slice([s[,e])    indexOf(ele)  push(...)/pop unshift(...)/shift() sort() reverse() concat(...,[1,2]) join('-') splice(s,e[,ele...])
        map       new map([[k1,v1],[k2,v2]]) has(k) get(k) set(k,v) delete(k)
        set       new set([v1,v2])                         add(v1)  delete(v1)

        Object  访问/赋值/新增o.field  删除delete o.field   判断field in o o.hasOwnProperty('field')

        null
        undefined

    运算符
        == ===
        if()else if(){}else{} for(;;)  while(){}  do{}whle()

        for(var i in arr){} //获取数组的索引i
        for(var f in o){} //获取所有属性f

    iterable  
        ES5.1
            forEach(function(ele, index, x){
                //arr ele index arr
                //set ele ele   set
                //map v   k     m
            })

        ES6
            for(var v of arr){}
            for(var kv of map){kv[0] kv[1]}
            for(var v of set){}

    解构赋值ES6
        数组
            let [x, [y, z]] = ['hello', ['JavaScript', 'ES6']]
            let [, , z] = ['hello', 'JavaScript', 'ES6']
        对象
            var person = {
                name: '小明',
                age: 20,
                gender: 'male',
                passport: 'G-12345678',
                school: 'No.4 middle school',
                address: {
                    city: 'Beijing',
                    street: 'No.1 Road',
                    zipcode: '100001'
                }
            };
            var {name, age, passport, single=true} = person //single有默认值true
            var {name, address: {city, zip}} = person;//address不是变量，而是为了让city和zip获得嵌套的address对象的属性
            let {name, passport:id} = person;// 注意: passport不是变量，而是为了让变量id获得passport属性:

    Function
        不定参数关键字arguments,rest
            function foo(a, b, ...rest){ //ES6引入了rest，表示其余的参数数组，当少参数时数组为null
                console.log(arguments.length) 
            }

        apply/call
            function.apply(obj, []) //obj为function中this的指向， 第二个参数为function的入参数组
            function.call(obj,...) //obj为function中this的指向， 第二个参数为function的入参数组的顺序传入

        高阶函数Hight-Order function： 函数的形参可以接受一个参数指针
            arr.Map(x=>{return x*1})           //对数组对象arr中的每个元素都调用箭头函数并返回新数组
            arr.reduce((x,y)=>{return x + y})
            arr.filter(function(ele){return true;}); //返回为true的
            arr.filger(function(ele, index, self){return self.indexOf(ele) === index;}) //数组去重
            arr.sort(function(x,y){if(x>y){return 1}else if(x<y){return -1}else{return 0;}}) //默认将ele转化为字符串按ascii排序
            arr.every(function(x){return x>1;}) //是否都>1
            arr.find(function(x){return x>1;})  //查询是否有大于1的元素并返回元素
            arr.findIndex(function(x){return x>1;}) //查询是否有大于1的元素并返回元素索引
            arr.forEach(console.log)
    异常
        try{

        }catch(e){
            console.log(e)
            throw new error("my err")
        }finally{

        }

    闭包

    产生器
        function* f(){yield x; return}
        var gen = f(5)  //产生一个generator
        gen.next()      //返回一个对象{value:x, done:true/false} x就是yield产生的 或 return返回的；  当是return直接返回时是value是undefined
        for (var x of f(5))

    标准对象
        Date  new Date()  Date.now()
        Json  Json.stringify(o,["f1", "f2"], '\t')  JSON.stringify(o, (k,v){}, '\t')  JSON.stringify(o)//优先调用o的toJson()成员函数
              JSON.Parse(o,(k,v){return v})
        RegExp

    面向对象
        var xiaoming = {}  xiaoming.__proto__ = Student  //xiaoming继承了Student

        var xiaoming = Object.create(Student)//根据Student原型创建对象 xiaoming有Student所有属性但为null  xiaoming.__proto__ === Student

        function Student(props){
            this.name = props.name
            this.grade = props.grade
            this.hello = function(){}  //每个对象都有一个hello函数
        }
        Stdent.prototype.hello = function(){} //在prototype中定义，则所有对象共享一个hello函数
        var xiaoming = new Student() //使用函数必须new默认返回this，否则返回undefined

        class ES6 需要Babel工具从class转换为prototype
            Class Base{
                constructor(name){
                    this.name = name
                }

                hello(){   //没有function
                    console.log(this.name)
                }

                this.byebye = function(){}
            }
            class Derived extends Base{
                constructor(name, age){
                    super(name)
                    this.grade = grade
                }

                myGrade(){}
            }
    








    作用域
        全局
            //在 HTML 中, 全局作用域是针对 window 对象
            //在 JavaScript 中, 全局作用域是针对 JavaScript 环境
            var x = 10    //使用 var 关键字声明的全局作用域变量属于 window 对象, 可以使用 window.carName 访问变量
            let x1 = 20   //使用 let 关键字声明的全局作用域变量不属于 window 对象, 不能使用 window.carName 访问变量
            {
                var x2 = 100 //不在函数体内，即使在{}内var修饰的仍然是全局变量
            }
            function foo(){
                y = 20       //函数体内没有var的一定是全局变量
            }
        块局
            {
                let x = 10
            }
            funtion foo(){
                var z = 1   //函数体内有var修饰的是局部变量
            }

    变量重置


    变量提升
        var可以  let不行



    


新建工程
    新建目录，切换到目录然后npm init, 产生package.json文件
引用
    引用具体的文件b.js中的export
        //export module.exports = {f1, f2}

        // var b = require("./b/b.js")
        // b.f1()
        // b.f2()

        module.exports = {
            k : require("./b.js")
        }

        var x = require("./b")
        x.k.f1()
        x.k.f2()
引用第三方库
    安装npm install -g date-fmt
调试
    点击最左边的调试，然后右边的setting，在编辑器上方弹出的地方选择node.js，然后产生launch.json文件，在里面的"program": "${workspaceFolder}\\a.js"，
    在具体的文件里行号左边点击添加断点





全屏  F11
sidebar ctrl+b
move up/down  alt+up/down

copy up/down  alt+shit+up/down
format        alt+shift+F




move line up/down       alt+shift+up/down
move statement up/down  ctrl+shift+up/down


浏览器  ctrl+shift+B



:%s/^\([A-Z]\)/#\1/g


https://www.ibm.com/developerworks/cn/linux/l-lpic1-v3-102-5/index.html
https://segmentfault.com/a/1190000011200461



/root/anaconda-ks.cfg
initial-setup-ks.cfg
original-ks.cfg        [anəˈkändə]  水蟒  kickstart 启动


查看文件系统类型
    cat /etc/fstab

    lsblk -f               #显示块设备
    blkid /dev/sda3        #打印查找块设备属性
    
    df -T -h               #只显示已挂载的,不显示未挂载的
    file -sL /dev/sda3    #标识文件类型 -s标志启用读取块或字符文件， -L启用以下符号链接

    parted && print list   #parted分区软件
    fsck -N /dev/sdb1      #打印和检查fs
    mount  | grep ^/dev

resize2fs更改文件系统的大小


ag advanced grep
fzf  
mycli             #mysql彩色客户端
shellchekc  a.sh  #检查shell语法

axel -n 20 $addr    多线程下载
lynx  --dump http://www.baidu.com  终端浏览器
tig git https://www.jianshu.com/p/e4ca3030a9d5
multitail
script/scriptreplay  终端会话录制并回放
top htop glances

zeal  dash
everything listary
Mockoon
chocolatey homebrew  babun


https://blog.csdn.net/u010625000/article/details/44455023


ag
    安装
        apt search silver
        apt search silver | grep search
        apt insall silversearcher-ag


fzf  fuzzy find 模糊查询 媲美vim的CtrlP插件
    安装
        apt install fzf 

        git clone --depth 1 https://github.com/junegunn/fzf.git ~/.fzf
        cd ~/.fzf && git pull && ./install

    使用
        keybinding bash zsh fish
            Ctrl-T  查找粘贴目录下的文件名或目录名到命令行
                vi Ctrl-T
                cd Ctrl-T
            Ctrl-R  查找粘贴选中的历史命令到命令行
                Ctrl-R  再按一次则在时间和相关性之间排序历史命令
            Ctrl-c  切换目录 == cd  + Ctrl-T
        autocomplete bash zsh
            kill -9/15 <tab>  然后tab或shift-Table选中

            vi $path/**<Tab>   vim $(fzf)
            cd $path/**<Tab>   cd $(find * -type d | fzf) 

            ssh **<tab>
            telnet **<tab>

            unset **<TAB>
            export **<TAB>
            unalias **<TAB>

        git分支
	        git checkout $(git branch -r | fzf)

        预览窗口  fzf --preview 'cat {}'

    快捷键 在输出交换窗口
        键盘 Ctrl-j/k/n/p   单选模式Enter选中     多选模式-m下Tab和shift-Table选中
        鼠标 滚轮滚动        单选模式双击选中      多选模式-m下Shift-Click或shift-scroll多选









apt install alien #可以在rpm dpkg deb之间转换
alien *.rpm
alien -r *.deb

*.rpm
*.src.rpm  包含未编译的原始代码,所以可以修改编译参数经过编译后才可以安装
            rpmbuild --rebuild    *.rpm   #build binary package from <source package>
            rpmbuild --recompile  *.rpm   #build through %install (%prep, %build, then install) from <source package> 

rpm格式
    Lead    公共
    signature
    header  软件包信息
    archive 文件列表

rpm -qil rpmdevtools

rpmdev-setuptree                        #与rpmdev-wipetree刚好相反
rpmdev-newspec -type python -o a.spec   #rpmdev-newspec --help 模板来自于/etc/rpmdevtools/spectemplate-*.spec 
rpmlint a.spec  &&  rpmlint -i a.spec   #检查spec语法错误    rpmbuild -E '%{_bindir}' tos.spec
rpmdev-newinit                 a.init   #制作服务控制脚本

目录结构
    SOURCES  *.tar.gz
    SPECS    *.spec

    BUILD               #config make
    BUILDROOT           #make install 产生x86_64

    RPMS    *.rpm       #将BUILDROOT打包
    SRPMS   *.src.rpm   #将BUILDROOT打包

rpmbuild
    常用选项
        --dbpath  ""             #默认值/var/lib/rpm
        --root    ""             #根目录

    编译前
        --nobuild                 #检出spec语法

    编译选项
        -bp %prep                 #解压缩并patch
        -bc       %build          #make
        -bi              %install #install 

        -bb                       #install之后只生成rpm          build binary package only from <specfile>        rpm
        -bs                       #           只生成src.rpm   
        -ba                       #                             build source and binary packages from <specfile> rpm src.rpm

        --buildroot ""
        --target i386 | i686 | x86_64
        --rmsource                #在build之后删除src.rpm 
        --rmspec                  #在build之后删除spec文件

    编译后
        --clean                  #删除build时的目录 BUILD/wget-1.14


spec
    定义变量  %define varname "xxx"
    引用变量  %{var}
    执行脚本  %( echo %{var} | sed 's///g' )
    定义宏    %global date 2012-02-08

    各种宏   cat /usr/lib/rpm/macros


    comments
    tags 变量定义
        包命名
            Name               不能含空格
            Version            不能含-
            Release
        描述  rpm -qpi *.rpm
            %description:      若以空格开始则逐字显示; 若不是以空格开始则对其段落划分 在变量定义中唯一个以%开头的变量
            Summary:  只能一行
            CopyRight: GPL 
            Lisence:  GPLv2 with exceptions
            Distribution:    软件集合
            Icon:            软件图标
            Vendor:          组织机构
            URL: 
            Group:
            Packager:    发包人的联系方式或公共的邮件列表
        依赖 rpm -qpi  --requires
            Provides     该包提供什么资源  既可以是一个真实存在的包,也可以只是一个虚拟的东西(仅仅是一个字符串)
            Requires     该包依赖哪些包 不支持不等于
                         = 1.2-2  >= > = <= < 
            conficts     该包与哪些包冲突
            serial       version之外的另外一种版本比较变量
            autoreqprov  自动生成软件依赖的标志位autorequire/autoprovide 取值为yes或者no,也可用0或1表示 默认值为yes或1 一般不用操作
        平台操作系统
            ExcludeArch: sparc alpha   不能在某CPU平台
            ExclusiveArch: aparc alpha 只能在某CPU平台
            ExcludeOS:  linux irix     不能在某OS
            ExclusiveOS: linux irix    只能在某OS
        目录
            prefix:  /opt  %files中声明为/opt/xx 在命令行的--prefix的优先级最高
            BuildRoot:  %{_topdir}/%{name}-%{version}-root 
        源码补丁
            Source:    源代码名称和存储位置
                Source:      #Source与Source0效果相同
                Source1:
                SourceN:
            NoSource:  从源代码中忽略一个或多个文件
            Patch:     标识源码的一个补丁文件
                Patch0:
                PatchN:
            NoPatch:   忽略一个或多个补丁
    script
        编译时
            %prep   为编译代码准备 1创建顶级目录 2解压源码到build目录 3如果有补丁的话打补丁

            %build   #####最多进行到configure && make 绝对不可能make install
            %ifarch cond1 cond2
                ./configure --with-ss=openssl
            %ifnarch cond1 cond2
            %ifos os1 os2 
            %ifnos os1 os2
                make RPM_OPT_FLAGS="$RPM_OPT_FLAGS -I . "
            %else
            %endif  

            %install  ####这儿才可以make install
            if [-d %{buildroot}]; then
                rm -rf %{buildroot}                              ← 清空下安装目录，实际会自动清除
            fi
            %{__install} -Dp -m0755 contrib/init.d %{buildroot}%{_initrddir}/foobar          
            make install prefix=$RPM_BUILD_ROOT/usr
            %{__install} -d %{buildroot}%{_sysconfdir}/foobar.d/   #对make install的目录结构进行修正,务必修正好 这样在%files可以直接打包

            %clean 
            [ "$RPM_BUILD_ROOT" != "/" ] && rm -rf $RPM_BUILD_ROOT
        安装到文件系统前/从文件系统卸载时
            %pre     第一个参数为1说明是初次安装,为2时是版本升级  hook默认使用bash来执行,但也可使用参数-p自定义
                %pre -p /usr/bin/perl 
                if ( $ARGV[0] == 1 ) {
                    print "preparing for init install\n"
                }
                elsif ( $ARGV[0] == 2 ) {
                    print "prepare to upgrade software\n"
                }
                添加group/user
            %post    第一个参数为1说明是初次安装,为2时是版本升级
                systemctl reload nginx.service
            %preun   第一个参数为0说明是卸载,为1时是版本升级
            %postun  第一个参数为0说明是卸载,为1时是版本升级

            升级流程
                执行新版本的%pre 
                安装新版的文件列表
                执行新版本的%post

                检查所有其他rpm包的triggerin触发器,如果有被N的安装触发,就执行相应脚本
                执行N的所有triggerin触发器
                执行N的所有triggerun触发器

                检查所有其他rpm包的triggerin触发器,如果有被N的卸载触发的,就执行相应的脚本

                执行老版本的%preun
                自动删除老版本中没有被新版本覆盖的文件
                执行老版本的%postun
        校验时          用rpm命令校验已安装的rpm时执行 rpm -qpVv *.rpm
            %verifyscipt  因为rpm默认会校验文件列表,所以不用去校验,因此这儿可以做点自己想做的 默认不会执行%verifyscipt,除非使用verbose模式进行校验
            echo "verify aaa" 
        触发器Trigger   被一定的条件(如其他rpm安装或卸载)触发执行
            B%triggerin A包安装时,如果B包已经安装,则触发该触发器
            B%triggerun A包安装时,如果B包已经卸载,则触发该触发器
            B%triggerpostun A包安装时,如果B包被卸载,则卸载完成后触发该触发器

            eg:
                %triggerin -p /usr/bin/perl -- ruby   #通过--符号指定被监控的包
                # print "ruby already installed"
    Macro 宏
        %setup      解压缩源码  多数情况下不用任何选项
            -n $name 设置编译目录名默认是name-version
            -c $build_dir_name  创建build目录并进入该目录
        %patch      给解压后的源码打补丁
    files 文件列表指令Directives 设置与检查文件/目录/软件包的属性 rpm -qf /etc/x.conf
        文件相关
            %doc    用来标识一个文件是文档 安装后会被rpm数据库记录 默认安装目录是/usr/doc 可以通过修改rpmrc中的defaultdocdir变量的值来修改
            %config 用来标识一个文件是配置文件 设置了noplace属性后 rpm在升级时就不会被覆盖 在卸载时会被保存为x.save  rpm -qp *.rpm --configfiles
                %config(noreplace) /etc/x.conf
            %attr   用来修改文件属性(默认权限 属主 属组)指令
                %attr (755, root, root) foo.bar
            %verify 校验指令
        目录相关
            %docdir /absolute-dir-path  用于指定配置文件目录
            %dir    /absolute-dir-path  用于只将目录打包  默认将目录下的文件及文件夹打包

        %package -n $new_sub_package_name 定义子包名,默认命名是"基础包-子包"格式

        eg
            %files                   ######## 对%install中的目录进行摘选
            %defattr (-,root,root,0755)                         ← 设定默认权限
            %attr(755, root, root) %{_sbindir}/mysqld
            %config(noreplace) /etc/my.cnf                      ← 表明是配置文件，noplace表示替换文件
            %attr(644, root, root) %{_mandir}/man8/mysqld.8*    ← 分别是权限，属主，属组
            %doc %{src_dir}/Docs/ChangeLog                      ← 表明这个是文档



全局配置      /etc/yum.conf                设置如何管理源repo
源配置文件    /etc/yum.repos.d/*.repo      源的配置文件
本地rpm数据库 /var/lib/rpm/_db.*           存储系统已安装了哪些rpm   /var/lib/yum
本地缓存      /var/cache/yum/*             存储索引文件和rpm文件
插件          /usr/lib/yum-plugins/fastestmirror.py       fastestmirror对每个mirror进行测速,然后根据连接速度排序站点速度,选择下载速度最快的站点下载
插件配置文件   /etc/yum/pluginconf.d/fastestmirror.conf
日志          /var/log/yum.log 


rpmbuild -ba main.spec 
yum install *.rpm 
rpm -ql main 
rpm -qi main 


cd BUILD
tar -zxvf $Source.tar.gz      #$Source来自*.spec中的Source
%build                        #执行spec中的%build
rm -rf   $Name-$Version &&    #Name和Version来自*.spec 
mkdir -p $Name-$Version 
%install                      #执行spec中的%install
打包


索引读写分离
缓存
镜像
智能DNS和多机房容灾


/root/anaconda-ks.cfg
initial-setup-ks.cfg
original-ks.cfg        [anəˈkändə]  水蟒  kickstart 启动


查看文件系统类型
    lsblk -f               #显示块设备
    cat /etc/fstab
    df -T -h               #只显示已挂载的,不显示未挂载的
    parted && print list   #parted分区软件
    fsck -N /dev/sdb1      #打印和检查fs
    blkid /dev/sda3        #打印查找块设备属性
    mount  | grep ^/dev
    file -sL /dev/sda3    #标识文件类型 -s标志启用读取块或字符文件， -L启用以下符号链接

    fdisk -l 只能列出硬盘的分区表、容量大小以及分区类型，但看不到文件系统类型


cal [[[day] month] year]

tmux 配置管理工具oh my tmux  set -g mouse off改为on
ag advanced grep
fzf  vim $(fzf)        fuzzy finder
	 cd $(find * -type d | fzf) 
	 git checkout $(git branch -r | fzf)
shellchekc  a.sh  检查shell语法
mycli mysql彩色客户端
axel -n 20 $addr    多线程下载
tig git https://www.jianshu.com/p/e4ca3030a9d5
multitail
script/scriptreplay  终端会话录制并回放
top htop glances atop
lynx  elinks 终端浏览器
tldr  too long don't read  #查看命令常用语法     https://www.yangxingzhen.com/
busybox top --help         #查看命令简短说明
man中文参考手册
cmder 
zeal/dash 帮助手册
cloc 统计代码

keepalived 高可用的保证工作在347层
Layer3： 发送ICMP报文，查看ip是否能ping通
Layer4： 查看端口port是否能telnet通
Layer：  根据用户自定义的协议检查是否正常  

haproxy 重点在proxy









https://blog.csdn.net/u010625000/article/details/44455023


全部摘抄 http://www.berlinix.com/gdb.html
http://www.docin.com/p-245963860.html
https://developer.apple.com/library/mac/#documentation/DeveloperTools/gdb/gdb/gdb_9.html  
http://www.douban.com/note/65837435/

gdb的配置文件是.gdbinit.就如vi的.vimrc.

break       b
delete      d
disassemble disas
info        i
registers   r
只有break和watch命令支持if，catch目前暂不支持if.


0、写在前头
产生core：              
                            limit -c                             #查看
                            limit -c unlimited/1024*1024*1024    #设置，防止消耗内存大的进程产生过大的coredump
配置     
                            kernel.core_pattern=/var/core/%t-%e-%p-%c.core   #cat /etc/sysctl.conf
                            kernel.core_uses_pid=0                           #若为1，即在core文件后加上pid，但上面我们已经加上了pid了
                            sysctl -p
编译                    <Esc>:make {arguments}  #编译代码
                           <Esc>:gr[ep] main *.c     #
遍历编译错误             http://man.chinaunix.net/newsoft/vi/doc/help.html 查找    quickfix.txt文档    
                            http://man.chinaunix.net/newsoft/vi/doc/usr_30.html#usr_30.txt
                           <Esc>:cl[ist]                          #只有那些含有文件名或行数的错误信息才会被显示。vim假定你对其他信息不感兴趣
                           <Esc>:c[list]! [from][,[to]]           #查看所有的make的信息,只需在上述命令上加！
                           <Esc>:cfir[st]                         #将光标移动到第一个错误
                           <Esc>:cl[ast]                          #将光标移动到最后一个错误
                           <Esc>:cp[revious]                      #将光标移动到上一个错误
                           <Esc>:cN[ext]                          #将光标移动到下一个错误所在的行
			       <Esc>:cc                              #有时空间不够，vim会缩短出错信息。如果想查看详细信息
                           <Esc>:cc 3                             #将光标移动到第三个错误
                           <Esc>:cope[n] [height]                 #打开一个窗口显示当前的错误列表.默认为10行高。一般位于底端。如果有垂直分割，会位于最右边窗口的最下边。
                           <Esc>:ccl[ose]                         #关闭quickfix窗口
                           <Esc>:cw[indow] [height]               #当存在可以识别的错误时，打开此窗口。如果该窗口已经打开且没有可以识别的错误，则将此窗口关闭

1、启动调试
gdb ./prog                                  #debug from start
gdb ./prog pid                              #debug running prog
gdb ./prog core                             #debug core file

server：gdbserver host:port --attatch PID
        gdbserver clientIP:serverPort Prog
client：gdb Prog
        (gdb)target remote serverIP:serverport
        (gdb)list/break
        (gdb)continue/c                    #不能run因为Prog已经在server上run了
        (gdb)以后如常

2、gdb shell 命令
宏
(gdb)info macro macro-name
(gdb)macro expand macro-name                #展开宏         http://blog.chinaunix.net/space.php?uid=23629988&do=blog&id=3053595
                                                            默认级别是-g2，简称-g,此时不能expand macro，需要-g3,产生更多的调试信息
                                                            对于单个文件，可以采取预编译 g++ -E test.c > test.e，查看宏定义，include文件
加载
(gdb)file [/path/to/]$(prog)                #加载prog符号文件即加载应用程序
(gdb)info files
(gdb)set args $(argv[1]) $(argv[2])         #设置应用程序参数    
(gdb)show args
(gdb)info args
(gdb)path <dir>                             #程序的运行路径
(gdb)show path                              #查看程序的运行路径
(gdb)set environment varname[=value]        #设置环境变量
(gdb)show environment [varname]             #查看环境变量

源代码   
编译的时候一定要加上-g参数，表示将源代码编译到执行文件，否则看不到路径和源代码
编译-g的时候，只包括了源代码的文件名，没有提供源代码的路径
总结：-g 表示将源代码编译到可执行文件，但看不了源代码，只能看到文件名，所以这时必须提供源代码路径
     但由于一般在调试的情况下有2个预制变量$cdir:$cwd，其中cwd表示当前路径，cdir表示compilation dir
       而由于一般调试在源码目录下，此时cwd就表示源码目录
       当将即使以-g编译的exe拷贝到别的机器，由于cwd没有源码，所以必须拷贝源码过去，且设置directory
Add directory DIR to beginning of search path for source files.  
Forget cached info on source file locations and line positions.  
DIR can also be $cwd for the current working directory, or $cdir for the  
directory in which the source file was compiled into object code.  
With no argument, reset the search path to $cdir:$cwd, the default.
(gdb)show directories                        #源代码搜索路径
(gdb)directory /path/to/src_dir1:/path/to/src_dir2 # http://coolshell.cn/articles/3643.html
     或分成多步directory /path/to/src_dir1          # https://sourceware.org/gdb/onlinedocs/gdb/Source-Path.html
       directory /path/to/src_dir2
                                             #添加源代码搜索路径在当前路径的前面.默认搜索路径是环境变量PATH中定义的路径。
                                             #如果需要指定多个路径，unix可以使用":"或whitespace,windows使用"；"
(gdb)director                                #清除所有自定义的原文件搜索路径
(gdb)set listsize <count>
(gdb)show listsize
(gdb)list <linenum>                          #显示程序第linenum行周围的代码
(gdb)list <function>                         #显示函数名function的源代码
(gdb)list                                    #显示当前行后的代码，默认是10行，当前行的前5和后5，函数则为前2下8
(gdb)list +                                  #显示当前行后的代码
(gdb)list -                                  #显示当前行前的代码
(gdb)list <first>,<last>                     #显示first行到last行的代码
(gdb)list <last>                             #显示当前行到last行之间的代码
(gdb)search/forward-search <reg>
(gdb)reverser-search <reg>
断点
在gdb中有以下几种暂停方法：
断点（BreakPoint）、观察点（WatchPoint）、捕捉点（CatchPoint）、信号（Signals）、线程停止（Thread Stops）
(gdb)b/break <fileName:linenum> [if  ]       #b x.cpp:15 在文件x.cpp的15行处设置断点
(gdb)break/b <fileName:function>
(gdb)break/b <linenum>                       #在当前文件的linenum停住
(gdb>break/b +<offset>                       #在当前行的后面offset行停住
(gdb)break/b -<offset>                       #在当前行的前offset行停住
(gdb)b <class::function|function(type,type>  #b main
(gdb)b *function-name                        #b *main
(gdb)b *address                              #在地址address处设置断点 b *0x804835C
(gdb)rb                                      #对符合正则表达式的位置处设置断点
                                             #若不带参数，则在所有位置处设置断点
(gdb)info b                                  #查询所有断点
(gdb)disable                                 #默认所有断点失效
(gdb)disable/enable $(id1) $(id2)            #enable/disable breakpoint
(gdb)condition $(breakpoint1) $(expression)  #修改breakpoint的停止条件为expression
(gdb)condition $(breakpoint1)                #清除断点号breakpoint1的停止条件
(gdb)ignore $(breakpoint1) $(number)         #从现在起忽略breakpoint$(number)次
(gdb)delete/d [$(id1)]                       #删除断点
(gdb)                                        #为断点设置运行命令command
(gdb)break string::after                     #断点菜单。当有函数重载时，break <function>不能告诉gdb停止在哪儿(当然，详细的函数原型可以定位).
                                             #此时，gdb会为你弹出一个菜单，提示在哪儿可以设置断点。
                                             #选择0表示取消设置断点，
                                             #亦可以同时选择多项数字，中间用空格间隔
(gdb)break <linespec> thread <threadno> if …#注意，这个threadno是GDB分配的，你可以通过“info threads”命令来查看正在运行程序中的线程信息。
                                             #当你的程序被GDB停住时，所有的运行线程都会被停住。这方便你你查看运行程序的总体情况。
                                             #而在你恢复程序运行时，所有的线程也会被恢复运行。那怕是主进程在被单步调试时。
运行
(gdb)run/r [argv[1] argv[2] ... argv[n]]#重新启动程序运行restart run
(gdb)continue/c/fg [ignore-count]            #continue/c/fg三个命令一样，ignore-count表示忽略断点的次数
                                             #next/step这两个命令必须在有源代码调试信息的情况下使用(即GCC编译时使用-g参数）
(gdb)next/n  [count]                         #next  count表示执行后面的count条指令再停住          
(gdb)step/s  [count]                         #step into function，前提是函数有debug信息。count表示执行子函数里的count条指令再停住。
(gdb)ni/nexti                                #执行一条机器指令  ni/si针对的是汇编指令
(gdb)si/stepi                                #执行一条机器指令
(gdb)finish                                  #运行程序，直至退出当前函数。并打印函数返回时的堆栈地址和返回值及参数值信息。
(gdb)until/u                                 #退出循环体
(gdb)set step-mode on                        #默认值是on。打开step-mode模式。于是在单步跟踪的时候不会因为没有debug信息而不停住。
                                             #这个参数很有利于查看机器源码
(gdb)set step-mode off
栈/帧
(gdb)bt [full]                               #显示局部变量
(gdb)bt [full]  <n>                          #只打印栈顶n层
(gdb)bt [full]  <-n>                         #只打印栈底n层
(gdb)f/frame                                 #check where you are
(gdb)f/frame $(fNum)                         #0表示栈顶
(gdb)info frame/f
查看
(gdb)display ...                             #设置程序中断后欲显示的数据及其格式。 http://hi.baidu.com/foxiong/blog/item/cf448dd67d40d02e06088b74.html
                                             #例如，希望程序每次中断后可以立即看到即将被执行的下一条汇编指令，可以使用
                                             #(gdb)display /i $pc   其中 /i表示以十六进制显示  $pc表示当前的指令
                                             #当需要关心汇编指令时，此命令相当有用
(gdb)undisplay 
查看变量
(gdb)info args                               #查看函数参数
(gdb)info locals                             #查看局部变量
(gdb)info registers                          #查看寄存器
(gdb)info catch                              #查看当前函数中的异常处理信息
(gdb)i r                                     #与上述等价  查看寄存器
查看类型
(gdb)ptype $(val)
(gdb)whatis $(val)                           #查看变量类型
查看寄存器
(gdb)info registers                          #查看寄存器(除了浮点寄存器)
(gdb)info all-registers                      #查看所有的寄存器(包括浮点寄存器)
(gdb)info registers <regname...>             #查看所有指定的寄存器    或 print/p $ip加上$
                                             #ip:当前运行指令的地址 sp:当前堆栈地址 
打印计算表达式
(gdb)set print pretty on
(gdb)print/p [/f] <expresssion>              #gdb会根据当前的程序运行的数据来计算表达式。
                                             #/f format的取值范围 x:16进制 d/u:10进制 o:8进制 t:2(two)进制 a:address c:AsciiChar s:string f:float
                                             #既然是表达式，那么可以是当前程序运行的const变量、变量、函数等，可惜不能是宏。
                                             #	@与数组有关
                                             #  ::指定一个在文件file::variable或函数func::variable中的变量，
                                                   注意与C++的::的区别,还有可能被编译器优化掉某些变量，建议调试时关闭优化选项即-O0
                                             #  {<type>} <addrss> 表示一个指向内存地址<address>的类型type的一个对象
(gdb)p *arrar@len                            #print arrar=(int*)malloc();//set print element 0 默认最长是200个字节
(gdb)p/x (unsigned int[])out                 #强转为unsigned int数组并以16进制打印
查看内存
(gdb)help x
(gdb)examine/x [/nfu] <address>              #n f u 是可选参数 如x /20b $addr
                                             #n number是一个正整数，表示显示内存的长度，也就是说从当前地址address后显示n个地址的内容
                                             #f format表示显示格式。如果地址所指的是字符串，那么格式是s；如果地址是指令地址，那么格式是i
                                             #u unit  表示从当前地址往后请求的字节数。如果不指定的话，gdb默认是4个字节。
                                             # u可以使用下面的字符来代替，b表示单字节，h表示双字节，w表示4个字节，g表示8个字节
                                             # x/3uh 0x54320  从内存地址0x54320读取内容，h表示以双字节为一个单位，3表示三个单位，u表示按十六进制显示
观察点
(gdb)watch $(v)                              #为变量v设点断点，当v被写时stop
(gdb)awatch $(v)                             #为变量v设点断点，当v读或写时stop
(gdb)rwatch $(v)                             #为变量v设点断点，当v被读时stop
设置变量
(gdb)set var = 5                             #设置程序变量
(gdb)set $var = 5                            #设置gdb变量,gdb中的变量以$开头，之后就可以print a[$var++]
自动显示                                  #在gdb中，你可以设置当程序停在断点处时，自动显示变量的内容，即display命令
(gdb)info display
(gdb)display <expr>                          #只要gdb停下来的时候，自动显示的变量
(gdb)display <fmt> <expr>
(gdb)display /<fmt> <addr>
(gdb)display /i $pc                          #$pc是GDB的环境变量，表示着指令的地址，/i则表示输出格式为机器指令码，也就是汇编。
                                             #   于是当程序停下后，就会出现源代码和机器指令码相对应的情形
(gdb)disable/enable display <dnums>
(gdb)undisplay/delete <dnums>                #undisplay 2-5
调用函数
(gdb)call ntohs(10275)                       #调用函数
源代码的内存指令
可以使用info line命令查看源代码行在内存中的起始地址。
info line后可接"linenum","function-name","filename:linenum","filename:functin-name".
(gdb)help info line
(gdb)info line main.c:5                   #默认显示当前行
Line 8 of "main.c" starts at address 0x4004ae <main+22> and ends at 0x4004b2 <main+26>.
在此后，有两种方法查看汇编layout asm或disassemble /r
(gdb)layout asm                           #注意[main+22,main+26)
(gdb)disassemble /r 0x4004ae,0x4004b2     #好像只有gdb7.0才支持/r
(gdb)disassemble /m 0x4004ae,0x4004b2     #会列出源码并汇编
汇编
(gdb)set disassemble-flavor intel/att        #设置反汇编风格
(gdb)show disassembly-flavor                 #查询反汇编风格，可以是intel/att
(gdb)disassemble/disas                    #默认的反汇编范围是所选帧的pc附近的函数
(gdb)disassemble pc/function-name            
(gdb)disassemble /r <begin-addr,end-addr>

(gdb)info/i program                          #find out why your program stopped
改变程序的执行
(gdb)p var = 5                               #设置程序变量并打印
(gdb)jump <linenum>                          #跳转到哪一行执行
(gdb)jump <file-name:linenum>
(gdb)jump +lineoffset
(gdb)jump <address>                          #代码行的内存地址
(gdb)return                                  #强制函数返回
(gdb)return <expression>                     #强制函数返回expression
(gdb)call <expr>                             #显示函数的返回值，如果返回值是void，那么就不显示。
                                             #与print类似，如果函数返回void，call则不显示；print则显示返回值，并把数据存到历史数据中。
历史
(gdb)history
(gdb)show commands 20                        #显示命令的历史记录
联调
(gdb)attach $(pid)                           #等价于gdb -p $(pid)
信号
(gdb)info signals                            #查看信号处理方式
(gdb)info handle                             #查看有哪些信号被gdb检测中
(gdb)handle <signal> <keywords...>       #改变gdb对信号signal的处理方式
						    #  可以以SIG开头或不以SIG开头；
                                             #	也可以定义一个范围SIGIO-SIGKILL,表示包括SIGIO,SIGIOT,SIGKILL三个信号
                                             #  也可以使用关键字all，表明需要处理所有的信号
                                             #keywords，可以是下面关键字的组合，实质上就3列： stop/nonstop print/nonprint pass/nopass
                                             #	nonstop 当被调试的程序收到信号时，gdb不会停住程序的运行，但会打印信息，表示收到这种信号
                                             #  stop    当被调试的程序收到信号时，gdb会停住程序
                                             #  print/noprint 当被调试的程序收到信号时，gdb是否会打印信息
                                             #  pass/noignore   当被调试的程序收到信号时，gdb不处理信号。这表示gdb会把这个信号交给程序处理
                                             #  nopass/ignore  当被调试的程序收到信号时，gdb不会让被调试的程序处理信号
                                             # 例如： handle SIGINT nostop print pass
(gdb)handle SIGNAL nopass/ignore             #不将信号signal传递给程序  
                     pass/ignore             #allow program see this signal
(gdb)signal <signal-number>             #发送信号给被调试程序。
                                             #signal命令与shell的kill命令不同，kill时由gdb截获，signal直接发送给被调试应用。
                                             #signal-number范围是1-15.unix的系统信号通常在1,-15，所以signal也在这个范围
捕捉点                                    #必须在程序处于run状态
(gdb)help catch                          
(gdb)catch <event>                           #throw一个C++的异常(throw为关键字)
                                             #catch一个C++的异常(catch为关键字)
                                             #exec系统调用(exec为关键字，目前只有HP-UX下有用)
                                             #fork系统调用(fork为关键字，目前只有HP-UX下有用)
                                             #vfork系统调用(vfork为关键字,目前只有HP-UX下有用)
                                             #load或load <libname>(load为关键字，目前只有HP-UX下有用)
                                             #unload或unload <libname>(unload为关键字，目前只有在HP-UX下有用)
(gdb)tcatch <event>                          #只设置捕捉一次，当程序停住后，断点被自动删除
设置显示项
(gdb)show print address                      #
(gdb)set print address on/off                #当gdb调用函数的时候，是否显示参数的地址，默认显示
(gdb)show print array
(gdb)set print array on/off                  #当打印数组时，on表示每个元素一行，off则每个元素以逗号分隔。默认off
(gdb)show print elements
(gdb)set print elements <number-of-elements> #设置打印数则时的最大个数，0表示不限制
(gdb)set print null-stop on/off              #on表示显示字符串时，遇到结束符就停止显示。默认off
(gdb)show print pretty                       #如何显示结构体
(gdb)set print pretty on/off                 #on显示比较漂亮 off单行显示
(gdb)show print sevenbit-strings             #设置字符是否按\nnn的格式显示
(gdb)set print sevenbit-strings on/off       #on表示字符串或字符数据按\nnn显示。如\065
(gdb)show print union                        #查看联合体的显示格式
(gdb)set print union on/off                  #设置显示结构体时，是否显示其内的联合体数据
(gdb)show print object                       #查看对象选项的设置
(gdb)set print object on/off                 #在C++中，如果一个对象指针指向其派生类，
                                             #如果on，gdb会自动按照虚方法调用的规则显示输出
                                             #如果off，gdb就不管虚函数表了。 默认off
(gdb)show print static-members               
(gdb)set print static-members on/off         #当显示一个c++对象的内容时，是否显示其中的静态数成员。默认是on
(gdb)show print vtbl
(gdb)set print vtbl on/off                   #是否显示虚函数.默认是off
环境变量
(gdb)show convenience                        #查看所有的环境变量
(gdb)set $v1=x
自动化命令command                         # http://coolshell.cn/articles/3643.html
    (gdb) b func
    (gdb) command 1                          #command 后接breaknumber,每行命令分行，最后以end结束
     >print arg1
     >print arg2
     >print arg3
     >end
    (gdb)
3、调试C++
gdb调试C++，涉及到STL容器查看，非常麻烦。 有一个GDB STL Viewer(http://www.berlinix.com/code/gdb_stl_viewer.txt)的脚本，可以帮助查看STL容器。 
只需在调用gdb后，执行命令source gdb_stl_viewer.txt加载它即可。
b 'C::foo                   自动补全'
ptype C                     显示类C的声明
info functions C::foo       显示类C的所有foo函数声明
在模板函数中的某一行设置断点，将导致gdb只在某个模板实例中中断。 通过info b查看，如:
breakpoint     keep y   0x08048774 in void print<char>(char) at tem.cpp:8
必须在函数签名，而非源代码某一行设置断点，如有模板函数 print<T> 要打断点，可通过：
i) 通过命令 objdump -tC ./tem|grep print 
    或 objdump -t ./tem|c++filt|grep print                  #c++ filter http://book.51cto.com/art/201005/197760.htm
    找出所有print符号。
ii)在gdb中对这些符号下断点。如 b void print<int>(int)

4、配置文件
vim ~/.gdbinit                               #新建gdbinit文件
source ~/gdb_stl_viewer.txt                  #添加gdb命令

define commond-name                          #gdbinit定义命令语法
commands
end

document command-name                        #给命令添加说明性文字
desc
end

5、调试多线程
(gdb)info threads                             #inquire threads
(gdb)thread $(tid)                            #switch among threads
(gdb)thread apply all bt                      #显示所有的线程堆栈              pstack 
(gdb)thread appy $(tid1) $(tid2) bt           #显示tid1, tid2的堆栈。bt可以换成其他任何gdb命令
(gdb)set scheduler-locking off|on|step
			                         #off不锁定任何线程。在调试某一线程时，其他线程照常执行。默认。
			                         #on锁定其他线程，只有当其线程会执行。
			                         #step除了next过一个函数的情况，step只让当前线程执行。
(gdb)break <line> [thread <threadno>] [if ...]#line  filename:linenum
                                              #threadno 是info threads最左边的序号0,1,2而不是大数 
6、调试多进程
(gdb)set detach-on-fork off                   #both parent/child process will be held under the control of gdb
(gdb)set follow-fork-mode child/parent        #default跟踪parent
(gdb)info forks                               #显示所有进程pid
(gdb)process $(pid)                           #切换到pid的进程
(gdb)fork $(fork-id)                          #切换到fork-id的进程，类似process pid,但该fork-id类似于frame id，是最前面的序号0，1，2,...

7、bookmark/checkpoint                        http://blog.chinaunix.net/space.php?uid=23629988&do=blog&id=2943273
(gdb)checkpoint                               #save a snapshot
(gdb)info checkpoints
(gdb)restart $(checkpoint-id)                 #wind back the clock

8、hook
给gdb定义钩子，使其在执行gdb命令前、后，执行用户自定义的命令
define hook-print           # 命令必须是全称，不能为缩写
echo --\n
end
define hookpost-print       # 在命令后执行用户指令
echo --\n
end

9、kgdb
kgdb可对Linux内核进行内核级别源码调试。需要两台机子，用串口相连(或在VMware里模拟串口通讯)。 kdb不能进行内核源码基本调试，但可以只用一台机子。





当进程不正常（死锁），但没有产生coredump，而生产环境又不允许gdb，则需要强制产生coredump：
kill -(SIGQUIT/SIGABRT/SIGFPE/SIGSEGV) $pid
还有一种情况，进程并没有死锁或者block在某个位置，但是我们需要在某个指定位置进行调试，获取某些变量或者其它信息。但是，有可能是客户环境或者生产环境，不允许我们进行长时间的检测。那么，我们就需要通过coredump来获得进程在运行到该点时的快照。这个时候，可以利用gdb来产生手工产生coredump。在attach上这个进程时，在指定位置打上断点，当断点触发时，使用gdb的命令gcore，可以立即产生一个coredump。这样，我们就拿到了这个位置的进程快照。



gdb -help
(gdb)help                      #列出类别
(gdb)help $(class_type)        #
(gdb)b\t\t                     #连续按两次tab键，可以显示候选命令或匹配的函数名
(gdb)shell <command string>    #在gdb中执行shell
(gdb)gcore                     #强制产生coredump




远程调试
情景：
目标机(Server)：192.168.1.241:1100  #在端口1100监听  
调试机(Client): 192.168.1.244
应用程序：a.out
步骤
(1)目标机先启动：
$gdbserver 192.168.1.244:1100 a.out
(gdb) Process a.out created;pid=5384
Listening on port 1100
(2)在客户机：
$gdb a.out
(gdb)target remote 192.168.0.241:1100
Remote debugging using 192.168.1.241:1100



$gdb main
(gdb)layout asm
(gdb)help x             #查看内存
Examine memory: x/FMT ADDRESS.
ADDRESS is an expression for the memory address to examine.
FMT is a repeat count followed by a format letter and a size letter.       [repeat-count]   默认值为1 
Format letters are o(octal), x(hex), d(decimal), u(unsigned decimal),      [format]         
  t(binary), f(float), a(address), i(instruction), c(char) and s(string).  [size]           b(byte) h(halfword) w(word) g(giant 8bytes)
Size letters are b(byte), h(halfword), w(word), g(giant, 8 bytes).
The specified number of objects of the specified size are printed
according to the format.

Defaults for format and size letters are those previously used.
Default count is 1.  Default address is following last thing printed
with this command or "print".






插件：
调试STL
    下载http://www.yolinux.com/TUTORIALS/src/dbinit_stl_views-1.03.txt
    cat dbinit_stl_views-1.03.txt >> ~/.gdbinit
    若正处于gdb状态,运行(gdb)source ~/.gdbinit
    查看帮助(gdb)help pvector 或查看源码dbinit_stl_views-1.03.txt 






$ apt-get source coreutils
$ sudo apt-get install coreutils-dbgsym
$ gdb /bin/ls
GNU gdb (GDB) 7.1-ubuntu
(gdb) list main
1192    ls.c: No such file or directory.
in ls.c
(gdb) directory ~/src/coreutils-7.4/src/
Source directories searched: /home/hchen/src/coreutils-7.4:$cdir:$cwd
(gdb) list main
1192        }
1193    }
1194
1195    int
1196    main (int argc, char **argv)
1197    {
1198      int i;
1199      struct pending *thispend;
1200      int n_files;
1201

















5.3 Signals 
A signal is an asynchronous event that can happen in a program. The operating system defines the possible kinds of signals, and gives each kind a name and a number. For example, in Unix SIGINT is the signal a program gets when you type an interrupt character (often C-c); SIGSEGV is the signal a program gets from referencing a place in memory far away from all the areas in use; SIGALRM occurs when the alarm clock timer goes off (which happens only if your program has requested an alarm). 

Some signals, including SIGALRM, are a normal part of the functioning of your program. Others, such as SIGSEGV, indicate errors; these signals are fatal (they kill your program immediately) if the program has not specified in advance some other way to handle the signal. SIGINT does not indicate an error in your program, but it is normally fatal so it can carry out the purpose of the interrupt: to kill the program. 

GDB has the ability to detect any occurrence of a signal in your program. You can tell GDB in advance what to do for each kind of signal. 

Normally, GDB is set up to let the non-erroneous signals like SIGALRM be silently passed to your program (so as not to interfere with their role in the program's functioning) but to stop your program immediately whenever an error signal happens. You can change these settings with the handle command. 


info signals 
info handle 
Print a table of all the kinds of signals and how GDB has been told to handle each one. You can use this to see the signal numbers of all the defined types of signals. 
info handle is an alias for info signals. 


handle signal keywords... 
Change the way GDB handles signal signal. signal can be the number of a signal or its name (with or without the `SIG' at the beginning); a list of signal numbers of the form `low-high'; or the word `all', meaning all the known signals. The keywords say what change to make. 
The keywords allowed by the handle command can be abbreviated. Their full names are: 


nostop 
GDB should not stop your program when this signal happens. It may still print a message telling you that the signal has come in. 

stop 
GDB should stop your program when this signal happens. This implies the print keyword as well. 

print 
GDB should print a message when this signal happens. 

noprint 
GDB should not mention the occurrence of the signal at all. This implies the nostop keyword as well. 

pass 
noignore 
GDB should allow your program to see this signal; your program can handle the signal, or else it may terminate if the signal is fatal and not handled. pass and noignore are synonyms. 

nopass 
ignore 
GDB should not allow your program to see this signal. nopass and ignore are synonyms. 
When a signal stops your program, the signal is not visible to the program until you continue. Your program sees the signal then, if pass is in effect for the signal in question at that time. In other words, after GDB reports a signal, you can use the handle command with pass or nopass to control whether your program sees that signal when you continue. 

The default is set to nostop, noprint, pass for non-erroneous signals such as SIGALRM, SIGWINCH and SIGCHLD, and to stop, print, pass for the erroneous signals. 

You can also use the signal command to prevent your program from seeing a signal, or cause it to see a signal it normally would not see, or to give it any signal at any time. For example, if your program stopped due to some sort of memory reference error, you might store correct values into the erroneous variables and continue, hoping to see more execution; but your program would probably terminate immediately as a result of the fatal signal once it saw the signal. To prevent this, you can continue with `signal 0'. See section Giving your program a signal.







































ln -s $sym_link  $entity  # sym_link --> $entity


cp    $sym_link $v        # cp $entity $v       拷贝链接指向的对象
cp -d $sym_link $v        # $v ---> $entity   d 单纯拷贝链接


a   ==dpR                       复制属性
d   拷贝时保存链接
p   将修改时间和访问权限也复制
R   递归
l   链接文件，不作拷贝
i   若存在则提示
f   若存在，先删除，再复制














































strace –tt –p –e –o a.txt
strace -f -s 100 ./test
strace -f -p $pid -s 600
strace -e rt_sigaction -f -s 100 ./test


-f/-F  跟踪fork/vfork
-p $pd 跟踪进程$pid
-e     
-s
-tt 
-o    输出文件





 1.挂死程序源码
//hang.c
#include
#include
#include
#include

int main(int argc, char** argv)
{
    getpid(); //该系统调用起到标识作用
    if(argc < 2)
    {
        printf("hang (user|system)\n");
        return 1;
    }
    if(!strcmp(argv[1], "user"))
        while(1);
    else if(!strcmp(argv[1], "system"))
        sleep(500);
    return 0;
}

可向该程序传送user和system参数，以上代码使用死循环模拟用户态挂死，调用sleep模拟内核态程序挂死。


2.strace跟踪输出

用户态挂死跟踪输出：

lx@LX:~$ gcc hang.c -o hang

lx@LX:~$ strace ./hang user

……

mprotect(0x8049000, 4096, PROT_READ)    = 0

mprotect(0xb59000, 4096, PROT_READ)     = 0

munmap(0xb77bf000, 80682)               = 0

getpid()                                = 14539

内核态挂死跟踪输出：

lx@LX:~$ strace ./hang system

……

mprotect(0x8049000, 4096, PROT_READ)    = 0

mprotect(0xddf000, 4096, PROT_READ)     = 0

munmap(0xb7855000, 80682)               = 0

getpid()                                = 14543

rt_sigprocmask(SIG_BLOCK, [CHLD], [], 8) = 0

rt_sigaction(SIGCHLD, NULL, {SIG_DFL, [], 0}, 8) = 0

rt_sigprocmask(SIG_SETMASK, [], NULL, 8) = 0

 

nanosleep({500, 0},

3.输出分析

用户态挂死情况下，strace在getpid()一行输出之后没有其他系统调用输出；进程在内核态挂死，最后一行的系统调用nanosleep不能完整显示，这里nanosleep没有返回值表示该调用尚未完成。

 

因而我们可以得出以下结论：使用strace跟踪挂死程序，如果最后一行系统调用显示完整，程序在逻辑代码处挂死；如果最后一行系统调用显示不完整，程序在该系统调用处挂死。

 

当程序挂死在系统调用处，我们可以查看相应系统调用的man手册，了解在什么情况下该系统调用会出现挂死情况。

下次再遇到程序挂死、命令执行报错的问题，如果从程序日志和系统日志中看不出问题出现的原因，先别急着google或找高手帮忙，别忘了一个强大的工具它就在那里，不离不弃，strace一下吧！




 starce 的另一个用处是解决和动态库相关的问题。当对一个可执行文件运行ldd时，它会告诉你程序使用的动态库和找到动态库的位置。但是如果你正在使用一个比较老 的glibc版本（2.2或更早），你可能会有一个有bug的ldd程序，它可能会报告在一个目录下发现一个动态库，但是真正运行程序时动态连接程序 （/lib/ld-linux.so.2）却可能到另外一个目录去找动态连接库。这通常因为/etc/ld.so.conf和 /etc/ld.so.cache文件不一致，或者/etc/ld.so.cache被破坏。在glibc 2.3.2版本上这个错误不会出现，可能ld-linux的这个bug已经被解决了。
尽管这样，ldd并不能把所有程序 依赖的动态库列出来，系统调用dlopen可以在需要的时候自动调入需要的动态库，而这些库可能不会被ldd列出来。作为glibc的一部分的NSS （Name Server Switch）库就是一个典型的例子，NSS的一个作用就是告诉应用程序到哪里去寻找系统帐号数据库。应用程序不会直接连接到NSS库，glibc则会通 过dlopen自动调入NSS库。如果这样的库偶然丢失，你不会被告知存在库依赖问题，但这样的程序就无法通过用户名解析得到用户ID了。让我们看一个例 子：
whoami程序会给出你自己的用户名，这个程序在一些需要知道运行程序的真正用户的脚本程序里面非常有用，whoami的一个示例输出如下： 
代码：
# whoami 
root
 
假设因为某种原因在升级glibc的过程中负责用户名和用户ID转换的库NSS丢失，我们可以通过把nss库改名来模拟这个环境： 
代码：
# mv /lib/libnss_files.so.2 /lib/libnss_files.so.2.backup 
# whoami 
whoami: cannot find username for UID 0
 
这里你可以看到，运行whoami时出现了错误，ldd程序的输出不会提供有用的帮助： 
代码：
# ldd /usr/bin/whoami 
libc.so.6 => /lib/libc.so.6 (0x4001f000) 
/lib/ld-linux.so.2 => /lib/ld-linux.so.2 (0x40000000)
你只会看到whoami依赖Libc.so.6和ld-linux.so.2，它没有给出运行whoami所必须的其他库。这里时用strace跟踪whoami时的输出： 
代码：
strace -o whoami-strace.txt whoami
open("/lib/libnss_files.so.2", O_RDONLY) = -1 ENOENT (No such file or directory) 
open("/lib/i686/mmx/libnss_files.so.2", O_RDONLY) = -1 ENOENT (No such file or directory) 
stat64("/lib/i686/mmx", 0xbffff190) = -1 ENOENT (No such file or directory) 
open("/lib/i686/libnss_files.so.2", O_RDONLY) = -1 ENOENT (No such file or directory) 
stat64("/lib/i686", 0xbffff190) = -1 ENOENT (No such file or directory) 
open("/lib/mmx/libnss_files.so.2", O_RDONLY) = -1 ENOENT (No such file or directory) 
stat64("/lib/mmx", 0xbffff190) = -1 ENOENT (No such file or directory) 
open("/lib/libnss_files.so.2", O_RDONLY) = -1 ENOENT (No such file or directory) 
stat64("/lib", {st_mode=S_IFDIR|0755, st_size=2352, ...}) = 0 
open("/usr/lib/i686/mmx/libnss_files.so.2", O_RDONLY) = -1 ENOENT (No such file or directory) 
stat64("/usr/lib/i686/mmx", 0xbffff190) = -1 ENOENT (No such file or directory) 
open("/usr/lib/i686/libnss_files.so.2", O_RDONLY) = -1 ENOENT (No such file or directory)
 
你可以发现在不同目录下面查找libnss.so.2的尝试，但是都失败了。如果没有strace这样的工具，很难发现这个错误是由于缺少动态库造成的。现在只需要找到libnss.so.2并把它放回到正确的位置就可以了。











sudo -h
sudo -l
sudo -v
sudo -k
sudo -s
sudo -H
sudo [ -b ] [ -p prompt ] [ -u username/#uid] -s



配置文件 /etc/sudoers



分区 
	fdisk    MBR
	gdisk    GPT
	parted 
	
	
	ls -lsh 第一列为因为占块所占的大小 size为实际数据的大小

lsblk  查看分区

echo $mypassword | passwd --stdin $user #对用户$user设置密码$passwd
curl ftp://$user:$passwd@$host//root #//etc中的第一个/是分隔符
python3 -m http.server 8000 | python2.7 -m SimpleHTTPServer 8000 # 就以当前目录为根目录建立一http server







apt install build-essential
yum groupinstall DevelopmentTools        #若软件需要开发工具
yum groupinstall KernelSourceDevelopment #若软件需要图形接口
yum groupinstall "XSoftwareDevelopment"  #若按照的软件教旧

rpm --help
#安装
rpm -ivh $pkg [opts]
	--prefix       #类似于config --prefix=
	--nodeps #不管依赖性
	--replacefiles #覆盖文件
	--replacepkgs  #重新安装
	--force        #强制安装 等价于replacefiles 和 replacepkgs 
	--test         #检查是否可以安装， 一般用于查看依赖性
	--justdb       #更新数据库信息
	--nosignature  #省略签名
#更新
rpm -Uvh $pkg      #以前没有安装则现在安装 有则更新
rpm -Fvh $pkg      #以前没有安装则不安装 有则更新
#删除
rpm -e $pkg 
#查询
rpm --provides     #查询依赖
rpm --whatprovides #反查询依赖
rpm -qa            #已安装软件
rpm -q  $pkg       #查询是否安装
rpm -q  $pkg
	l            #list 所有文件及其路径
	i            #info
	c            #在/etc下的configure file 
	d            #document 与man有关
	R            #依赖文件 required
rpm -qf $absolute-file #查询属于哪个安装包 由于list是绝对路径， 所以这儿也是绝对路径
rpm -q[licdR]p $pkg #查询当前rpm pkg
#验证pkg自安装后是否被修改过
rpm -Va          #验证所有的pkg
rpm -V  $pkg     #验证某个已安装的pkg， 只有修改过才会列出来
rpm -Vf $ab-file #验证已安装包的某个文件
rpm -Vp a.rpm    #验证某个安装包
#
rpm --rebuild  #
rpmbuild --rebuild *.src.rpm    #仅编译到/root/rpmbuild/RPMS/x86_64/*.rpm
pmbuild --recompile *.src.rpm   #编译并安装


yum install -y --installroot=  #安装到指定目录
yum remove    $pkg
yum list                 #rpm -qa 
yum list pam*            #已安装和可安装
yum list updates         #可供升级
yum search all $pkg 
yum info       $pkg 
yum provides   $ab-file  #rpm -qf yum provides passwd

yum grouplist
yum groupinfo    $groupName
yum groupinstall $groupName
yum groupremove  $groupName

yum repolist all #列举仓库
yum clean [packages|headers|all]




https://wiki.ubuntu.org.cn/%E9%A6%96%E9%A1%B5
https://wiki.ubuntu.org.cn/Qref/Apps
https://wiki.ubuntu.org.cn/UbuntuSkills







http://ddrv.cn/a/342647
https://www.jianshu.com/p/d7c9cef525bc


https://blog.csdn.net/yhc166188/category_7937752.html
https://blog.csdn.net/yhc166188/article/details/82795177


cleos wallet create [-n $walletName]  [--to-console | -f ~/$passwordFileName]  #会在~创建文件夹eos-wallet,默认的钱包名为default.wallet  
#cleos create key [--to-console | -f $keyFileName]  #产生public/private key 
#cleos wallet import -n $walletName --private-key $privKey
cleos wallet create_key -n $walletName 
cleos wallet list  #钱包名列表
#cleos wallet open -n $walletName
cleos wallet unlock -n $walletName --password $password
cleos wallet keys  #列举公钥
cleos wallet private-keys #列举私钥


#建立新账户12位字符 12345abcdefghijklmnopqrstuvwxyz
# 抵押0.001EOS用于网络，0.02EOS用于CPU，购买3k内存（约0.0465EOS）可满足新账户转账最低资源需求
cleos system newaccount --stake-net '0.001 EOS' --stake-cpu '0.02 EOS' --buy-ram-kbytes 3 <自动分配的账户名> <新注册账户名> <你的公钥>


##查看账户
#概要信息（可用资源、投票等）
cleos get account <账户名> 
cleos get table eosio  <账户名>  userres
# 查看账户抵押信息
cleos system listbw <账户名> 
cleos get table eosio <账户名>  delband
# 查看账户余额
cleos get currency balance eosio.token  <账户名> 
cleos get table eosio.token <账户名>  accounts


##转账
cleos transfer <转出账户名>  <转入账户名>  '0.0001 EOS' 'memo'

##竞拍短名（少于12字符的短账户名需竞拍，每24小时只成交一个。目前只能出价，主网激活14天后才正式交易）
# 查询短名出价情况
cleos system bidnameinfo  <短名> 
# 参与竞拍
cleos system bidname <本人账户名>  <短名>  '0.0001 EOS'


atop htop 
bash -c "echo a.sh | at now"

nmcli connection show
nmcli connection show eth0
nmcli connection modify eth0 \
connection.autoconnect yes \
ipv4.method manual \
ipv4.address $ip/$netmask \
ipv4.gateway $gateway \
ipv4.dns $dns
nmcli connection modify eth0 connection.autoconnect yes ipv4.method auto
nmcli connection up eth0

hostnamectl
hostnamectl set-hostname $hostname  #cat /etc/hostname

timedatectl
timedatectl list-timezone
timedatectl set-timezone  "Asia/Shanghai"
timedatectl set-time "2020-02-05 11:01"    # date && hwclock -w
timedatectl set-ntp 
ntpdate tock.stdtime.gov.tw && hwclock -w

localectl
localectl set-locale LANG=en-US.utf8



dmidecode -t [1|4|9|17]  #1SYS 4CPU 9PCI 17MEM

dd if=/dev/sda of=/dev/sdb #不必格式化，速度较慢
find / -print | cpio -covB > /dev/back &&  cpio -iduv < /dev/back
xfsdump 
xfsrestore
tar --exclude --exclude /proc -jcvp -f back.tar.bz2 /

tar --exclude --exclude /proc -N ‘2020-02-05’ -jcvp -f back.tar.bz2 /
rsync -av $src $dst

locate updatedb生效
man    mandb生效
tmpwatch 删除暂存文件

systemctl enabled/restart/status atd
at $time
>echo "hhh" > /dev/tty1  #at环境的默认输出都到/var/spool/mail PATH也会变，所以使用绝对路径
>sync                    #多指令
>sync
>shutdown -h now
>ctrl-d  #显示为EOT
时间格式$time
	HH:MM  04:00
	HH:MM YYYY-MM-DD 04:00 2020-02-20
	HH:MM[am|pm] [Month] [Date]  04pm July 30
	HH:MM[am|pm] + number [minutes|houres|days|weeks]  ex>now+5munutes
atq       #at -l  列出有哪些任务
at -c $jobNumber #列出job具体内容
atrm $jobNumber #at -d  删除任务job

batch 没时间限制的在CPU不忙的情况下执行 是一个shell脚本，本质上就是at


systemctl restart crond
cron  /var/spool/cron/$user文件中 日志在/var/log/cron
	-u  $user
	-e  #edit */5 3,6 3-6 
	-l  #list all items
	-r  #remove all items
minute hour day month week action

如何查找怪异进程：找crontab或怪异进程的父进程pid，然后kill -9 $ppid



man -a signal 
man 7 signal       
kill -l
stty -a 

ctrl-c sigint 2
ctrl-z sigsup 
ctrl-s sigstop 19

ctrl-s 发送stop信号，未放弃fg控制权 ctrl-q 发送start信号
& ctrl-z 发送suspend信号 放弃前台控制权，放入后台 不接受输入，不能ctrl-c， 可以使用bg/fg
jobs -l # -表示最近最后倒数第二个 +表示最近最后一个 只能管理自身这个bash pid直接产生的后台进程， 间接产生的都管理不了
kill -9 %{$jobNumber} %{$jobNumer}   #eg kill -9 %1
fg %{$jobNumber}
bg %{jobNumber}  将前台进程由于ctrl-z状态为暂停变成后台进程运行，自动添加了一个&

ps axjf
top 
	-d $intervalSeconds  #默认3秒刷新一次
	-b -n $displayNumber > a.txt 
	-p $pid
    ?/h 显示按键帮助
	P CPU M Mem N PID T Time+ 排序默认CPU
pstree 
	-A  线
	-u  在括号中显示用户
	-p  在括号中显示pid
free -hw
fuser -v $file/$dir #eg .

systemctl 
	daemon-reload 
	disable 实质是删除链接
	mask    实质就是链接指空     ln -s /dev/null /etc/systemd/system/$service
	unmask  实质就是删除指空链接 rm /etc/systemd/system/$service
	
	
	show ssh #查看服务的配置文件
	/usr/lib/systemd/a.service/               #存放a服务的配置文件 
	/etc/systemd/system/a.service.d/a.conf
	/etc/systemd/system/a.service.d/wants/    #存放a服务启动后需要启动的服务脚本
	/etc/systemd/system/a.service.d/requires/ #存放a服务启动前需要启动的服务脚本
	
	get-default 
	set-default multi-user.target 
	isoloate graphical.target #切换到target  操作隔离等级使用isolate而不是start/stop
	poweroff #操作等级的快捷方式
	reboot
	suspend    #未关机 当唤醒时从内存中读取数据
	hibernate  #数据保存到硬盘然后关机， 当唤醒时从硬盘读取数据
	rescue     #root无法登录
	emergency  #允许root登录
	
	list-dependencies [$target]            #target默认为get-default获取， target中有哪些unit
	list-dependencies [$target] --reverse  #有哪些unit依赖这个target
	list-dependencies $service             #service依赖哪些unit
	list-dependencies $service --reverse  #有哪些unit依赖这个service

客户端命令行 man 1 logger
客户端API    man 3 syslog
服务端       rsyslog.service rsyslogd /etc/rsyslog.conf


/var/log/boot.log 本次启动
/var/log/dmesg

/var/log/lastlog 所有账号最近一次登录
/var/log/wtmp 正确登录
/var/log/faillog 错误登录
/var/log/secure  所有涉及账号密码登录 包括系统的login程序 图形接口登录gdm程序 su sudo ssh telnet

/var/log/messages 
/var/log/cron

logger -p $serviceName.$loglevel "$msg"
logrotate -vf /etc/logrotate.conf  #-v尝试进行一次详细的lograte  -f强制进行一次logrotate
journalctl [-nrpf] [--since TIME] [--until TIME] _optional
	-n 5   #最近几条 类似于head -n 5
	-r     #反向输出 类似于ls -rt 
	-p err #优先级
	-f     #类似于tail -f 
	TIME   #today tomorrow "2020-02-05 12:00:00"
	_SYSTEMD_UNIT=a.service #只显示a.service 
	_COMM=bash              #只显示与命令有关的
	_PID=pid                #只显示pid有关的
	SYSLOG_FACILITY=[0-23]  #使用syslog.h中的服务序号
logwatch 是一分析syslog的工具  是一perl脚本
mail     #读取邮件发送邮件 mail -s ”$subject" $user < $mail_content.txt

dmidecode -t $type
	1  #SYS
	4  #CPU
	9  #主版插槽
	17 #MEM
lspci [-v|-vv] #列出pci接口
lsusb [-t]#以tree形式列出usb
smartctl -t short /dev/sda  #检测磁盘坏道和寿命 t short for test /dev/sda物理磁盘名
smartctl -a       /dev/sda  #a short for all display all info  self-monitoring analysis and report technology system 


tar.gz == tgz
tar.bz2       #(bzip2)
xz

#patch因为不是源码的全部，而是diff出来的， 所以体积小 便于下载存储
patch -p$number < a.patch #给源码打补丁即diff文件 然后重新make && make install
#ldconfig 预先加载so到内存中以便加速访问
echo "/usr/lib/mmysqlclid" >> /etc/ld.so.conf.d/mmysql.conf #配置哪些so需要预先加载
ldconfig [-f /etc/ld.so.conf] [-C /etc/ld.so.cache]  #加载配置文件中定义
ldconfig -p #打印已加载的so
ldd [-v|-d|-r] $exe | $lib.so  #load dependency
	-v #列出所有内容信息
	-d #重新将有丢失的link点show出来
	-r #显示将elf有关的错误
pldd $pid #正在运行的程序      #process load dependencies


SELinux  cat /etc/selinux/config 
DAC(Discretionary Access Control)自主式访问控制 依据进程的拥有者与文件资源的rwx权限来决定有无存取能力
MAC(Madatory Access Control)委任式控制          设定进程和文件资源的权限

主体(Subject|process) <------policy---securityContext---rwx---->目标(Object|filesystem)
##是否启动SE
getenforce        #获取SE模式级别  enforcing|1强制模式  permissive|0 宽容模式   disable 
setenforce [0|1]  #设置SE模式级别
##policy政策,是rule规则的集合  (targeted minimum mls三个主要的政策)
sestatus   #policy
	-v  #校验/etc/sestatus.conf中的文件与进程的安全性文本内容
	-b  #政策中的规则rule是否启动（0|1)
seinfo  #规则统计
	-A #all
	-u #about user
	-r #role
	-t #type
	-b #bool
getsebool -a                 #列出所有规则名ruleName及其值on/off
getsebool $ruleName          #查看某规则值on/off
setsebool [-P] $ruleName 0|1 #persist  否则重启失效
semanage boolean -l |grep $ruleName  #查看规则rule的当前stateValue 默认值defaultValue 描述description
sesearch [-A] [-s $subjectType] [-t objectType] [-b $ruleName]
	-A --allow 
	-s NAME, --source=NAME
	-t NAME, --target=NAME
	-b NAME, --bool=NAME
sesearch -A -b $ruleName     #查看规则内容 一个rule可能有多条item
##securityContext安全性文本 格式user_id:role:typeForFilesystem_OR_DomainForProcess:rest...
ls -Z
ps -eZ  #查看第一个字段中的第三小字段domain值，若是unconfined_t则是不受限的，否则就是受限的
chcon [-R] [-u user] [-r role] [-t type] [-v] $file #改变change file se context  R short for recursive
chcon [-R] [-v] --reference=$范例文件 $file|dir     #参考范例文件一样设置
restorecon [-Rv] $file|dir                          #恢复restore se context 
semanage {login|user|port|interface|translation|fcontext} -l | grep -E "^/etc|^/etc/cron" #list
semanage fcontext -{a|d|m} [-frst] file_spec                 #add|delete|modify
#eg semanage fcontext -a -t system_cron_spool_t "/srv/mycron(/.*)?"
#   semanage fcontext -l | grep "^/srv/mycron"
yum install setroublshoot setroubleshoot-server
systemctl restart auditd  #由audit服务启动setroubleshoot




quota配额
作用对象
	组group          #group与project/dir从文件系统/etc/fstab上就互斥
	非root用户       #四海之内莫非王土 root对所有硬盘都有使用权
	project/dir      #ext文件系统只能针对挂载点，xfs可以针对具体目录
	                 #inode(限制文件数量) block(限制文件夹大小， 单位可以kMG)
					 #有soft和hard之分 类似于低水位和高水位
xfs_quota -x -c "print"  #查看支持quota的挂载点moutpoint -xExpertMode cCmder
xfs_quota -x -c "disable|enable|off|remove -ugp"  #启用关闭quota
xfs_quota -x -c "state"  #查看quota是否启动
#设置user或group或project的block的软硬值 inode的软硬值
xfs_quota -x -c "limit [-ugp] [useName|groupName|prjectName] b[soft|hard]=$N1 i[soft|hard]=$N2" [$mountPoint] 
#设置user或group的宽限时间graceTime
xfs_quota -x -c "timer [-ug] [useName|groupName] [-bir] $Ndays" [$mountPoint]  
#查看设置项uUser gGroup pProject block inode humanreadable
xfs_quota -x -c "report -u|g|p -bih" [$mountPoint]

echo "$userDefinedRandomID:$absoutPathDir" >> /etc/projects
echo "$prjectName:$userDefinedRandomID" >> /etc/projid
xfs_quota -x -c "project -s $projectName"#初始化project
xfs_quota -x -c "limit -p $prjectName bhard=1000M bsoft=100M" /mountPoint

设定流程	        xfs                                   ext
设置文件/etc/fstab  usrquota/grpquota/prjquota            usrquota/grpquota
配置文件                                                  quotacheck 
启动关闭quota       xfs_quota -c "disable|enable -ugp"    quotaon|quotaoff
启动关闭状态        xfs_quota -c "status"
设置user/group      xfs_quota -c "limit "                 edquota|setquota
设置project         xfs_quota -c "limit "
设置grace时间       xfs_quota -c "timer "                 edquota
查看设置项          xfs_quota -c "report"                 repquota|quota
发送警告给用户                                            warnquota


mount | grep quota #查看fs支持哪些quota
mount -a #挂在所有配置在/etc/fstab中的配置的文件系统
unmount $mountPoint|device 


命令
	locate quota | grep bin 等价于 locate *quota* | grep bin  说明支持正则locate $includeCharacters
	locate quota #只要绝对路径名中包含字符串都显示 根据文件名查找比find快多了
	whereis quota 不支持 whereis *quota* 说明whereis不支持正则
	whereis nano  #只查找bin 源文件*.h /usr/share参考文档和脚本  man/info文档
	小结: locate $reg-fileName && whereis $noReg-fileName




vi中     30%跳到文件行数的30%
shell中  ctrl-u 取消当前命令
zgrep
apt install speedtest-cli | pip3 install speedtest-cli  speedtest  #测试的是speedtest.net 
npm install --global fast-cli  fast #默认下载 fast -u #上行        #netflix提供
apt install iperf  #测试局域网window/linux/mac CS模型
server： iperf -s 
cli：    iperf -c $serverIP

mkdir /swapfile
cd /swapfile
dd if=/dev/zero of=swap bs=1G count=1
mkswap -f swap 
swapon swap

sysctl -a #打印所有的kernal变量
taskset   #set/display cpu亲和性
time timeout watch

curl ipconfig.co  #curl ifconfig.me

ipcs   #inter process communication show
ipcmk  #ipc make
ipcrm  #ipc rm
 

dpkg -L tldr | sed -n '2,$p' | xargs ls -ld | awk /^d/ ''   #行首非目录怎么表示     ???

	
 

 


apt-cache madison nginx              #查看有哪些版本
ap-cache  show    nginx | grep -i version  
apt-get install -s $pkgName=$version #模拟安装指定版本 apt-get install nginx=1.14.2-1~xenial
apt-cache policy nginx               #查看已安装的版本号






	
疑问
1 如何由应用bin得知serviceName


systemctl start sysstat && sar #Ubuntu默认没启动 sed 's/false/true/' /etc/default/sysstat 
pkill nginx
echo "" >> /etc/crontab
service crond restart
service keepalived restart 



grep | 尽可能多 ?+*只是前一个单位(单个字符或小括号或中括号为单位)
tmux  ctrl-b q  #显示pane数字
             x  #kill pane
			 m  #mark current pane 加粗
			 o  #select next pane
			 ;  #last pane
			 
			 c  #create window
			 &  #kill current window
			 p  #pre window
			 n  #next window
			 l  #last windows 
			 '  #输入windows index
			 w  #choose window
			 0-9 #choose window
			 
			 - _     #水平竖直切分出pane
			 hjkl    #切换pane 
			 c-h c-l #切换窗口
			 HJKL    #resize pane
			 c       #create window
			 +       #pane -> window
			 x       #kill pane
			 &       #kill window
			 



https://blog.51cto.com/7424593/2174156

GET http://$ip/v1/versions
{
	"code":200,
	"description":"",
	"data":{
		"windows":["1.0","2.0"],
		"linux":["1.0","2.0"],
		"android":["1.0","2.0"]
	}
}

GET http://$ip/v1/hosts
{
	"code":200,
	"description":"fail reason",
	"data":{
		"windows":[$ip,$ip],
		"linux":[$ip,$ip],
		"android":[$ip,$ip]
	}
}

POST http://$ip/api/v1/deploy              #部署节点
{
	"ip": "192.168.1.8",                   #部署节点机器ip
	"os": "windows|linux|android",         #部署节点的操作系统
	"deployLocation":"/data/ipfs",         #部署位置
	"deployVersion":"1.0",                 #部署版本
}

{
	"code": 200,
	"reason": "fail reeson",
	"data":{
		"nodeid":1,                        #返回节点id
	}
}


POST http://$ip/api/v1/start?nodeid=1       #启动节点
{
	"code":200,
	"reason":"fail reason",
	"data":{}
}


POST http://$ip/api/v1/stop?nodeid=1        #停止节点
{
	"code":200,
	"reason":"fail reason",
	"data":{}
}


POST http://$ip/api/v1/restart?nodeid=1     #重启节点
{
	"code":200,
	"reason":"fail reason",
	"data":{}
}


GET http://$ip/api/v1/nodesstatus           #查询所有节点状态
{
	"code": 200,                            #http返回码
	"reason": "failed reason",              #失败原因
	"data": [
		{
			"ip": "192.168.1.8",
			"runningStatus":2,              #运行状态stop:0 launching running:2
			"deployLocation": "/data/ipfs", #部署位置
			"deployVersion": "1.0",         #部署版本
			"diskspace":"100M",             #占用磁盘空间
		},
		{

		}
	]
}

GET htttp://$ip/api/v1/nodestatus?nodeid=1   #查询单节点状态
{
	"code":200,
	"reason":"",
	"data":{
		"runningStatus":2,
		"deployLocation": "/data/ipfs",
		"deployVersion": "1.0",
		"diskspace":"100M",
	}
}

POST　http://$ip/api/ipfs/v1/updatenode?nodeid=1
{
	"os":2,
	"preDeployLocation":"",
	"preDeployVersion":"",
	"deployLocation":"",
	"deployVersion":"1.0"
}

{
	
}




redis
百度redis 命令参考  doc.redisfans.com  redisdoc.com


>object idletime $key #lru时间

rdb方式(真实数据)
人工主动执行命令  save 阻塞执行
                  bgsave 后台执行
配置被动执行命令  save 900 1 

aof方式(真实命令list/set/zset/hash64个元素)
增量
	什么时候人工主动执行?????????
	配置被动执行aof命令        appendfsync always|everysecond|no  #执行fsync或fdatasync的频率
		操作append_to_buf
全量  
	人工主动执行rewriteaof命令 bgrewriteaof
		操作append_to_rewrite_buf
		pid=fork();
		if pid > 0 {
			execute_cmd
			append_to_buf          -----> old.aof
			append_to_rewrite_buf  -----> new.aof
		} else if pid == 0 {
		}
	什么时候全量自动执行rewrieaof??????????????


replicate 
slaveof $master_ip $master_port
slaveof none
info replication   #offset lag最后一次主从通讯到现在的时间   类似于client list中idle字段

Master                                            slave
		   <-----ping ----------------------------
		   ------pong ---------------------------->
		   <-----auth $master_auth_passwd----------   slave配置文件中masterauth字段 也就是master配置文件中的requirepasswd 要一致  输入master密码
		   <-----replconf listening-port $port-----   向master报告自己的listen port
	       <-----psync $master_id offset --------     向master报告自己的replication offset
	bgsave
			-----send rdb  offset -------->              状态同步
			-----send replication backlog中的命令 ---->  命令传播cmder prograte
			<----replconf ack $offset --------------      headbeat


sentinel
在sentinel中使用raft协议选举sentinel leader
>slave of none
>slave of $master_ip $master_port


cluser  #gossip协议(检查节点是否断线和故障转移) 节点只能使用0号数据库
redis-cli -c $ip $port
>cluster meet $ip $port  #将节点加入cluster
>cluster nodes           #查看cluster nodes 
>cluster addslots 1 2 3 4 ... 1000  #分配好slot才可称为上线
>get $key                ########MOVED错误 这个slot根本就不在我这儿

#迁移slot
>cluster setslot $slotNumber importing $sourceID #通知target准备接收slot

>cluster setslot $slotNumber migrating $targetID #通知source准备迁移migrate slot
>cluser getkeysinslots $slotNumber $count 
>cluser migrate $targetIP $targetPort $keyName 0 $timeout #从source迁移key
>cluster setslot $slotNumber node $targetID   #通知cluster中的节点slot迁移到了$targetID
##########ASK错误                  #本来这个slot是在我这儿 但我正搬家呢
>asking

>cluster replicate $nodeID


>cluster info 
>set msg "dfd"          #返回MOVED错误，redirected to slot $slot at $ip:$port
>cluster keyslost $key  #返回key属于哪个slot
>cluster getkeysinslots $slotNumber $keysCount #返回槽号slotNumber中keyCount个key


Master                Slave
	                  slaveof $master_ip $master_port
	     <----sync----	   
(bgsave)

hotkey
bigkey

3.2
bitmap
geohash
4.0
boomfilter
unlink替换del flushdb flushall
redis-cell 漏斗限流
mix-persistence
psync2
memory 
swapdb
5.0 
stream


pipe
pubsub
tx
lua
sort (list set zset)
	sort 
		alpha asc/desc 
		by *_id 
		limit offset cout
		get *_name
		store $new_key  #默认是暂时排序 
bitmap getbit
client list/kill 
slowlog
monitor
info


watch $key1 $key2   #让服务器登记这个client要求在接下来的这段时间内服务器不能对这些key进行修改
multi               #begin 标记tx的开始
exec/discard        #commit 准备执行 首先检查watched key是否被修改，若被修改过，则直接返回错误
                    #discard 只能位于最后，不能位于中间  非rollback 表示放弃不执行
unwatch $key1 $key2 #让服务器取消登记

Atomic     原子性  不支持   遇见错误,也会继续往下执行
Consitence 一致性  
	什么是一致？       只有对比才可发现是否一致。那么对比什么呢？ 数据库
	一致的标准时什么？ 数据符合数据库标准的定义和标准，无无效或非法数据。
	
lua
redis-cli --eval "a.lua"
>script    load "return 0;"
>eval      "return 0" 0  
>evalsha   $hash $argCount $arg1 ...
>script    exists $hash1 $hash2
>script    kill    #lua_time_limit 还需要用户手动发起命令script kill或shutdown nosave
>script    flush

lua原生函数库
	base/core:  assert error pairs tostring pcall and so on,但loadfile因为安全被删
	string:     find format len reverse and so on
	table:      insert remove sort concat and so on
	math:       因为安全删掉原版的randomseed random    
	debug：     sethook gethook getinfo setmetable getmetable
	cjson       decode encode
	struct      pack unpack
	cmsgpack    pack unpack
redis封装的
	全局变量
		用户不能自定义全局变量，只能get/set由redis定义的全局变量
	函数  
		redis.call                  #eval "return redis.call('SMEMBERS', KEYS[1])" 1 sname  使用辅助函数__redis__compare__helper排序
		redis.pcall                 #若出现错误使用__redis__err__helper排序
		redis.status_reply  
		redis.error_reply
		redis.log(redis.LOG_DEBUG)  #VERBOSE NOTICE WARNING
		math.randomseed($seedValue) #修改版的randomseed,相同的seed产生相同的随机数  改变种子,参数默认值为0,返回空 
		math.random($var)           #修改版的random,返回随机数
		redis.sha1hex               #计算sha值
		__redis__err_helper         #辅助函数作用于redis.pcall打印具有行号的错误日志 
		__redis__compare_helper     #辅助函数作用于需要一致性的地方 smembers sunion sdiff smembers hkeys hvalues keys
	

	

gdb -ex "set pagination 0" -ex "thread apply all bt" -batch -p $pid
obdump -c -x #-c ascii -x hex



https://blog.csdn.net/qq_38472380/article/details/81039058
无人值守安装centos


实验： 
redis fork 查看内存是否倍增？？？？？？？？？？

mysqld_safe  &  启动mysql的文本文件


#https://blog.csdn.net/sixdaycoder/article/details/89947893
#https://blog.csdn.net/zxc024000/article/details/104168924
ctrl-shift-p 输入remote-ssh:setting ->勾选show login termial
ctrl-shift-p 输入remote-ssh:connect to host -> configure ssh host 

左侧 remote explore 选择对应的目标,连接  在弹出的额终端窗口中输入密码
左侧 remote explore 选择对应的目标,右击

免密码登录
    ssh-keygen -t rsa -b 4096         #产生的key位于 /c/Users/Administrator/.ssh/id_rsa.pub
    ssh-copy-id root@192.168.1.106
    ssh root@192.168.1.106 -p22







https://stackoverflow.com/questions/3427872/whats-the-difference-between-and-in-bash/3427931#3427931
https://www.zsythink.net/archives/2252





5.1    2008-11
5.5    2010-12-03
5.6    2013-02-05
5.7    2015-12-07
8.0.0  2016-09-12
8.0.11 2018-04-19


https://www.docs4dev.com/docs/zh/mysql/5.7/reference/explain-output.html  mysql5.7中文文档
http://www.deituicms.com/mysql8cn/cn/web.html                             mysql8.0中文手册https://github.com/lrjxgl/mysql8cn



删除mysql
	官方方法
		apt remove mysql-server
		apt autoremove
		dpkg -l | grep mysql | grep ii
	试验过的方法
		apt purge mysql-server
		apt purge mysql-server-5.7
		updatedb 
		locate mysql


innodb_file_per_table

变量
	系统变量
		set 必须明确
			global
				set @@global.$var
				set global $var
			session
				set @@session.$var
				set session $var
				set $var
		get
			global
				select @@global.$var
				select global $var
				show   @@global.$var
				show   global variables like $var
			session
				select @@session.$var
				select session $var
				show   @@session.$var
				show   session variables like $var

		SELECT @@var_name  优先返回session global
		show   variables   优先返回session global
	用户变量
		set
			set @useVar1:=1, @userVar2:=2
		get
			select @userVar1, @userVar2



mysql>system ls -l *  #执行bash命令

mysql
windows下是my.ini  linux下是my.cnf  /etc/mysql/mysql.conf.d/mysqld.cnf  mysqld --verbose --help | grep defaults-file
mysql.cnf是mysql各应用的集中配置的地方
[client]
host=        #对应环境变量MYSQL_HOST
user=        #对应环境变量USER
password=    #对应环境变量MYSQL_PWD
default-character-set=utf8
[mysql]
default-character-set=utf8
[mysqld]   #选项组
basedir=
datadir=
bind-addr=0.0.0.0  #不能是127.0.0.1
port=3306
server_id=1
character-set-server=utf8
#skip-grant-tables  #忘记密码时使用
default_authentication_plugin=mysql_native_password #默认的密码加密方式是caching_sha2_password，但很多gui客户端不支持默认加密方式，所以不能登录
explicit_defaults_for_timestamp = true
time_zone=system    #使用linux操作系统的时区   SELECT @@global.time_zone, @@session.time_zone;
[mysqldump]

任何时候出现错误都可以删掉数据目录的所有文件，重新再来  rm -rf /var/lib/mysql/* && chown -R mysql:mysql /var/lib/mysql
mysqld --verbose --help 可以查看加载配置文件的顺序及默认值 mysqld --print-defaults 最后提示查看运行的mysqld的变量可以使用mysqladmin variables 
mysql            --help 可以查看加载配置文件的顺序及默认值 mysql --print-defaults

1. 初始化生成密码
方式一 官方推荐方式
mysqld --initialize --user=mysql #会初始化data目录并将password打印到控制台
                                 #如果不加console， 会写入日志/var/log/mysqld.log
                                 #a temporary password is generated for root@localhost: $passwd
方式二
mysql_install_db --user=mysql    #会在~/.mysql_secret中存放密码   man mysql_install_db得知已过时  
                                 #创建data目录 mysql数据库(初始化授权表 访问控制) test数据库


2. 启动
mysqld_safe --user=mysql &

3.使用初始密码登录 修改密码并可远程登录， 实际就是设置mysql.user表  mysql.host表 mysql.db表
mysql -uroot -p   #host默认为localhost user默认为登录linux的用户
Enter password:   #输入上步的密码
mysql>show databases;
mysql>use mysql;

mysql>CREATE USER 'yy'@'%' IDENTIFIED BY '111111';     #这步只能查看infomation_schema
mysql>insert into mysql.user(host,user,password) values('%','root',password('111111'));

mysql>SET PASSWORD FOR 'root'@'%' = PASSWORD('newpwd'); #方式一 使用环境变量方式 第一个password是环境变量 第二个是函数
mysql>UPDATE mysql.user SET password = PASSWORD('newpwd') where user='root'; #方式二 使用sql语句
mysql>ALTER USER "root"@"%" IDENTIFIED WITH auth_plugin BY "111111"; #可以使用默认的加密方法
            #plugin是密码的加密方式 authentication_string是密码加密后的字符串
			#mysql8.0需要修改加密方式，否则一般的gui client由于不支持某种加密方式而无法登录
mysqladmin -u root -h host_name password "111111"       #方式三 这种更方便

mysql>GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY '111111' WITH GRANT OPTION;   #一气呵成  创建用户 远程访问 设置权限
                          #host的通配符为%或_ %表示任意ip都可以登录，默认是localhost 
                          #	  root@192.168.1.2/255.255.255.0 只能局域网内访问
                          #   root@192.168.1.%
                          #   root@%.loc.gov
                          #on $db.$table TO $user@$host  db和table的通配符为*
                          #全局权限是在mysql.user设置,某个具体数据库的权限是在mysql.db表
mysql>show grants for yy;   
mysql>show grants for yy@%;
mysql>flush privileges;   #与mysqladmin flush-privileges; 或 mysqladmin reload;效果相同 否则mysql服务需要重启


      
>help;  #最后提示
>help contents;
>help show;
>help set;
>help alter {database|table}
>help {create|drop} {database|table|index}
>help select insert delete update replace truncate
>help {do|handler|load data infile}
>help use $dbName;
>help desc $tableName;
>help explain

show variables [like '%a%'];
set [session|global] $variableName=$value;  #global表示全局的，默认是session级别。
show status    [like '%a%'];
select version();
select user();
select current_user();
show databases;

select @@global.transaction_isolation;
show variables like '%isolation%';
set global transaction_isolation='REPEATABLE-READ';




use mysql;
select database();
drop database $databaseName;

show tables;
desc user;                
show create table $tableName;
drop table $tableName;
show index from $tableName;
show table status [from $dbName] [like 'pattern']


mysqladmin -uroot -p111111 
	create|drop $databaseName
	variables | status | exteneded-status
	processlist 
	kill $pid
	shutdown
	password  '$newPassword'
	start-slave|stop-slave 

mysql -uroot -p -N -e " select * from user where user='root'; "
--disable-column-names --skip-column-names --column-names=0
--column-names --enable-column-names --column-names=1




show open tables where in_use > 0;            #查看哪些表被锁住了
select * from information_schema.innodb_trx;  #查看锁表的进程
show processlist;
kill $pid;


压力测试工具
mysqlslap mysql自带的
sysbench

pxc集群Percona XtraDB Cluster

create table clone_tbl select * from tbl_name limit  0

调整参数key_buffer_size bulk_insert_buffer_size
mysql -t   #批模式下一般比较精简，为得到如交互模式格式的输出
mysql -vvv #回显在批模式下所执行的语句
mysql < a.sql   
mysql>source /root/a.sql
mysql>.      /root/a.sql
mysql>alter table tbl_name disable keys;  \    #使用alter可以跳过flush tables;
	  LOAD DATA LOCAL INFILE '/path/pet.txt' INTO TABLE pet FIELDS TERMINATED BY '\t' \
	  	   OPTIONALLY ENCLOSED BY '"' ESCAPED BY '\\' LINES TERMINATED BY '\r\n'; \
      alter table tbl_name enable keys;
                                #local可以装在client端文件(运行mysqlcli的客户端),否则只能装在server端文件(运行mysqld的服务器)  
                                #默认从show variable like '%load%';加载数据文件,所以一般用绝对路径
mysql>lock tables a write; \             #只锁定部分表
       insert into a values (), (), ()  \
       insert into a values (), (), ()  \
       unlock tables;                    #释放这个session所有获取的lock
msyql>begin; \           #对于事务表
       insert into a values (), (), ()  \
       insert into a values (), (), ()  \
      commit;
mysql>lock tables real_t write, temp_t write; \
       insert into real_t select * from temp_t; \
       truncate table temp_t; \
       unlock tables;
mysql>select to outfile from 
mysqldump
mysqlimport

select count(*) fron myisam_t #不能有where语句,直接读
为什么innodb不保存行数?
因为是事务特性,同一时刻表中的行数对不同的事务而言是不一样的.


锁
除bdb页 innodb行外, 基本都是表锁myisam/memory
表级锁不可能死锁,因为在事务前就已获取锁
页行锁因为在sql语句处理时获取锁,而不是事务启动时,所以可能死锁
查看行级锁 show variabeles like '%table%'  tables_locks_waited tables_locks_immediate
表级锁 write优先级高于read
建议锁 GET_LOCK()/RELEASE_LOCK()

表写锁 lock tables a write, b write;
表读锁 lock tables a read, b read;
行读锁 select * from t in share mode;
行写锁  select * from t for update;


thread_cache_size connection数的大小



在not null其实可以插入0或"", 因为0或“” is NOT NULL
group by NULL;  2个NULL视为相同
order by $field asc; NULL排在最前，即NULL最小

模式匹配
标准SQL like '_'表示单个字符 '%'表示任意长度的字符串(包括0个字符)
MySQL  vi sed grep  一般情况下(除^$外)，只要子匹配即可
	REGEXP|RLIKE  NOT REGEXP|RLIKE    #类似于like not like

mysql>select LAST_INSERT_ID();  #session级别的 亦可以使用CAPI mysql_insert_id()
insert into $t values ($rowA) [,($rowB) ...] 

mysql>ALTER TABLE tbl AUTO_INCREMENT = 100; #设auto列的初始值
mysql> SELECT @min_price:=MIN(price),@max_price:=MAX(price) FROM shop;
mysql> SELECT * FROM shop WHERE price=@min_price OR price=@max_price;





log
mysql>flush logs;
mysqladmin flush-logs;
mysqladmin refresh;
错误日志
log-error[=hostname.err]
通用日志
general_log=ON
general_log_file=[hostname.log] #mysqld -l 
慢查日志  mysqldumpslow
log-slow-queries[=hostname-slow.log]
long_query_time=10
log_queries_not_using_indexes=1   使用mysqld --log-short-format避免记录不适用index的query
log_slow_admin_statements=0       默认alter optimize analyze table不记录
bin日志  mysqlbinlog
log_bin[=/dataPath/bin.$hostName]              #文件名后缀会被忽略
max_binlog_size[=]                             #但也必须确保一个tx写入同一个文件
log_bin_index[=/dataPath/bin.$hostName.index]  #包含所有binlog文件名。 
                                               #mysql>reset master;      #删除所有二进制日志
                                               #mysql>purge master logs TO $logName ;        #只删除部分二进制日志
                                               #mysql>purge master los before ''2003-04-02 22:46:26';




information_schema  数据库表 列 函数 存储过程 视图 触发器的定义
mysql               用户管理 权限
performance_schema  inspect the internal execution of the server at runtime 查看服务器运行状况
sys                 提供一系列对象更好地查看performance schema

mysql-log-rotate 

create select
insert select


mysql>show variables like '%query_cache%'
mysql> SHOW STATUS LIKE 'Qcache%';
have_query_cache=YES/NO;  指示查询缓存是否可用
query_cache_type=on/off;  0/off表示禁用 1/on允许缓存，尽明确使用select sql_no_cache除外 2/demand仅针对select SQL_CACHE可以启用缓存  
select SQL_CACHE    id from t;
select SQL_NO_CACHE id from t;
query_cache_min_res_unit[=4k]；  #每次分配一次select查询结果至少使用多少缓存 
query_cache_limit[=1M]           #每次分配一次select查询结果至多使用多少缓存 
query_cache_size[=0]             #默认值0表示禁用缓存,至少40K
Qcache_lowmem_prunes=            #因为缓存太少而被踢除的数量
                                 #它计算为了缓存新的查询而从查询缓冲区中移出到自由内存中的查询的数目。查询缓冲区使用最近最少使用(LRU)策略来确定哪些查询从缓冲区中移出
Qcache_queries_in_cache=

Qcache_total_blocks=             #总块多少
Qcache_free_blocks=              #空闲块多少 total与free blocks可知querycache碎片程度
mysql>flush query cache          #清理query,只保留一个块 cache内存碎片整理而提高查询速度

select数量=Qcache_hits(命中缓存数) + com_select(普通查询数) + queries with errors found by parser
com_select=Qcache_inserts + Qcache_not_cached + queries with errors found during columns/rights check

Qcache_hits +1 而不是 com_select
mysql>reset query cache   #重置清空query cache

当执行sql语句或设置SET GLOBAL query_cache_size = 4000;时，会提示有warning，因为至少需要40Kquery_cache.这时可以使用show warning查看具体warning;





保护数据最简单的方法是使用''
 ';drop database test'                  #
 select * from t where id='12 or 1=1';  #没''则检出所有所有数据  mysql在数字列会自动将字符串转换为数字，非数字的自动舍弃。



	mysqldump -uroot -p --single-transaction --master-data --where='id<10' $db $table > a.sql; 
	cat a.sql
	lock tables $table write;
	#一些ddl dml
	unlock tables; 

	mysqlbinlog mysqld-bin.01 | more   #at是起始位置 end_log_pos是结束位置  [at end_log_pos)
	/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=1*/;
	/*!40019 SET @@session.max_insert_delayed_threads=0*/;
	/*!50003 SET @OLD_COMPLETION_TYPE=@@COMPLETION_TYPE,COMPLETION_TYPE=0*/;
	DELIMITER /*!*/;
	# at 180   ##############################################################################################################起始点#####
	#180410 17:57:32 server id 1  end_log_pos 496     Query    thread_id=89    exec_time=0    error_code=0
	use `employees`/*!*/;
	SET TIMESTAMP=1523354252/*!*/;
	INSERT INTO `departments` VALUES 
	('d001','Marketing'),
	('d002','Finance'),
	/*!*/;


备份和恢复维护之myisam(.frm myd myi)
	备份
		全量备份
			lock tables && flush tables &&  cp 文件  && unlock tables;
			sql级别 select into outfile $outFileName from $t 或  backup table
			mysqldump > mysqldumpfullbackup.sql
			mysqlhotcopy $dbName $dstDir   只适合myisam,已经不再使用了
			snapshot 快照
				Client1                                Client2
				mysql>flush tables with read lock;
                                                       >mount vxvf snapshot;
                mysql>unlock tables; 
                									   从快照复制文件后unmount
		增量冷备份  自从上次mysqldump以来的binlog
			mysql>flush logs    或mysqladmin flush-logs #告诉服务器关闭当前的binlogN文件并创建下一个序号的binlogN+1
			停止mysqld                                  #每次重启也会创建下一个序号的binlog
			拷贝binlog到远处
			mysqld --log-bin[=安全媒介如raid/san目录,不同于普通的mysql数据目录]启动.
		主从之从还需要备份master.info relay-log.info
	恢复  repair table myisamchk -r
		全量
			sql级别 load data infile $inFileName replace 
			mysql < mysqldumpfullbackup.sql
		增量冷备份
			mysql < mysqldumpfullbackup.sql
			mysqlbinlog mysqld-bin.* | mysql         #正常bin日志,肯定可以恢复  也可以mysqlbinlog bin.1 bin.2 | mysql
			mysqlbinlog 崩溃raid目录下的mysqld-bin.* | mysql   #崩溃bin日志 尽可能恢复
	维护
		检查 check table $tableName; repair table $tableName;
		优化 optimize table $tableName;
		分析 analyze table $tableName;
备份和恢复之innodb   innochecksum
	不将表的内容保存到数据库目录中
	不需要加锁,可以在线备份
	备份
		全量备份
			mysqldump --single-transaction --flush-logs --delete-master-logs --all-databases > backup.sql 
				#--single-transaction使用一致性地读,并且保证mysqldump所看见的数据不会更改
				#--delete-master-logs  删除binlog 有可能从服务器还没有复制完,慎用
		增量备份
			mysql>flush logs;
	恢复
		全量
			mysql < mysqldumpfullbackup.sql
		增量
		    #查看binlog的保存位置
		    mysql>show binlog events;

			mysqlbinlog  --stop-date="2005-04-20 9:59:59"  -v mysqld-bin.1 | mysql
				--no-defaults
				--database=$dbName 
				--base64-output=decode-rows
				-o $skipNumber
				--server-id=$serverID
				-s --short-form              #只显示语句,不显示附加信息
				-R -h $host/$ip -p           #获取远程服务器的
			mysqlbinlog --start-date="2005-04-20 10:01:00" mysqld-bin.1 | mysql

			mysqlbinlog --stop-position="368312" mysqld-bin.1 | mysql
			mysqlbinlog --start-position="368315" mysqld-bin.1 | mysql
	维护
		检查 check table $tableName; 
		优化 optimize table $tableName;
		分析 analyze table $tableName;


binlog
	格式
		statement-based replication(SBR)  基于sql语句
			只记录修改节约IO
			准确性查,不能now() UUID()
		row-based replication(RBR)        基于行
			记录记录每个字段变化前后的值,准确性强
			文件大,耗磁盘与带宽
		mixed-based replication           混合模式
			文件大小适中
			有可能主从不一致
	存在形式
		   .index 记录所有的binlog名，以便跟踪日志循环
		bin.log
	命令
		查看是否开启 
			show variables like '%log_bin%';  
			select @@log_bin;
		查看正在写入的日志
			show master logs;      #master与binary是同义词
		查看binlog文件列表
			show binary logs;
		查看log_bin文件中的内容
			show binlog events [in $logName] [from pos] [limit [offset,] row_count]
		刷新
			flush logs;

		重置所有binlog
			show master status;
			show slave hosts;
			show slave status; !!!!关注seconds_behind_master字段, 这是salve的sql线程分析relaylog得到的,当前要执行的sql与master执行这条sql时相差的时间.
                               !!!!show processlist中的sql线程time字段为 从master复制而来的最后一次事件/最后一条sql与slave现在的时间差, 从这个地方可以看出master最后一次发送binlog的时间

			reset master;
			reset slave;

			start slave $threadType $UNIT
				IO_THREAD   MASTER_LOG_FILE = 'log_name', MASTER_LOG_POS = log_pos
				SQL_THREAD  RELAY_LOG_FILE = 'log_name', RELAY_LOG_POS = log_pos
			stop slave  IO_THREAD | SQL_THREAD;

		binlog_cache_size
		Binlog_cache_use
		Binlog_cache_disk_use

		mysqlbinlog -j $pos $file | head


主(binlog binlog.index)                                                           从(relaylog relaylog.index master.info relay-log.info) 
	配置文件                           
		gtid_mode=ON
		enforce-gtid-consistency=ON

		server-id=$ip$port (1-2^32-1)                                             server-id=$ip$port
		sql_log_bin=1     #是否允许写入binlog                                      
		logs_bin=mysql-bin #定义文件                                               logs_bin=mysql-bin #定义文件

        sync_binlog=1     #定义写入文件的频率                                       logs_slave-update=1 #当这个slave又作为其他slave的master时，否则不会给更新的记录写入到binlog
		       
        innodb_flush_log_at_trx_commit=1                                
		
		slave_skip_errors=1 #跳过错误 继续复制                                      master-connect-retry[=60] #从服务器若失去连接隔多长时间去重试

		binlog_do_db=mydb1      #必须写入binlog的db                                replicate-do-db=mydb1     #必须复制的数据库             
		binlog_do_db=mydb2                                                        replicate-do-db=mydb1     #必须复制的数据库 
		binlog_ignore_db=mydb3  #必须忽略写入binlog的db                            replicate-ignore-db=mydb3
		binlog_ignore_db=mydb4                                                    replicate-ignore-db=mydb4
                                                                                  replicate-ignore-table=mydb1.mytabl1
		binlog_format=mixed
		expire_log_days=7
		max_binlog_size=100m                                                      max-relay-logs-size=size
		binlog_cache_size=4M
		max_binlog_cache_size=512M

		auto_increment_offset=1
		auto_increment_increment=1    


	创建账号并授权
		mysql> GRANT REPLICATION SLAVE ON *.* TO 'repl'@'192.168.0.%' IDENTIFIED BY 'repl';

	全量备份
        不是binlog方式运行
            mysql>flush tables with read lock;
            tar czvf 数据文件或目录
            mysql>show master status;                                            #change master to master_log_file="" master_log_pos=4
            mysqladmin -u root shutdown

        已经是binlog方式运行
    		mysql>flush tables with read lock;
            tar czvf 数据文件或目录
    		mysql>show master status;
    		mysql>unlock tables;

        #mysqldump效率较低 相对于拷贝文件
		mysqldump -S /tmp/mysql3306.sock -p --master-data=2 --single-transaction -A |gzip >3306-`date +%F`.tar.gz
                                                                                    mysqld 
                                                                                        --skip-slave-start 不立即连接master, 即以后start slave
                                                                                        --log-warnings     默认启动  记录更多信息
																			        清除GTID_EXECUTED值
																			        	mysql>reset master;
                                                                                    还原数据
                                                                                    	gunzip < 3306-2019-10-13.sql.gz | mysql -S /tmp/mysql3306.sock -p
                                                                                    	mysql>CHANGE MASTER TO
                                                                                    	       MASTER_HOST='192.168.0.106',
                                                                                    	       MASTER_PORT=3306,
                                                                                    	       MASTER_USER='repl',
                                                                                    	       MASTER_PASSWORD='repl',
                                                                                    	       MASTER_AUTO_POSITION=1;  #使用GTID模式
                                                                                               master_log_file=
                                                                                               master_log_pos=
                                                                                    	mysql>start slave;
                                                                                    	mysql>show slave status;  #!!!!!Slave_IO_Running: Yes   Slave_SQL_Running: Yes
                                                                                                                  #seconds_behind_master

    master/slave强制同步
        master                                       slave
            mysql>flush tables with read lock;
            mysql>show master status;
                  #此时master只读,等待slave
                                                     mysql>select master_pos_wait('binlog_file', binlog_pos);
                                                           #执行这条sql会阻塞知道slave达到指定的file和pos,此时master/slave同步,返回
            mysql>unlock tables;




     出现问题时
     slave
     	mysql>stop slave;
     	mysql>reset master;
     master
     	mysql>reset master
     slave
     	mysql>reset slave;
     	mysql>start slave;

     	mysql>SET GLOBAL SQL_slave_SKIP_COUNTER = n; #当next为AUTO_INCREMENT或LAST_INSERT_ID()的语句使用值2的原因是它们从主服务器的二进制日志中取两个事件
     	                                             #当是其他时为1
     	mysql>start slave;

     不复制table的存储引擎类别 以便在不同的存储引擎间复制; 为提高速度,salve一般使用myisam来代替innodb和bdb
     双主复制  只是减少了锁竞争  

     主从切换
         在每个slave上,先
            mysql>stop io_thread; 不再复制
            循环执行mysql>show processlist; 直到status为has read all relay log
         在被选举为master的slave上
            mysql>stop slave;
            mysql>reset master;
         在未被选为master的slave上
            mysql>stop slave;
            mysql>change master to master_host="" master_port= master_user= master_password=; #file使用默认值(第一个bin'log), pos使用默认值(4)
            msyql>start slave;

    状态
    	master (show processlist中Command: Binlog Dump)
    		Sending binlog event to slave  线程已经从二进制日志读取了一个事件并且正将它发送到从服务器
    		Finished reading one binlog; switching to next binlog  线程已经读完二进制日志文件并且正打开下一个要发送到从服务器的日志文件
    		Has sent all binlog to slave; waiting for binlog to be updated 线程已经从二进制日志读取所有主要的更新并已经发送到了从服务器。线程现在正空闲，等待由主服务器上新的更新导致的出现在二进制日志中的新事件
    		Waiting to finalize termination 线程停止时发生的一个很简单的状态
    	slave
    		io thread (show processlist中command: connect)
    			Connecting to master     线程正试图连接主服务器
    			Checking master version  建立同主服务器之间的连接后立即临时出现的状态
    			Registering slave on master 建立同主服务器之间的连接后立即临时出现的状态
    			Requesting binlog dump  建立同主服务器之间的连接后立即临时出现的状态。线程向主服务器发送一条请求，索取从请求的二进制日志文件名和位置开始的二进制日志的内容
    			Waiting to reconnect after a failed binlog dump request 如果二进制日志转储请求失败(由于没有连接)，线程进入睡眠状态，然后定期尝试重新连接。可以使用--master-connect-retry选项指定重试之间的间隔
    			Reconnecting after a failed binlog dump request 线程正尝试重新连接主服务器
    			Waiting for master to send event 线程已经连接上主服务器，正等待二进制日志事件到达。如果主服务器正空闲，会持续较长的时间。如果等待持续slave_read_timeout秒，则发生超时。此时，线程认为连接被中断并企图重新连接
    			Queueing master event to the relay log 线程已经读取一个事件，正将它复制到中继日志供SQL线程来处理
    			Waiting to reconnect after a failed master event read 读取时(由于没有连接)出现错误。线程企图重新连接前将睡眠master-connect-retry秒
    			Reconnecting after a failed master event read  线程正尝试重新连接主服务器。当连接重新建立后，状态变为Waiting for master to send event
    			Waiting for the slave SQL thread to free enough relay log space 正使用一个非零relay_log_space_limit值，中继日志已经增长到其组合大小超过该值。I/O线程正等待直到SQL线程处理中继日志内容并删除部分中继日志文件来释放足够的空间
    			Waiting for slave mutex on exit 线程停止时发生的一个很简单的状态
    		sql thread (show processlist中command: connect)
    			Reading event from the relay log  线程已经从中继日志读取一个事件，可以对事件进行处理了
    			Has read all relay log; waiting for the slave I/O thread to update it 线程已经处理了中继日志文件中的所有事件，现在正等待I/O线程将新事件写入中继日志
    			Waiting for slave mutex on exit 线程停止时发生的一个很简单的状态




xtraBackup #https://www.percona.com/downloads/Percona-XtraBackup-LATEST/
	innobackupex --defaults-file=/data/mysql/mysql3307/my3307.cnf -S /tmp/mysql3307.sock -proot --stream=tar ./ | gzip -> `date +%F%H%M%S`.tar.gz
	mkdir 2019-03-26092718 && tar -zxvf 2019-03-26092718.tar.gz -C 2019-03-26092718/
	cd 2019-03-26092718/
	cat xtrabackup_binlog_info   # mysql-binlog.000181   12921798           ## mysql-binlog.000181 为备份到binlog文件名称，12921798 为备份到的position点
	innobackupex --apply-log ./
	innobackupex --defaults-file=/data/mysql/mysql3306/my3306.cnf --copy-back /root/2019-03-26092718/
	chown -R mysql:mysql /data/
	mysqld --defaults-file=/data/mysql/mysql3306/my3306.cnf &


perl -ne ‘m/^([^#][^\s=]+)\s*(=.*|)/ && printf(“%-35s%s\n”, $1, $2)’ /etc/mysql/my.cnf 美化my.cnf



set profiling = 1;
select * from mysql.user;
show profile;
set profiling = 0;

explain
字段
    id                  查询序号
    select_type
        simple          简单select,不使用uniion或subquery
        primary         最外面的select
        union           union中的第二个或后面的select
        dependent union union中的第二个或后面的select
        union result    union的结果
        subquery        子查询中的第一个select
        dependent subquery 子查询中的第一个select,取决于外面的查询
        derived         导出表的select(from子句的子查询)
    table               输出的行所引用的表
    partition
    type 联结类型,从优到此排序
        system          表仅有一行(系统表),这是const联结类型的特列
        const           表最多有一个匹配行,它将在查询开始使被读取.因为仅有一行,在这行的数据可被优化器剩余部分认为是常熟.
                        const表很快,因为之读取一次.
                        用于常数值比较primaryKey或unique索引的所有部分时
                        select * from t where pk=1;
                        select * from t where pk_part1=1 and pk_part2=2;
        eq_ref          对于每个来自前面的表的行组合,从该表中读取一行.
                        这可能是除了const外最好的情形.
                        它用在一个索引的所有部分被联结使用并且链接是unique或pk
                        可用于使用=操作符比较的带索引的列.比较值可以为常量或一个使用在该表前面所读取的表的列的表达式
                        select * from ref_t, other_t where ref_t.key_column = other_t.column;
                        select * from ref_t, other_t where ref_t.key_column_part1 = other_t.column and ref_t.key_column_part2=2;
        ref             对于每个来自于前面的表的行组合，所有有匹配索引值的行将从这张表中读取
                        如果联接只使用键的最左边的前缀，或如果键不是UNIQUE或PRIMARY KEY（换句话说，如果联接不能基于关键字选择单个行的话），则使用ref
                        如果使用的键仅仅匹配少量行，该联接类型是不错的
                        ref可以用于使用=或<=>操作符的带索引的列
                        select * from ref_t where key_column=expr;
                        select * from ref_t, other_t where ref_t.key_column = other_t.column;
                        select * from ref_t, other_t where ref_t.key_column_part1 = other_t.column and ref_t.key_column_part2=2;
        ref_or_null     该联接类型如同ref，但是添加了MySQL可以专门搜索包含NULL值的行。在解决子查询中经常使用该联接类型的优化
                        select * from ref_t where key_column=expr or key_column is null;
        index_merge     该链接类型使用了索引合并优化
                        key列包含了使用的索引的清单,key_len包含了使用的索引的最长的关键元素
        unique_subquery 该类型替换了下面形式的IN子查询的ref
                        v  in (select pk from t where some_exp) 
        index_subquery  类似于unique_subquery. 只适用于子查询的非唯一索引
                        v  in (select k_column from t where some_exp)  
        range           只检索给定范围的行，使用一个索引来选择行。key列显示使用了哪个索引。key_len包含所使用索引的最长关键元素。在该类型中ref列为NULL。
                        当使用=、<>、>、>=、<、<=、IS NULL、<=>、BETWEEN或者IN操作符，用常量比较关键字列时，可以使用range
                        select * from t where k=10;
                        select * from t where k between 10 and 20;
                        select * from t where k in (10,20,30)
                        select * from t where k_part1=1 and k_part2 in (10,20,30)
        index
        all             对每个来自先前表的行的组合,进行完整的表扫描
    possible_keys       可以使用哪个索引. 如果该列为NULL,则没有相关的索引.
    key                 实际使用的哪个索引. 如果该列为NULL,则没有相关的索引.
                        可以强制使用force index, use index, 或 ignore index.
    key_len             实际使用的键的长度. 如果key为null,则长度为null.
                        通过key_len可以确定实际使用一个多字段为index的哪些部分
    ref                 显示选择使用其他表的哪些列或常数与key
    rows                显示执行query时必须检查的行数
    filtered            显示结果返回多少行
    extra               详细信息
        distinct        发现一行后停止扫描
        not exists 
        range checked for each record
        using filesort   order by
        using index
        using temporary  需要创建临时表来容纳结果,如查询包含可以按不同情况出列的group by和order by
        using where
        using sort_union(), using union(), using intersect()
        using index for group_by











cat >> ~/.ssh/config << EOF
Host gitlab.com
    ProxyCommand=nc -X 5 -x 127.0.0.1:7778 %h %p
    HostName gitlab.com
    User git
EOF
git config --global core.compression=0

git clone --depth=1 git://github.com:example/awesome-project
git fetch --unshallow
git pull --all

https://www.avtb7788.com/56164/%E7%A4%BE%E4%BA%A4%E5%B9%B3%E5%8F%B0%E9%9D%9E%E5%B8%B8%E7%81%AB%E7%9A%84%E7%BD%91%E7%BA%A2%E9%9B%AA%E4%B9%B3%E6%AD%A3%E5%A6%B9%E7%B3%BB%E5%88%97%E6%9E%81%E5%93%81%E8%B6%85%E7%BA%A7%E5%B7%A8%E4%B9%B3%E8%9B%AE%E8%85%B0%E7%BF%98%E8%87%80%E7%99%BD%E8%99%8E%E5%AB%A9%E7%A9%B4%E5%8F%AB%E5%A3%B0%E5%8F%88%E7%94%9C%E4%B9%B3%E4%BA%A4%E6%89%93%E7%82%AE%E5%AE%85%E7%94%B7%E6%89%93%E9%A3%9E%E6%9C%BA%E7%A5%9E%E5%99%A8/



激活码  https://www.41sh.cn/?id=101
E70JHCOV2H-eyJsaWNlbnNlSWQiOiJFNzBKSENPVjJIIiwibGljZW5zZWVOYW1lIjoi5bGx5Lic55CG5bel5aSn5a2mIiwiYXNzaWduZWVOYW1lIjoiIiwiYXNzaWduZWVFbWFpbCI6IiIsImxpY2Vuc2VSZXN0cmljdGlvbiI6IkZvciBlZHVjYXRpb25hbCB1c2Ugb25seSIsImNoZWNrQ29uY3VycmVudFVzZSI6ZmFsc2UsInByb2R1Y3RzIjpbeyJjb2RlIjoiSUkiLCJwYWlkVXBUbyI6IjIwMjEtMDItMTgifSx7ImNvZGUiOiJBQyIsInBhaWRVcFRvIjoiMjAyMS0wMi0xOCJ9LHsiY29kZSI6IkRQTiIsInBhaWRVcFRvIjoiMjAyMS0wMi0xOCJ9LHsiY29kZSI6IlBTIiwicGFpZFVwVG8iOiIyMDIxLTAyLTE4In0seyJjb2RlIjoiR08iLCJwYWlkVXBUbyI6IjIwMjEtMDItMTgifSx7ImNvZGUiOiJETSIsInBhaWRVcFRvIjoiMjAyMS0wMi0xOCJ9LHsiY29kZSI6IkNMIiwicGFpZFVwVG8iOiIyMDIxLTAyLTE4In0seyJjb2RlIjoiUlMwIiwicGFpZFVwVG8iOiIyMDIxLTAyLTE4In0seyJjb2RlIjoiUkMiLCJwYWlkVXBUbyI6IjIwMjEtMDItMTgifSx7ImNvZGUiOiJSRCIsInBhaWRVcFRvIjoiMjAyMS0wMi0xOCJ9LHsiY29kZSI6IlBDIiwicGFpZFVwVG8iOiIyMDIxLTAyLTE4In0seyJjb2RlIjoiUk0iLCJwYWlkVXBUbyI6IjIwMjEtMDItMTgifSx7ImNvZGUiOiJXUyIsInBhaWRVcFRvIjoiMjAyMS0wMi0xOCJ9LHsiY29kZSI6IkRCIiwicGFpZFVwVG8iOiIyMDIxLTAyLTE4In0seyJjb2RlIjoiREMiLCJwYWlkVXBUbyI6IjIwMjEtMDItMTgifSx7ImNvZGUiOiJSU1UiLCJwYWlkVXBUbyI6IjIwMjEtMDItMTgifV0sImhhc2giOiIxNjc5MTgwMy8wIiwiZ3JhY2VQZXJpb2REYXlzIjo3LCJhdXRvUHJvbG9uZ2F0ZWQiOmZhbHNlLCJpc0F1dG9Qcm9sb25nYXRlZCI6ZmFsc2V9-qlgtO4xVGHX/r45fIKMaR6B9pWQtucrCYVsz0o00crcAiYN1k/kSMygggYl187B0u0jeXQCe4BmQIItKL79x6NwoPn43inreVhZ88f4+Cbl+V/KGeAYeybon+7YoTs8FY4+31ANW/LwBPxkPnlErxYdQ6oc/k6mnxIOm5Nf8WjKRfYYIl5Bhmdt1gHMGgFsocCcTLLiqDUGEcPj5tUIJXwwYaeKAR3YGXm/P73QpnYR/BcGaodBN3jprQRxsS5Ia5y06rrDAJcPSZuttAFpAit/4o/gq2XzhrjaBCtOMxNzk3XEAT82glTlWQOQx6KnRq6D7WUXzd81g44aP+Dca5Q==-MIIElTCCAn2gAwIBAgIBCTANBgkqhkiG9w0BAQsFADAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBMB4XDTE4MTEwMTEyMjk0NloXDTIwMTEwMjEyMjk0NlowaDELMAkGA1UEBhMCQ1oxDjAMBgNVBAgMBU51c2xlMQ8wDQYDVQQHDAZQcmFndWUxGTAXBgNVBAoMEEpldEJyYWlucyBzLnIuby4xHTAbBgNVBAMMFHByb2QzeS1mcm9tLTIwMTgxMTAxMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAxcQkq+zdxlR2mmRYBPzGbUNdMN6OaXiXzxIWtMEkrJMO/5oUfQJbLLuMSMK0QHFmaI37WShyxZcfRCidwXjot4zmNBKnlyHodDij/78TmVqFl8nOeD5+07B8VEaIu7c3E1N+e1doC6wht4I4+IEmtsPAdoaj5WCQVQbrI8KeT8M9VcBIWX7fD0fhexfg3ZRt0xqwMcXGNp3DdJHiO0rCdU+Itv7EmtnSVq9jBG1usMSFvMowR25mju2JcPFp1+I4ZI+FqgR8gyG8oiNDyNEoAbsR3lOpI7grUYSvkB/xVy/VoklPCK2h0f0GJxFjnye8NT1PAywoyl7RmiAVRE/EKwIDAQABo4GZMIGWMAkGA1UdEwQCMAAwHQYDVR0OBBYEFGEpG9oZGcfLMGNBkY7SgHiMGgTcMEgGA1UdIwRBMD+AFKOetkhnQhI2Qb1t4Lm0oFKLl/GzoRykGjAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBggkA0myxg7KDeeEwEwYDVR0lBAwwCgYIKwYBBQUHAwEwCwYDVR0PBAQDAgWgMA0GCSqGSIb3DQEBCwUAA4ICAQAF8uc+YJOHHwOFcPzmbjcxNDuGoOUIP+2h1R75Lecswb7ru2LWWSUMtXVKQzChLNPn/72W0k+oI056tgiwuG7M49LXp4zQVlQnFmWU1wwGvVhq5R63Rpjx1zjGUhcXgayu7+9zMUW596Lbomsg8qVve6euqsrFicYkIIuUu4zYPndJwfe0YkS5nY72SHnNdbPhEnN8wcB2Kz+OIG0lih3yz5EqFhld03bGp222ZQCIghCTVL6QBNadGsiN/lWLl4JdR3lJkZzlpFdiHijoVRdWeSWqM4y0t23c92HXKrgppoSV18XMxrWVdoSM3nuMHwxGhFyde05OdDtLpCv+jlWf5REAHHA201pAU6bJSZINyHDUTB+Beo28rRXSwSh3OUIvYwKNVeoBY+KwOJ7WnuTCUq1meE6GkKc4D/cXmgpOyW/1SmBz3XjVIi/zprZ0zf3qH5mkphtg6ksjKgKjmx1cXfZAAX6wcDBNaCL+Ortep1Dh8xDUbqbBVNBL4jbiL3i3xsfNiyJgaZ5sX7i8tmStEpLbPwvHcByuf59qJhV/bZOl8KqJBETCDJcY6O2aqhTUy+9x93ThKs1GKrRPePrWPluud7ttlgtRveit/pcBrnQcXOl1rHq7ByB8CFAxNotRUYL9IF5n3wJOgkPojMy6jetQA5Ogc8Sm7RG6vg1yow==


D:\fjy\code\go\src\github.com\ethereum\go-ethereum\miner\miner.go  Start()

D:\fjy\code\go\src\github.com\ethereum\go-ethereum\internal\web3ext\web3ext.go 28 miner minerjs