我的google账号  fujiyong2000@gmail.com  yaxin


WIFI 13622228504
ftp \\192.168.1.182     user:user
git fu_ji_yong fujy6789
bug fu_ji_yong pass@2019

google youtube  fujiyong2000@gmail.com  sr


测试机	121.9.227.91	22124	root	pass@2019
数据库	192.168.1.102	5432	postgres	pass@2018
ipfs1	192.168.1.106	22	root	13622228504
ipfs2	192.168.1.178	22	root	13622228504
ipfs3	192.168.1.127	22	root	13622228504
以太坊1	120.79.97.248	22	root	SuperVDS*2020@2805
以太坊2	120.78.173.134	22	root	Svdsdev2019*$()
以太坊3	39.108.104.133	22	root	Svdsdev2019*$()
测试机  192.168.1.128  root/orangepi  orangepi  



goland 
    改变背景颜色   Editor -> Color Schema -> General -> Text -> Default text -> Backgroud
    代码模板快捷   Editor -> Live Templates
    文件头自动注释 Editor -> File and Code Templates -> include 
    注释对其代码
    注释空格       Editor -> Code Style -> Go -> Other
    =对其代码
    import group  Editor -> Code Style -> Go -> import



git clone http://fu_ji_yong:fujy6789@git.isecsp.com/frank/ocelot-api-gateway.git

zsh操作指南
http://www.skywind.me/blog/archives/2060

S*vds%%2020*()02191848$



alias | grep -E "b\."
echo $DIFOSS_ENV_BASE/.privacy/__init__.sh
b.privacy


https://www.npmjs.com/package/windows-build-tools  npm安装windows编译工具

linux命令  column -t
            for i in 0 1 2 3 4 5 6 7 8 9; do iostat | column -t; sleep 1; done
            for i in {0..9} ; do iostat 1 1 | column -t; sleep 1; done
            vmstat 1 10 | while read line
            do
                echo "$line" | column -t
            done

            在终端直接执行在a.sh中定义的函数say():  chmod +x a.sh && source a.sh && say
            last     最后登录信息,每个用户可以多行
            lastlog  最后各个用户的登录信息,每个登录用户一行

软件 web        hbuilder 
     数据库客   dbeave  pgadmin
     cmder     设置分屏
     markdonw  typora
     截图       snipaste

     nodejs进程管理  pm2  process manager

     mac      dash参考文档


https://www.cnblogs.com/the-tops/p/7600985.html


             符号位     指数位     尾数位
    float    1          8         23
    double   1          11        52

    mkdir -pv a/b/c
    realpath $file
    ssh user@hostname/ip

    在命令行上参数上有些--符号,表示--跟在--之后的就不再是不确定参数,即参数不再是变量,而是确定量
    --             indicates the unambiguous end of options    #man awk 

    vi  set cursorline
        set cursorcolumn   https://github.com/nathanaelkane/vim-indent-guides





mist 以太坊节点/钱包
metamask chrome插件方式的以太坊节点、钱包， 可以连接到本地或实际的
truffle  以太坊开发框架，内置了只能合约的编译 链接 部署
remix   智能合约开发环境
whisper 集成进以太坊的非实时消息系统

ganache 在公链上测试部署dapp或只能合约需要消耗gas， 使用ganache可以创建本地区块链


npm install -g truffle  && truffle --version 


git clone http://fu_ji_yong:fujy6789@git.isecsp.com/frank/ocelot-api-gateway.git



npm
    npm init
    npm adduser && npm publish

    npm install [-g] $pkg@tag/version
    npm uninstall $pkg
    npm update [-g] $pkg
    npm search $pkg

    npm list -g  //查看安装的全局包的版本
    npm list $pkg //查看某个包的版本

    npm cache clear 清空本地缓存，用于使用相同的版本号发布

    npm unpublish $pkg@version 取消某版本的发布

    npm install -g cnpm --registry=https://registry.npm.taobao.org //淘宝的npm镜像

    npm run 可以查看package.json里有哪些可以通过npm run start|stop|test|dev|debug等命令

nodejs
    创建工程 cd projDir && npm init 会产生package.json文件
    添加依赖库  在package.json中的dependencies中添加 然后npm install 就可
    启动程序
        命令行 node --use_strict a.js  //让node为所有的js开启strict模式  这也是vscode launch.json文件中的配置
        命令行 npm start               //在package.json中配置"scripts": {"start": "node app.js"}

a.js
    // @ts-check 或者在jsconfig.json中添加{"compilerOptions": {"checkJs": true},"exclude": ["node_modules"]}
    //npm i @types/第三方库名  //为第三方库安装类型声明文件.d.ts

    数据类型
        bool    0 NaN null undefined
        Number  NaN  isNaN(NaN)
        string  多行时``  +  模板字符串`${x}`                    length  下标引用[0]/substring()      indexOf(str)

        array  [] new Array()  元素类型可以不同, 可以越组访问/赋值 length  下标引用[0]/slice([s[,e])    indexOf(ele)  push(...)/pop unshift(...)/shift() sort() reverse() concat(...,[1,2]) join('-') splice(s,e[,ele...])
        map       new map([[k1,v1],[k2,v2]]) has(k) get(k) set(k,v) delete(k)
        set       new set([v1,v2])                         add(v1)  delete(v1)

        Object  访问/赋值/新增o.field  删除delete o.field   判断field in o o.hasOwnProperty('field')

        null
        undefined

    运算符
        == ===
        if()else if(){}else{} for(;;)  while(){}  do{}whle()

        for(var i in arr){} //获取数组的索引i
        for(var f in o){} //获取所有属性f

    iterable  
        ES5.1
            forEach(function(ele, index, x){
                //arr ele index arr
                //set ele ele   set
                //map v   k     m
            })

        ES6
            for(var v of arr){}
            for(var kv of map){kv[0] kv[1]}
            for(var v of set){}

    解构赋值ES6
        数组
            let [x, [y, z]] = ['hello', ['JavaScript', 'ES6']]
            let [, , z] = ['hello', 'JavaScript', 'ES6']
        对象
            var person = {
                name: '小明',
                age: 20,
                gender: 'male',
                passport: 'G-12345678',
                school: 'No.4 middle school',
                address: {
                    city: 'Beijing',
                    street: 'No.1 Road',
                    zipcode: '100001'
                }
            };
            var {name, age, passport, single=true} = person //single有默认值true
            var {name, address: {city, zip}} = person;//address不是变量，而是为了让city和zip获得嵌套的address对象的属性
            let {name, passport:id} = person;// 注意: passport不是变量，而是为了让变量id获得passport属性:

    Function
        不定参数关键字arguments,rest
            function foo(a, b, ...rest){ //ES6引入了rest，表示其余的参数数组，当少参数时数组为null
                console.log(arguments.length) 
            }

        apply/call
            function.apply(obj, []) //obj为function中this的指向， 第二个参数为function的入参数组
            function.call(obj,...) //obj为function中this的指向， 第二个参数为function的入参数组的顺序传入

        高阶函数Hight-Order function： 函数的形参可以接受一个参数指针
            arr.Map(x=>{return x*1})           //对数组对象arr中的每个元素都调用箭头函数并返回新数组
            arr.reduce((x,y)=>{return x + y})
            arr.filter(function(ele){return true;}); //返回为true的
            arr.filger(function(ele, index, self){return self.indexOf(ele) === index;}) //数组去重
            arr.sort(function(x,y){if(x>y){return 1}else if(x<y){return -1}else{return 0;}}) //默认将ele转化为字符串按ascii排序
            arr.every(function(x){return x>1;}) //是否都>1
            arr.find(function(x){return x>1;})  //查询是否有大于1的元素并返回元素
            arr.findIndex(function(x){return x>1;}) //查询是否有大于1的元素并返回元素索引
            arr.forEach(console.log)
    异常
        try{

        }catch(e){
            console.log(e)
            throw new error("my err")
        }finally{

        }

    闭包

    产生器
        function* f(){yield x; return}
        var gen = f(5)  //产生一个generator
        gen.next()      //返回一个对象{value:x, done:true/false} x就是yield产生的 或 return返回的；  当是return直接返回时是value是undefined
        for (var x of f(5))

    标准对象
        Date  new Date()  Date.now()
        Json  Json.stringify(o,["f1", "f2"], '\t')  JSON.stringify(o, (k,v){}, '\t')  JSON.stringify(o)//优先调用o的toJson()成员函数
              JSON.Parse(o,(k,v){return v})
        RegExp

    面向对象
        var xiaoming = {}  xiaoming.__proto__ = Student  //xiaoming继承了Student

        var xiaoming = Object.create(Student)//根据Student原型创建对象 xiaoming有Student所有属性但为null  xiaoming.__proto__ === Student

        function Student(props){
            this.name = props.name
            this.grade = props.grade
            this.hello = function(){}  //每个对象都有一个hello函数
        }
        Stdent.prototype.hello = function(){} //在prototype中定义，则所有对象共享一个hello函数
        var xiaoming = new Student() //使用函数必须new默认返回this，否则返回undefined

        class ES6 需要Babel工具从class转换为prototype
            Class Base{
                constructor(name){
                    this.name = name
                }

                hello(){   //没有function
                    console.log(this.name)
                }

                this.byebye = function(){}
            }
            class Derived extends Base{
                constructor(name, age){
                    super(name)
                    this.grade = grade
                }

                myGrade(){}
            }
    








    作用域
        全局
            //在 HTML 中, 全局作用域是针对 window 对象
            //在 JavaScript 中, 全局作用域是针对 JavaScript 环境
            var x = 10    //使用 var 关键字声明的全局作用域变量属于 window 对象, 可以使用 window.carName 访问变量
            let x1 = 20   //使用 let 关键字声明的全局作用域变量不属于 window 对象, 不能使用 window.carName 访问变量
            {
                var x2 = 100 //不在函数体内，即使在{}内var修饰的仍然是全局变量
            }
            function foo(){
                y = 20       //函数体内没有var的一定是全局变量
            }
        块局
            {
                let x = 10
            }
            funtion foo(){
                var z = 1   //函数体内有var修饰的是局部变量
            }

    变量重置


    变量提升
        var可以  let不行



    


新建工程
    新建目录，切换到目录然后npm init, 产生package.json文件
引用
    引用具体的文件b.js中的export
        //export module.exports = {f1, f2}

        // var b = require("./b/b.js")
        // b.f1()
        // b.f2()

        module.exports = {
            k : require("./b.js")
        }

        var x = require("./b")
        x.k.f1()
        x.k.f2()
引用第三方库
    安装npm install -g date-fmt
调试
    点击最左边的调试，然后右边的setting，在编辑器上方弹出的地方选择node.js，然后产生launch.json文件，在里面的"program": "${workspaceFolder}\\a.js"，
    在具体的文件里行号左边点击添加断点





全屏  F11
sidebar ctrl+b
move up/down  alt+up/down

copy up/down  alt+shit+up/down
format        alt+shift+F




move line up/down       alt+shift+up/down
move statement up/down  ctrl+shift+up/down


浏览器  ctrl+shift+B



:%s/^\([A-Z]\)/#\1/g


https://www.ibm.com/developerworks/cn/linux/l-lpic1-v3-102-5/index.html
https://segmentfault.com/a/1190000011200461



/root/anaconda-ks.cfg
initial-setup-ks.cfg
original-ks.cfg        [anəˈkändə]  水蟒  kickstart 启动


查看文件系统类型
    cat /etc/fstab

    lsblk -f               #显示块设备
    blkid /dev/sda3        #打印查找块设备属性
    
    df -T -h               #只显示已挂载的,不显示未挂载的
    file -sL /dev/sda3    #标识文件类型 -s标志启用读取块或字符文件， -L启用以下符号链接

    parted && print list   #parted分区软件
    fsck -N /dev/sdb1      #打印和检查fs
    mount  | grep ^/dev

resize2fs更改文件系统的大小


ag advanced grep
fzf  
mycli             #mysql彩色客户端
shellchekc  a.sh  #检查shell语法

axel -n 20 $addr    多线程下载
lynx  --dump http://www.baidu.com  终端浏览器
tig git https://www.jianshu.com/p/e4ca3030a9d5
multitail
script/scriptreplay  终端会话录制并回放
top htop glances

zeal  dash
everything listary
Mockoon
chocolatey homebrew  babun


https://blog.csdn.net/u010625000/article/details/44455023


ag
    安装
        apt search silver
        apt search silver | grep search
        apt insall silversearcher-ag


fzf  fuzzy find 模糊查询 媲美vim的CtrlP插件
    安装
        apt install fzf 

        git clone --depth 1 https://github.com/junegunn/fzf.git ~/.fzf
        cd ~/.fzf && git pull && ./install

    使用
        keybinding bash zsh fish
            Ctrl-T  查找粘贴目录下的文件名或目录名到命令行
                vi Ctrl-T
                cd Ctrl-T
            Ctrl-R  查找粘贴选中的历史命令到命令行
                Ctrl-R  再按一次则在时间和相关性之间排序历史命令
            Ctrl-c  切换目录 == cd  + Ctrl-T
        autocomplete bash zsh
            kill -9/15 <tab>  然后tab或shift-Table选中

            vi $path/**<Tab>   vim $(fzf)
            cd $path/**<Tab>   cd $(find * -type d | fzf) 

            ssh **<tab>
            telnet **<tab>

            unset **<TAB>
            export **<TAB>
            unalias **<TAB>

        git分支
	        git checkout $(git branch -r | fzf)

        预览窗口  fzf --preview 'cat {}'

    快捷键 在输出交换窗口
        键盘 Ctrl-j/k/n/p   单选模式Enter选中     多选模式-m下Tab和shift-Table选中
        鼠标 滚轮滚动        单选模式双击选中      多选模式-m下Shift-Click或shift-scroll多选









apt install alien #可以在rpm dpkg deb之间转换
alien *.rpm
alien -r *.deb

*.rpm
*.src.rpm  包含未编译的原始代码,所以可以修改编译参数经过编译后才可以安装
            rpmbuild --rebuild    *.rpm   #build binary package from <source package>
            rpmbuild --recompile  *.rpm   #build through %install (%prep, %build, then install) from <source package> 

rpm格式
    Lead    公共
    signature
    header  软件包信息
    archive 文件列表

rpm -qil rpmdevtools

rpmdev-setuptree                        #与rpmdev-wipetree刚好相反
rpmdev-newspec -type python -o a.spec   #rpmdev-newspec --help 模板来自于/etc/rpmdevtools/spectemplate-*.spec 
rpmlint a.spec  &&  rpmlint -i a.spec   #检查spec语法错误    rpmbuild -E '%{_bindir}' tos.spec
rpmdev-newinit                 a.init   #制作服务控制脚本

目录结构
    SOURCES  *.tar.gz
    SPECS    *.spec

    BUILD               #config make
    BUILDROOT           #make install 产生x86_64

    RPMS    *.rpm       #将BUILDROOT打包
    SRPMS   *.src.rpm   #将BUILDROOT打包

rpmbuild
    常用选项
        --dbpath  ""             #默认值/var/lib/rpm
        --root    ""             #根目录

    编译前
        --nobuild                 #检出spec语法

    编译选项
        -bp %prep                 #解压缩并patch
        -bc       %build          #make
        -bi              %install #install 

        -bb                       #install之后只生成rpm          build binary package only from <specfile>        rpm
        -bs                       #           只生成src.rpm   
        -ba                       #                             build source and binary packages from <specfile> rpm src.rpm

        --buildroot ""
        --target i386 | i686 | x86_64
        --rmsource                #在build之后删除src.rpm 
        --rmspec                  #在build之后删除spec文件

    编译后
        --clean                  #删除build时的目录 BUILD/wget-1.14


spec
    定义变量  %define varname "xxx"
    引用变量  %{var}
    执行脚本  %( echo %{var} | sed 's///g' )
    定义宏    %global date 2012-02-08

    各种宏   cat /usr/lib/rpm/macros


    comments
    tags 变量定义
        包命名
            Name               不能含空格
            Version            不能含-
            Release
        描述  rpm -qpi *.rpm
            %description:      若以空格开始则逐字显示; 若不是以空格开始则对其段落划分 在变量定义中唯一个以%开头的变量
            Summary:  只能一行
            CopyRight: GPL 
            Lisence:  GPLv2 with exceptions
            Distribution:    软件集合
            Icon:            软件图标
            Vendor:          组织机构
            URL: 
            Group:
            Packager:    发包人的联系方式或公共的邮件列表
        依赖 rpm -qpi  --requires
            Provides     该包提供什么资源  既可以是一个真实存在的包,也可以只是一个虚拟的东西(仅仅是一个字符串)
            Requires     该包依赖哪些包 不支持不等于
                         = 1.2-2  >= > = <= < 
            conficts     该包与哪些包冲突
            serial       version之外的另外一种版本比较变量
            autoreqprov  自动生成软件依赖的标志位autorequire/autoprovide 取值为yes或者no,也可用0或1表示 默认值为yes或1 一般不用操作
        平台操作系统
            ExcludeArch: sparc alpha   不能在某CPU平台
            ExclusiveArch: aparc alpha 只能在某CPU平台
            ExcludeOS:  linux irix     不能在某OS
            ExclusiveOS: linux irix    只能在某OS
        目录
            prefix:  /opt  %files中声明为/opt/xx 在命令行的--prefix的优先级最高
            BuildRoot:  %{_topdir}/%{name}-%{version}-root 
        源码补丁
            Source:    源代码名称和存储位置
                Source:      #Source与Source0效果相同
                Source1:
                SourceN:
            NoSource:  从源代码中忽略一个或多个文件
            Patch:     标识源码的一个补丁文件
                Patch0:
                PatchN:
            NoPatch:   忽略一个或多个补丁
    script
        编译时
            %prep   为编译代码准备 1创建顶级目录 2解压源码到build目录 3如果有补丁的话打补丁

            %build   #####最多进行到configure && make 绝对不可能make install
            %ifarch cond1 cond2
                ./configure --with-ss=openssl
            %ifnarch cond1 cond2
            %ifos os1 os2 
            %ifnos os1 os2
                make RPM_OPT_FLAGS="$RPM_OPT_FLAGS -I . "
            %else
            %endif  

            %install  ####这儿才可以make install
            if [-d %{buildroot}]; then
                rm -rf %{buildroot}                              ← 清空下安装目录，实际会自动清除
            fi
            %{__install} -Dp -m0755 contrib/init.d %{buildroot}%{_initrddir}/foobar          
            make install prefix=$RPM_BUILD_ROOT/usr
            %{__install} -d %{buildroot}%{_sysconfdir}/foobar.d/   #对make install的目录结构进行修正,务必修正好 这样在%files可以直接打包

            %clean 
            [ "$RPM_BUILD_ROOT" != "/" ] && rm -rf $RPM_BUILD_ROOT
        安装到文件系统前/从文件系统卸载时
            %pre     第一个参数为1说明是初次安装,为2时是版本升级  hook默认使用bash来执行,但也可使用参数-p自定义
                %pre -p /usr/bin/perl 
                if ( $ARGV[0] == 1 ) {
                    print "preparing for init install\n"
                }
                elsif ( $ARGV[0] == 2 ) {
                    print "prepare to upgrade software\n"
                }
                添加group/user
            %post    第一个参数为1说明是初次安装,为2时是版本升级
                systemctl reload nginx.service
            %preun   第一个参数为0说明是卸载,为1时是版本升级
            %postun  第一个参数为0说明是卸载,为1时是版本升级

            升级流程
                执行新版本的%pre 
                安装新版的文件列表
                执行新版本的%post

                检查所有其他rpm包的triggerin触发器,如果有被N的安装触发,就执行相应脚本
                执行N的所有triggerin触发器
                执行N的所有triggerun触发器

                检查所有其他rpm包的triggerin触发器,如果有被N的卸载触发的,就执行相应的脚本

                执行老版本的%preun
                自动删除老版本中没有被新版本覆盖的文件
                执行老版本的%postun
        校验时          用rpm命令校验已安装的rpm时执行 rpm -qpVv *.rpm
            %verifyscipt  因为rpm默认会校验文件列表,所以不用去校验,因此这儿可以做点自己想做的 默认不会执行%verifyscipt,除非使用verbose模式进行校验
            echo "verify aaa" 
        触发器Trigger   被一定的条件(如其他rpm安装或卸载)触发执行
            B%triggerin A包安装时,如果B包已经安装,则触发该触发器
            B%triggerun A包安装时,如果B包已经卸载,则触发该触发器
            B%triggerpostun A包安装时,如果B包被卸载,则卸载完成后触发该触发器

            eg:
                %triggerin -p /usr/bin/perl -- ruby   #通过--符号指定被监控的包
                # print "ruby already installed"
    Macro 宏
        %setup      解压缩源码  多数情况下不用任何选项
            -n $name 设置编译目录名默认是name-version
            -c $build_dir_name  创建build目录并进入该目录
        %patch      给解压后的源码打补丁
    files 文件列表指令Directives 设置与检查文件/目录/软件包的属性 rpm -qf /etc/x.conf
        文件相关
            %doc    用来标识一个文件是文档 安装后会被rpm数据库记录 默认安装目录是/usr/doc 可以通过修改rpmrc中的defaultdocdir变量的值来修改
            %config 用来标识一个文件是配置文件 设置了noplace属性后 rpm在升级时就不会被覆盖 在卸载时会被保存为x.save  rpm -qp *.rpm --configfiles
                %config(noreplace) /etc/x.conf
            %attr   用来修改文件属性(默认权限 属主 属组)指令
                %attr (755, root, root) foo.bar
            %verify 校验指令
        目录相关
            %docdir /absolute-dir-path  用于指定配置文件目录
            %dir    /absolute-dir-path  用于只将目录打包  默认将目录下的文件及文件夹打包

        %package -n $new_sub_package_name 定义子包名,默认命名是"基础包-子包"格式

        eg
            %files                   ######## 对%install中的目录进行摘选
            %defattr (-,root,root,0755)                         ← 设定默认权限
            %attr(755, root, root) %{_sbindir}/mysqld
            %config(noreplace) /etc/my.cnf                      ← 表明是配置文件，noplace表示替换文件
            %attr(644, root, root) %{_mandir}/man8/mysqld.8*    ← 分别是权限，属主，属组
            %doc %{src_dir}/Docs/ChangeLog                      ← 表明这个是文档



全局配置      /etc/yum.conf                设置如何管理源repo
源配置文件    /etc/yum.repos.d/*.repo      源的配置文件
本地rpm数据库 /var/lib/rpm/_db.*           存储系统已安装了哪些rpm   /var/lib/yum
本地缓存      /var/cache/yum/*             存储索引文件和rpm文件
插件          /usr/lib/yum-plugins/fastestmirror.py       fastestmirror对每个mirror进行测速,然后根据连接速度排序站点速度,选择下载速度最快的站点下载
插件配置文件   /etc/yum/pluginconf.d/fastestmirror.conf
日志          /var/log/yum.log 


rpmbuild -ba main.spec 
yum install *.rpm 
rpm -ql main 
rpm -qi main 


cd BUILD
tar -zxvf $Source.tar.gz      #$Source来自*.spec中的Source
%build                        #执行spec中的%build
rm -rf   $Name-$Version &&    #Name和Version来自*.spec 
mkdir -p $Name-$Version 
%install                      #执行spec中的%install
打包


索引读写分离
缓存
镜像
智能DNS和多机房容灾


/root/anaconda-ks.cfg
initial-setup-ks.cfg
original-ks.cfg        [anəˈkändə]  水蟒  kickstart 启动


查看文件系统类型
    lsblk -f               #显示块设备
    cat /etc/fstab
    df -T -h               #只显示已挂载的,不显示未挂载的
    parted && print list   #parted分区软件
    fsck -N /dev/sdb1      #打印和检查fs
    blkid /dev/sda3        #打印查找块设备属性
    mount  | grep ^/dev
    file -sL /dev/sda3    #标识文件类型 -s标志启用读取块或字符文件， -L启用以下符号链接

    fdisk -l 只能列出硬盘的分区表、容量大小以及分区类型，但看不到文件系统类型


cal [[[day] month] year]

tmux 配置管理工具oh my tmux  set -g mouse off改为on
ag advanced grep
fzf  vim $(fzf)        fuzzy finder
	 cd $(find * -type d | fzf) 
	 git checkout $(git branch -r | fzf)
shellchekc  a.sh  检查shell语法
mycli mysql彩色客户端
axel -n 20 $addr    多线程下载
tig git https://www.jianshu.com/p/e4ca3030a9d5
multitail
script/scriptreplay  终端会话录制并回放
top htop glances atop
lynx  elinks 终端浏览器
tldr  too long don't read  #查看命令常用语法     https://www.yangxingzhen.com/
busybox top --help         #查看命令简短说明
man中文参考手册
cmder 
zeal/dash 帮助手册
cloc 统计代码

keepalived 高可用的保证工作在347层
Layer3： 发送ICMP报文，查看ip是否能ping通
Layer4： 查看端口port是否能telnet通
Layer：  根据用户自定义的协议检查是否正常  

haproxy 重点在proxy









https://blog.csdn.net/u010625000/article/details/44455023


全部摘抄 http://www.berlinix.com/gdb.html
http://www.docin.com/p-245963860.html
https://developer.apple.com/library/mac/#documentation/DeveloperTools/gdb/gdb/gdb_9.html  
http://www.douban.com/note/65837435/

gdb的配置文件是.gdbinit.就如vi的.vimrc.

break       b
delete      d
disassemble disas
info        i
registers   r
只有break和watch命令支持if，catch目前暂不支持if.


0、写在前头
产生core：              
                            limit -c                             #查看
                            limit -c unlimited/1024*1024*1024    #设置，防止消耗内存大的进程产生过大的coredump
配置     
                            kernel.core_pattern=/var/core/%t-%e-%p-%c.core   #cat /etc/sysctl.conf
                            kernel.core_uses_pid=0                           #若为1，即在core文件后加上pid，但上面我们已经加上了pid了
                            sysctl -p
编译                    <Esc>:make {arguments}  #编译代码
                           <Esc>:gr[ep] main *.c     #
遍历编译错误             http://man.chinaunix.net/newsoft/vi/doc/help.html 查找    quickfix.txt文档    
                            http://man.chinaunix.net/newsoft/vi/doc/usr_30.html#usr_30.txt
                           <Esc>:cl[ist]                          #只有那些含有文件名或行数的错误信息才会被显示。vim假定你对其他信息不感兴趣
                           <Esc>:c[list]! [from][,[to]]           #查看所有的make的信息,只需在上述命令上加！
                           <Esc>:cfir[st]                         #将光标移动到第一个错误
                           <Esc>:cl[ast]                          #将光标移动到最后一个错误
                           <Esc>:cp[revious]                      #将光标移动到上一个错误
                           <Esc>:cN[ext]                          #将光标移动到下一个错误所在的行
			       <Esc>:cc                              #有时空间不够，vim会缩短出错信息。如果想查看详细信息
                           <Esc>:cc 3                             #将光标移动到第三个错误
                           <Esc>:cope[n] [height]                 #打开一个窗口显示当前的错误列表.默认为10行高。一般位于底端。如果有垂直分割，会位于最右边窗口的最下边。
                           <Esc>:ccl[ose]                         #关闭quickfix窗口
                           <Esc>:cw[indow] [height]               #当存在可以识别的错误时，打开此窗口。如果该窗口已经打开且没有可以识别的错误，则将此窗口关闭

1、启动调试
gdb ./prog                                  #debug from start
gdb ./prog pid                              #debug running prog
gdb ./prog core                             #debug core file

server：gdbserver host:port --attatch PID
        gdbserver clientIP:serverPort Prog
client：gdb Prog
        (gdb)target remote serverIP:serverport
        (gdb)list/break
        (gdb)continue/c                    #不能run因为Prog已经在server上run了
        (gdb)以后如常

2、gdb shell 命令
宏
(gdb)info macro macro-name
(gdb)macro expand macro-name                #展开宏         http://blog.chinaunix.net/space.php?uid=23629988&do=blog&id=3053595
                                                            默认级别是-g2，简称-g,此时不能expand macro，需要-g3,产生更多的调试信息
                                                            对于单个文件，可以采取预编译 g++ -E test.c > test.e，查看宏定义，include文件
加载
(gdb)file [/path/to/]$(prog)                #加载prog符号文件即加载应用程序
(gdb)info files
(gdb)set args $(argv[1]) $(argv[2])         #设置应用程序参数    
(gdb)show args
(gdb)info args
(gdb)path <dir>                             #程序的运行路径
(gdb)show path                              #查看程序的运行路径
(gdb)set environment varname[=value]        #设置环境变量
(gdb)show environment [varname]             #查看环境变量

源代码   
编译的时候一定要加上-g参数，表示将源代码编译到执行文件，否则看不到路径和源代码
编译-g的时候，只包括了源代码的文件名，没有提供源代码的路径
总结：-g 表示将源代码编译到可执行文件，但看不了源代码，只能看到文件名，所以这时必须提供源代码路径
     但由于一般在调试的情况下有2个预制变量$cdir:$cwd，其中cwd表示当前路径，cdir表示compilation dir
       而由于一般调试在源码目录下，此时cwd就表示源码目录
       当将即使以-g编译的exe拷贝到别的机器，由于cwd没有源码，所以必须拷贝源码过去，且设置directory
Add directory DIR to beginning of search path for source files.  
Forget cached info on source file locations and line positions.  
DIR can also be $cwd for the current working directory, or $cdir for the  
directory in which the source file was compiled into object code.  
With no argument, reset the search path to $cdir:$cwd, the default.
(gdb)show directories                        #源代码搜索路径
(gdb)directory /path/to/src_dir1:/path/to/src_dir2 # http://coolshell.cn/articles/3643.html
     或分成多步directory /path/to/src_dir1          # https://sourceware.org/gdb/onlinedocs/gdb/Source-Path.html
       directory /path/to/src_dir2
                                             #添加源代码搜索路径在当前路径的前面.默认搜索路径是环境变量PATH中定义的路径。
                                             #如果需要指定多个路径，unix可以使用":"或whitespace,windows使用"；"
(gdb)director                                #清除所有自定义的原文件搜索路径
(gdb)set listsize <count>
(gdb)show listsize
(gdb)list <linenum>                          #显示程序第linenum行周围的代码
(gdb)list <function>                         #显示函数名function的源代码
(gdb)list                                    #显示当前行后的代码，默认是10行，当前行的前5和后5，函数则为前2下8
(gdb)list +                                  #显示当前行后的代码
(gdb)list -                                  #显示当前行前的代码
(gdb)list <first>,<last>                     #显示first行到last行的代码
(gdb)list <last>                             #显示当前行到last行之间的代码
(gdb)search/forward-search <reg>
(gdb)reverser-search <reg>
断点
在gdb中有以下几种暂停方法：
断点（BreakPoint）、观察点（WatchPoint）、捕捉点（CatchPoint）、信号（Signals）、线程停止（Thread Stops）
(gdb)b/break <fileName:linenum> [if  ]       #b x.cpp:15 在文件x.cpp的15行处设置断点
(gdb)break/b <fileName:function>
(gdb)break/b <linenum>                       #在当前文件的linenum停住
(gdb>break/b +<offset>                       #在当前行的后面offset行停住
(gdb)break/b -<offset>                       #在当前行的前offset行停住
(gdb)b <class::function|function(type,type>  #b main
(gdb)b *function-name                        #b *main
(gdb)b *address                              #在地址address处设置断点 b *0x804835C
(gdb)rb                                      #对符合正则表达式的位置处设置断点
                                             #若不带参数，则在所有位置处设置断点
(gdb)info b                                  #查询所有断点
(gdb)disable                                 #默认所有断点失效
(gdb)disable/enable $(id1) $(id2)            #enable/disable breakpoint
(gdb)condition $(breakpoint1) $(expression)  #修改breakpoint的停止条件为expression
(gdb)condition $(breakpoint1)                #清除断点号breakpoint1的停止条件
(gdb)ignore $(breakpoint1) $(number)         #从现在起忽略breakpoint$(number)次
(gdb)delete/d [$(id1)]                       #删除断点
(gdb)                                        #为断点设置运行命令command
(gdb)break string::after                     #断点菜单。当有函数重载时，break <function>不能告诉gdb停止在哪儿(当然，详细的函数原型可以定位).
                                             #此时，gdb会为你弹出一个菜单，提示在哪儿可以设置断点。
                                             #选择0表示取消设置断点，
                                             #亦可以同时选择多项数字，中间用空格间隔
(gdb)break <linespec> thread <threadno> if …#注意，这个threadno是GDB分配的，你可以通过“info threads”命令来查看正在运行程序中的线程信息。
                                             #当你的程序被GDB停住时，所有的运行线程都会被停住。这方便你你查看运行程序的总体情况。
                                             #而在你恢复程序运行时，所有的线程也会被恢复运行。那怕是主进程在被单步调试时。
运行
(gdb)run/r [argv[1] argv[2] ... argv[n]]#重新启动程序运行restart run
(gdb)continue/c/fg [ignore-count]            #continue/c/fg三个命令一样，ignore-count表示忽略断点的次数
                                             #next/step这两个命令必须在有源代码调试信息的情况下使用(即GCC编译时使用-g参数）
(gdb)next/n  [count]                         #next  count表示执行后面的count条指令再停住          
(gdb)step/s  [count]                         #step into function，前提是函数有debug信息。count表示执行子函数里的count条指令再停住。
(gdb)ni/nexti                                #执行一条机器指令  ni/si针对的是汇编指令
(gdb)si/stepi                                #执行一条机器指令
(gdb)finish                                  #运行程序，直至退出当前函数。并打印函数返回时的堆栈地址和返回值及参数值信息。
(gdb)until/u                                 #退出循环体
(gdb)set step-mode on                        #默认值是on。打开step-mode模式。于是在单步跟踪的时候不会因为没有debug信息而不停住。
                                             #这个参数很有利于查看机器源码
(gdb)set step-mode off
栈/帧
(gdb)bt [full]                               #显示局部变量
(gdb)bt [full]  <n>                          #只打印栈顶n层
(gdb)bt [full]  <-n>                         #只打印栈底n层
(gdb)f/frame                                 #check where you are
(gdb)f/frame $(fNum)                         #0表示栈顶
(gdb)info frame/f
查看
(gdb)display ...                             #设置程序中断后欲显示的数据及其格式。 http://hi.baidu.com/foxiong/blog/item/cf448dd67d40d02e06088b74.html
                                             #例如，希望程序每次中断后可以立即看到即将被执行的下一条汇编指令，可以使用
                                             #(gdb)display /i $pc   其中 /i表示以十六进制显示  $pc表示当前的指令
                                             #当需要关心汇编指令时，此命令相当有用
(gdb)undisplay 
查看变量
(gdb)info args                               #查看函数参数
(gdb)info locals                             #查看局部变量
(gdb)info registers                          #查看寄存器
(gdb)info catch                              #查看当前函数中的异常处理信息
(gdb)i r                                     #与上述等价  查看寄存器
查看类型
(gdb)ptype $(val)
(gdb)whatis $(val)                           #查看变量类型
查看寄存器
(gdb)info registers                          #查看寄存器(除了浮点寄存器)
(gdb)info all-registers                      #查看所有的寄存器(包括浮点寄存器)
(gdb)info registers <regname...>             #查看所有指定的寄存器    或 print/p $ip加上$
                                             #ip:当前运行指令的地址 sp:当前堆栈地址 
打印计算表达式
(gdb)set print pretty on
(gdb)print/p [/f] <expresssion>              #gdb会根据当前的程序运行的数据来计算表达式。
                                             #/f format的取值范围 x:16进制 d/u:10进制 o:8进制 t:2(two)进制 a:address c:AsciiChar s:string f:float
                                             #既然是表达式，那么可以是当前程序运行的const变量、变量、函数等，可惜不能是宏。
                                             #	@与数组有关
                                             #  ::指定一个在文件file::variable或函数func::variable中的变量，
                                                   注意与C++的::的区别,还有可能被编译器优化掉某些变量，建议调试时关闭优化选项即-O0
                                             #  {<type>} <addrss> 表示一个指向内存地址<address>的类型type的一个对象
(gdb)p *arrar@len                            #print arrar=(int*)malloc();//set print element 0 默认最长是200个字节
(gdb)p/x (unsigned int[])out                 #强转为unsigned int数组并以16进制打印
查看内存
(gdb)help x
(gdb)examine/x [/nfu] <address>              #n f u 是可选参数 如x /20b $addr
                                             #n number是一个正整数，表示显示内存的长度，也就是说从当前地址address后显示n个地址的内容
                                             #f format表示显示格式。如果地址所指的是字符串，那么格式是s；如果地址是指令地址，那么格式是i
                                             #u unit  表示从当前地址往后请求的字节数。如果不指定的话，gdb默认是4个字节。
                                             # u可以使用下面的字符来代替，b表示单字节，h表示双字节，w表示4个字节，g表示8个字节
                                             # x/3uh 0x54320  从内存地址0x54320读取内容，h表示以双字节为一个单位，3表示三个单位，u表示按十六进制显示
观察点
(gdb)watch $(v)                              #为变量v设点断点，当v被写时stop
(gdb)awatch $(v)                             #为变量v设点断点，当v读或写时stop
(gdb)rwatch $(v)                             #为变量v设点断点，当v被读时stop
设置变量
(gdb)set var = 5                             #设置程序变量
(gdb)set $var = 5                            #设置gdb变量,gdb中的变量以$开头，之后就可以print a[$var++]
自动显示                                  #在gdb中，你可以设置当程序停在断点处时，自动显示变量的内容，即display命令
(gdb)info display
(gdb)display <expr>                          #只要gdb停下来的时候，自动显示的变量
(gdb)display <fmt> <expr>
(gdb)display /<fmt> <addr>
(gdb)display /i $pc                          #$pc是GDB的环境变量，表示着指令的地址，/i则表示输出格式为机器指令码，也就是汇编。
                                             #   于是当程序停下后，就会出现源代码和机器指令码相对应的情形
(gdb)disable/enable display <dnums>
(gdb)undisplay/delete <dnums>                #undisplay 2-5
调用函数
(gdb)call ntohs(10275)                       #调用函数
源代码的内存指令
可以使用info line命令查看源代码行在内存中的起始地址。
info line后可接"linenum","function-name","filename:linenum","filename:functin-name".
(gdb)help info line
(gdb)info line main.c:5                   #默认显示当前行
Line 8 of "main.c" starts at address 0x4004ae <main+22> and ends at 0x4004b2 <main+26>.
在此后，有两种方法查看汇编layout asm或disassemble /r
(gdb)layout asm                           #注意[main+22,main+26)
(gdb)disassemble /r 0x4004ae,0x4004b2     #好像只有gdb7.0才支持/r
(gdb)disassemble /m 0x4004ae,0x4004b2     #会列出源码并汇编
汇编
(gdb)set disassemble-flavor intel/att        #设置反汇编风格
(gdb)show disassembly-flavor                 #查询反汇编风格，可以是intel/att
(gdb)disassemble/disas                    #默认的反汇编范围是所选帧的pc附近的函数
(gdb)disassemble pc/function-name            
(gdb)disassemble /r <begin-addr,end-addr>

(gdb)info/i program                          #find out why your program stopped
改变程序的执行
(gdb)p var = 5                               #设置程序变量并打印
(gdb)jump <linenum>                          #跳转到哪一行执行
(gdb)jump <file-name:linenum>
(gdb)jump +lineoffset
(gdb)jump <address>                          #代码行的内存地址
(gdb)return                                  #强制函数返回
(gdb)return <expression>                     #强制函数返回expression
(gdb)call <expr>                             #显示函数的返回值，如果返回值是void，那么就不显示。
                                             #与print类似，如果函数返回void，call则不显示；print则显示返回值，并把数据存到历史数据中。
历史
(gdb)history
(gdb)show commands 20                        #显示命令的历史记录
联调
(gdb)attach $(pid)                           #等价于gdb -p $(pid)
信号
(gdb)info signals                            #查看信号处理方式
(gdb)info handle                             #查看有哪些信号被gdb检测中
(gdb)handle <signal> <keywords...>       #改变gdb对信号signal的处理方式
						    #  可以以SIG开头或不以SIG开头；
                                             #	也可以定义一个范围SIGIO-SIGKILL,表示包括SIGIO,SIGIOT,SIGKILL三个信号
                                             #  也可以使用关键字all，表明需要处理所有的信号
                                             #keywords，可以是下面关键字的组合，实质上就3列： stop/nonstop print/nonprint pass/nopass
                                             #	nonstop 当被调试的程序收到信号时，gdb不会停住程序的运行，但会打印信息，表示收到这种信号
                                             #  stop    当被调试的程序收到信号时，gdb会停住程序
                                             #  print/noprint 当被调试的程序收到信号时，gdb是否会打印信息
                                             #  pass/noignore   当被调试的程序收到信号时，gdb不处理信号。这表示gdb会把这个信号交给程序处理
                                             #  nopass/ignore  当被调试的程序收到信号时，gdb不会让被调试的程序处理信号
                                             # 例如： handle SIGINT nostop print pass
(gdb)handle SIGNAL nopass/ignore             #不将信号signal传递给程序  
                     pass/ignore             #allow program see this signal
(gdb)signal <signal-number>             #发送信号给被调试程序。
                                             #signal命令与shell的kill命令不同，kill时由gdb截获，signal直接发送给被调试应用。
                                             #signal-number范围是1-15.unix的系统信号通常在1,-15，所以signal也在这个范围
捕捉点                                    #必须在程序处于run状态
(gdb)help catch                          
(gdb)catch <event>                           #throw一个C++的异常(throw为关键字)
                                             #catch一个C++的异常(catch为关键字)
                                             #exec系统调用(exec为关键字，目前只有HP-UX下有用)
                                             #fork系统调用(fork为关键字，目前只有HP-UX下有用)
                                             #vfork系统调用(vfork为关键字,目前只有HP-UX下有用)
                                             #load或load <libname>(load为关键字，目前只有HP-UX下有用)
                                             #unload或unload <libname>(unload为关键字，目前只有在HP-UX下有用)
(gdb)tcatch <event>                          #只设置捕捉一次，当程序停住后，断点被自动删除
设置显示项
(gdb)show print address                      #
(gdb)set print address on/off                #当gdb调用函数的时候，是否显示参数的地址，默认显示
(gdb)show print array
(gdb)set print array on/off                  #当打印数组时，on表示每个元素一行，off则每个元素以逗号分隔。默认off
(gdb)show print elements
(gdb)set print elements <number-of-elements> #设置打印数则时的最大个数，0表示不限制
(gdb)set print null-stop on/off              #on表示显示字符串时，遇到结束符就停止显示。默认off
(gdb)show print pretty                       #如何显示结构体
(gdb)set print pretty on/off                 #on显示比较漂亮 off单行显示
(gdb)show print sevenbit-strings             #设置字符是否按\nnn的格式显示
(gdb)set print sevenbit-strings on/off       #on表示字符串或字符数据按\nnn显示。如\065
(gdb)show print union                        #查看联合体的显示格式
(gdb)set print union on/off                  #设置显示结构体时，是否显示其内的联合体数据
(gdb)show print object                       #查看对象选项的设置
(gdb)set print object on/off                 #在C++中，如果一个对象指针指向其派生类，
                                             #如果on，gdb会自动按照虚方法调用的规则显示输出
                                             #如果off，gdb就不管虚函数表了。 默认off
(gdb)show print static-members               
(gdb)set print static-members on/off         #当显示一个c++对象的内容时，是否显示其中的静态数成员。默认是on
(gdb)show print vtbl
(gdb)set print vtbl on/off                   #是否显示虚函数.默认是off
环境变量
(gdb)show convenience                        #查看所有的环境变量
(gdb)set $v1=x
自动化命令command                         # http://coolshell.cn/articles/3643.html
    (gdb) b func
    (gdb) command 1                          #command 后接breaknumber,每行命令分行，最后以end结束
     >print arg1
     >print arg2
     >print arg3
     >end
    (gdb)
3、调试C++
gdb调试C++，涉及到STL容器查看，非常麻烦。 有一个GDB STL Viewer(http://www.berlinix.com/code/gdb_stl_viewer.txt)的脚本，可以帮助查看STL容器。 
只需在调用gdb后，执行命令source gdb_stl_viewer.txt加载它即可。
b 'C::foo                   自动补全'
ptype C                     显示类C的声明
info functions C::foo       显示类C的所有foo函数声明
在模板函数中的某一行设置断点，将导致gdb只在某个模板实例中中断。 通过info b查看，如:
breakpoint     keep y   0x08048774 in void print<char>(char) at tem.cpp:8
必须在函数签名，而非源代码某一行设置断点，如有模板函数 print<T> 要打断点，可通过：
i) 通过命令 objdump -tC ./tem|grep print 
    或 objdump -t ./tem|c++filt|grep print                  #c++ filter http://book.51cto.com/art/201005/197760.htm
    找出所有print符号。
ii)在gdb中对这些符号下断点。如 b void print<int>(int)

4、配置文件
vim ~/.gdbinit                               #新建gdbinit文件
source ~/gdb_stl_viewer.txt                  #添加gdb命令

define commond-name                          #gdbinit定义命令语法
commands
end

document command-name                        #给命令添加说明性文字
desc
end

5、调试多线程
(gdb)info threads                             #inquire threads
(gdb)thread $(tid)                            #switch among threads
(gdb)thread apply all bt                      #显示所有的线程堆栈              pstack 
(gdb)thread appy $(tid1) $(tid2) bt           #显示tid1, tid2的堆栈。bt可以换成其他任何gdb命令
(gdb)set scheduler-locking off|on|step
			                         #off不锁定任何线程。在调试某一线程时，其他线程照常执行。默认。
			                         #on锁定其他线程，只有当其线程会执行。
			                         #step除了next过一个函数的情况，step只让当前线程执行。
(gdb)break <line> [thread <threadno>] [if ...]#line  filename:linenum
                                              #threadno 是info threads最左边的序号0,1,2而不是大数 
6、调试多进程
(gdb)set detach-on-fork off                   #both parent/child process will be held under the control of gdb
(gdb)set follow-fork-mode child/parent        #default跟踪parent
(gdb)info forks                               #显示所有进程pid
(gdb)process $(pid)                           #切换到pid的进程
(gdb)fork $(fork-id)                          #切换到fork-id的进程，类似process pid,但该fork-id类似于frame id，是最前面的序号0，1，2,...

7、bookmark/checkpoint                        http://blog.chinaunix.net/space.php?uid=23629988&do=blog&id=2943273
(gdb)checkpoint                               #save a snapshot
(gdb)info checkpoints
(gdb)restart $(checkpoint-id)                 #wind back the clock

8、hook
给gdb定义钩子，使其在执行gdb命令前、后，执行用户自定义的命令
define hook-print           # 命令必须是全称，不能为缩写
echo --\n
end
define hookpost-print       # 在命令后执行用户指令
echo --\n
end

9、kgdb
kgdb可对Linux内核进行内核级别源码调试。需要两台机子，用串口相连(或在VMware里模拟串口通讯)。 kdb不能进行内核源码基本调试，但可以只用一台机子。





当进程不正常（死锁），但没有产生coredump，而生产环境又不允许gdb，则需要强制产生coredump：
kill -(SIGQUIT/SIGABRT/SIGFPE/SIGSEGV) $pid
还有一种情况，进程并没有死锁或者block在某个位置，但是我们需要在某个指定位置进行调试，获取某些变量或者其它信息。但是，有可能是客户环境或者生产环境，不允许我们进行长时间的检测。那么，我们就需要通过coredump来获得进程在运行到该点时的快照。这个时候，可以利用gdb来产生手工产生coredump。在attach上这个进程时，在指定位置打上断点，当断点触发时，使用gdb的命令gcore，可以立即产生一个coredump。这样，我们就拿到了这个位置的进程快照。



gdb -help
(gdb)help                      #列出类别
(gdb)help $(class_type)        #
(gdb)b\t\t                     #连续按两次tab键，可以显示候选命令或匹配的函数名
(gdb)shell <command string>    #在gdb中执行shell
(gdb)gcore                     #强制产生coredump




远程调试
情景：
目标机(Server)：192.168.1.241:1100  #在端口1100监听  
调试机(Client): 192.168.1.244
应用程序：a.out
步骤
(1)目标机先启动：
$gdbserver 192.168.1.244:1100 a.out
(gdb) Process a.out created;pid=5384
Listening on port 1100
(2)在客户机：
$gdb a.out
(gdb)target remote 192.168.0.241:1100
Remote debugging using 192.168.1.241:1100



$gdb main
(gdb)layout asm
(gdb)help x             #查看内存
Examine memory: x/FMT ADDRESS.
ADDRESS is an expression for the memory address to examine.
FMT is a repeat count followed by a format letter and a size letter.       [repeat-count]   默认值为1 
Format letters are o(octal), x(hex), d(decimal), u(unsigned decimal),      [format]         
  t(binary), f(float), a(address), i(instruction), c(char) and s(string).  [size]           b(byte) h(halfword) w(word) g(giant 8bytes)
Size letters are b(byte), h(halfword), w(word), g(giant, 8 bytes).
The specified number of objects of the specified size are printed
according to the format.

Defaults for format and size letters are those previously used.
Default count is 1.  Default address is following last thing printed
with this command or "print".






插件：
调试STL
    下载http://www.yolinux.com/TUTORIALS/src/dbinit_stl_views-1.03.txt
    cat dbinit_stl_views-1.03.txt >> ~/.gdbinit
    若正处于gdb状态,运行(gdb)source ~/.gdbinit
    查看帮助(gdb)help pvector 或查看源码dbinit_stl_views-1.03.txt 






$ apt-get source coreutils
$ sudo apt-get install coreutils-dbgsym
$ gdb /bin/ls
GNU gdb (GDB) 7.1-ubuntu
(gdb) list main
1192    ls.c: No such file or directory.
in ls.c
(gdb) directory ~/src/coreutils-7.4/src/
Source directories searched: /home/hchen/src/coreutils-7.4:$cdir:$cwd
(gdb) list main
1192        }
1193    }
1194
1195    int
1196    main (int argc, char **argv)
1197    {
1198      int i;
1199      struct pending *thispend;
1200      int n_files;
1201

















5.3 Signals 
A signal is an asynchronous event that can happen in a program. The operating system defines the possible kinds of signals, and gives each kind a name and a number. For example, in Unix SIGINT is the signal a program gets when you type an interrupt character (often C-c); SIGSEGV is the signal a program gets from referencing a place in memory far away from all the areas in use; SIGALRM occurs when the alarm clock timer goes off (which happens only if your program has requested an alarm). 

Some signals, including SIGALRM, are a normal part of the functioning of your program. Others, such as SIGSEGV, indicate errors; these signals are fatal (they kill your program immediately) if the program has not specified in advance some other way to handle the signal. SIGINT does not indicate an error in your program, but it is normally fatal so it can carry out the purpose of the interrupt: to kill the program. 

GDB has the ability to detect any occurrence of a signal in your program. You can tell GDB in advance what to do for each kind of signal. 

Normally, GDB is set up to let the non-erroneous signals like SIGALRM be silently passed to your program (so as not to interfere with their role in the program's functioning) but to stop your program immediately whenever an error signal happens. You can change these settings with the handle command. 


info signals 
info handle 
Print a table of all the kinds of signals and how GDB has been told to handle each one. You can use this to see the signal numbers of all the defined types of signals. 
info handle is an alias for info signals. 


handle signal keywords... 
Change the way GDB handles signal signal. signal can be the number of a signal or its name (with or without the `SIG' at the beginning); a list of signal numbers of the form `low-high'; or the word `all', meaning all the known signals. The keywords say what change to make. 
The keywords allowed by the handle command can be abbreviated. Their full names are: 


nostop 
GDB should not stop your program when this signal happens. It may still print a message telling you that the signal has come in. 

stop 
GDB should stop your program when this signal happens. This implies the print keyword as well. 

print 
GDB should print a message when this signal happens. 

noprint 
GDB should not mention the occurrence of the signal at all. This implies the nostop keyword as well. 

pass 
noignore 
GDB should allow your program to see this signal; your program can handle the signal, or else it may terminate if the signal is fatal and not handled. pass and noignore are synonyms. 

nopass 
ignore 
GDB should not allow your program to see this signal. nopass and ignore are synonyms. 
When a signal stops your program, the signal is not visible to the program until you continue. Your program sees the signal then, if pass is in effect for the signal in question at that time. In other words, after GDB reports a signal, you can use the handle command with pass or nopass to control whether your program sees that signal when you continue. 

The default is set to nostop, noprint, pass for non-erroneous signals such as SIGALRM, SIGWINCH and SIGCHLD, and to stop, print, pass for the erroneous signals. 

You can also use the signal command to prevent your program from seeing a signal, or cause it to see a signal it normally would not see, or to give it any signal at any time. For example, if your program stopped due to some sort of memory reference error, you might store correct values into the erroneous variables and continue, hoping to see more execution; but your program would probably terminate immediately as a result of the fatal signal once it saw the signal. To prevent this, you can continue with `signal 0'. See section Giving your program a signal.







































ln -s $sym_link  $entity  # sym_link --> $entity


cp    $sym_link $v        # cp $entity $v       拷贝链接指向的对象
cp -d $sym_link $v        # $v ---> $entity   d 单纯拷贝链接


a   ==dpR                       复制属性
d   拷贝时保存链接
p   将修改时间和访问权限也复制
R   递归
l   链接文件，不作拷贝
i   若存在则提示
f   若存在，先删除，再复制














































strace –tt –p –e –o a.txt
strace -f -s 100 ./test
strace -f -p $pid -s 600
strace -e rt_sigaction -f -s 100 ./test


-f/-F  跟踪fork/vfork
-p $pd 跟踪进程$pid
-e     
-s
-tt 
-o    输出文件





 1.挂死程序源码
//hang.c
#include
#include
#include
#include

int main(int argc, char** argv)
{
    getpid(); //该系统调用起到标识作用
    if(argc < 2)
    {
        printf("hang (user|system)\n");
        return 1;
    }
    if(!strcmp(argv[1], "user"))
        while(1);
    else if(!strcmp(argv[1], "system"))
        sleep(500);
    return 0;
}

可向该程序传送user和system参数，以上代码使用死循环模拟用户态挂死，调用sleep模拟内核态程序挂死。


2.strace跟踪输出

用户态挂死跟踪输出：

lx@LX:~$ gcc hang.c -o hang

lx@LX:~$ strace ./hang user

……

mprotect(0x8049000, 4096, PROT_READ)    = 0

mprotect(0xb59000, 4096, PROT_READ)     = 0

munmap(0xb77bf000, 80682)               = 0

getpid()                                = 14539

内核态挂死跟踪输出：

lx@LX:~$ strace ./hang system

……

mprotect(0x8049000, 4096, PROT_READ)    = 0

mprotect(0xddf000, 4096, PROT_READ)     = 0

munmap(0xb7855000, 80682)               = 0

getpid()                                = 14543

rt_sigprocmask(SIG_BLOCK, [CHLD], [], 8) = 0

rt_sigaction(SIGCHLD, NULL, {SIG_DFL, [], 0}, 8) = 0

rt_sigprocmask(SIG_SETMASK, [], NULL, 8) = 0

 

nanosleep({500, 0},

3.输出分析

用户态挂死情况下，strace在getpid()一行输出之后没有其他系统调用输出；进程在内核态挂死，最后一行的系统调用nanosleep不能完整显示，这里nanosleep没有返回值表示该调用尚未完成。

 

因而我们可以得出以下结论：使用strace跟踪挂死程序，如果最后一行系统调用显示完整，程序在逻辑代码处挂死；如果最后一行系统调用显示不完整，程序在该系统调用处挂死。

 

当程序挂死在系统调用处，我们可以查看相应系统调用的man手册，了解在什么情况下该系统调用会出现挂死情况。

下次再遇到程序挂死、命令执行报错的问题，如果从程序日志和系统日志中看不出问题出现的原因，先别急着google或找高手帮忙，别忘了一个强大的工具它就在那里，不离不弃，strace一下吧！




 starce 的另一个用处是解决和动态库相关的问题。当对一个可执行文件运行ldd时，它会告诉你程序使用的动态库和找到动态库的位置。但是如果你正在使用一个比较老 的glibc版本（2.2或更早），你可能会有一个有bug的ldd程序，它可能会报告在一个目录下发现一个动态库，但是真正运行程序时动态连接程序 （/lib/ld-linux.so.2）却可能到另外一个目录去找动态连接库。这通常因为/etc/ld.so.conf和 /etc/ld.so.cache文件不一致，或者/etc/ld.so.cache被破坏。在glibc 2.3.2版本上这个错误不会出现，可能ld-linux的这个bug已经被解决了。
尽管这样，ldd并不能把所有程序 依赖的动态库列出来，系统调用dlopen可以在需要的时候自动调入需要的动态库，而这些库可能不会被ldd列出来。作为glibc的一部分的NSS （Name Server Switch）库就是一个典型的例子，NSS的一个作用就是告诉应用程序到哪里去寻找系统帐号数据库。应用程序不会直接连接到NSS库，glibc则会通 过dlopen自动调入NSS库。如果这样的库偶然丢失，你不会被告知存在库依赖问题，但这样的程序就无法通过用户名解析得到用户ID了。让我们看一个例 子：
whoami程序会给出你自己的用户名，这个程序在一些需要知道运行程序的真正用户的脚本程序里面非常有用，whoami的一个示例输出如下： 
代码：
# whoami 
root
 
假设因为某种原因在升级glibc的过程中负责用户名和用户ID转换的库NSS丢失，我们可以通过把nss库改名来模拟这个环境： 
代码：
# mv /lib/libnss_files.so.2 /lib/libnss_files.so.2.backup 
# whoami 
whoami: cannot find username for UID 0
 
这里你可以看到，运行whoami时出现了错误，ldd程序的输出不会提供有用的帮助： 
代码：
# ldd /usr/bin/whoami 
libc.so.6 => /lib/libc.so.6 (0x4001f000) 
/lib/ld-linux.so.2 => /lib/ld-linux.so.2 (0x40000000)
你只会看到whoami依赖Libc.so.6和ld-linux.so.2，它没有给出运行whoami所必须的其他库。这里时用strace跟踪whoami时的输出： 
代码：
strace -o whoami-strace.txt whoami
open("/lib/libnss_files.so.2", O_RDONLY) = -1 ENOENT (No such file or directory) 
open("/lib/i686/mmx/libnss_files.so.2", O_RDONLY) = -1 ENOENT (No such file or directory) 
stat64("/lib/i686/mmx", 0xbffff190) = -1 ENOENT (No such file or directory) 
open("/lib/i686/libnss_files.so.2", O_RDONLY) = -1 ENOENT (No such file or directory) 
stat64("/lib/i686", 0xbffff190) = -1 ENOENT (No such file or directory) 
open("/lib/mmx/libnss_files.so.2", O_RDONLY) = -1 ENOENT (No such file or directory) 
stat64("/lib/mmx", 0xbffff190) = -1 ENOENT (No such file or directory) 
open("/lib/libnss_files.so.2", O_RDONLY) = -1 ENOENT (No such file or directory) 
stat64("/lib", {st_mode=S_IFDIR|0755, st_size=2352, ...}) = 0 
open("/usr/lib/i686/mmx/libnss_files.so.2", O_RDONLY) = -1 ENOENT (No such file or directory) 
stat64("/usr/lib/i686/mmx", 0xbffff190) = -1 ENOENT (No such file or directory) 
open("/usr/lib/i686/libnss_files.so.2", O_RDONLY) = -1 ENOENT (No such file or directory)
 
你可以发现在不同目录下面查找libnss.so.2的尝试，但是都失败了。如果没有strace这样的工具，很难发现这个错误是由于缺少动态库造成的。现在只需要找到libnss.so.2并把它放回到正确的位置就可以了。











sudo -h
sudo -l
sudo -v
sudo -k
sudo -s
sudo -H
sudo [ -b ] [ -p prompt ] [ -u username/#uid] -s



配置文件 /etc/sudoers



分区 
	fdisk    MBR
	gdisk    GPT
	parted 
	
	
	ls -lsh 第一列为因为占块所占的大小 size为实际数据的大小

lsblk  查看分区

echo $mypassword | passwd --stdin $user #对用户$user设置密码$passwd
curl ftp://$user:$passwd@$host//root #//etc中的第一个/是分隔符
python3 -m http.server 8000 | python2.7 -m SimpleHTTPServer 8000 # 就以当前目录为根目录建立一http server







apt install build-essential
yum groupinstall DevelopmentTools        #若软件需要开发工具
yum groupinstall KernelSourceDevelopment #若软件需要图形接口
yum groupinstall "XSoftwareDevelopment"  #若按照的软件教旧

rpm --help
#安装
rpm -ivh $pkg [opts]
	--prefix       #类似于config --prefix=
	--nodeps #不管依赖性
	--replacefiles #覆盖文件
	--replacepkgs  #重新安装
	--force        #强制安装 等价于replacefiles 和 replacepkgs 
	--test         #检查是否可以安装， 一般用于查看依赖性
	--justdb       #更新数据库信息
	--nosignature  #省略签名
#更新
rpm -Uvh $pkg      #以前没有安装则现在安装 有则更新
rpm -Fvh $pkg      #以前没有安装则不安装 有则更新
#删除
rpm -e $pkg 
#查询
rpm --provides     #查询依赖
rpm --whatprovides #反查询依赖
rpm -qa            #已安装软件
rpm -q  $pkg       #查询是否安装
rpm -q  $pkg
	l            #list 所有文件及其路径
	i            #info
	c            #在/etc下的configure file 
	d            #document 与man有关
	R            #依赖文件 required
rpm -qf $absolute-file #查询属于哪个安装包 由于list是绝对路径， 所以这儿也是绝对路径
rpm -q[licdR]p $pkg #查询当前rpm pkg
#验证pkg自安装后是否被修改过
rpm -Va          #验证所有的pkg
rpm -V  $pkg     #验证某个已安装的pkg， 只有修改过才会列出来
rpm -Vf $ab-file #验证已安装包的某个文件
rpm -Vp a.rpm    #验证某个安装包
#
rpm --rebuild  #
rpmbuild --rebuild *.src.rpm    #仅编译到/root/rpmbuild/RPMS/x86_64/*.rpm
pmbuild --recompile *.src.rpm   #编译并安装


yum install -y --installroot=  #安装到指定目录
yum remove    $pkg
yum list                 #rpm -qa 
yum list pam*            #已安装和可安装
yum list updates         #可供升级
yum search all $pkg 
yum info       $pkg 
yum provides   $ab-file  #rpm -qf yum provides passwd

yum grouplist
yum groupinfo    $groupName
yum groupinstall $groupName
yum groupremove  $groupName

yum repolist all #列举仓库
yum clean [packages|headers|all]




https://wiki.ubuntu.org.cn/%E9%A6%96%E9%A1%B5
https://wiki.ubuntu.org.cn/Qref/Apps
https://wiki.ubuntu.org.cn/UbuntuSkills







http://ddrv.cn/a/342647
https://www.jianshu.com/p/d7c9cef525bc


https://blog.csdn.net/yhc166188/category_7937752.html
https://blog.csdn.net/yhc166188/article/details/82795177


cleos wallet create [-n $walletName]  [--to-console | -f ~/$passwordFileName]  #会在~创建文件夹eos-wallet,默认的钱包名为default.wallet  
#cleos create key [--to-console | -f $keyFileName]  #产生public/private key 
#cleos wallet import -n $walletName --private-key $privKey
cleos wallet create_key -n $walletName 
cleos wallet list  #钱包名列表
#cleos wallet open -n $walletName
cleos wallet unlock -n $walletName --password $password
cleos wallet keys  #列举公钥
cleos wallet private-keys #列举私钥


#建立新账户12位字符 12345abcdefghijklmnopqrstuvwxyz
# 抵押0.001EOS用于网络，0.02EOS用于CPU，购买3k内存（约0.0465EOS）可满足新账户转账最低资源需求
cleos system newaccount --stake-net '0.001 EOS' --stake-cpu '0.02 EOS' --buy-ram-kbytes 3 <自动分配的账户名> <新注册账户名> <你的公钥>


##查看账户
#概要信息（可用资源、投票等）
cleos get account <账户名> 
cleos get table eosio  <账户名>  userres
# 查看账户抵押信息
cleos system listbw <账户名> 
cleos get table eosio <账户名>  delband
# 查看账户余额
cleos get currency balance eosio.token  <账户名> 
cleos get table eosio.token <账户名>  accounts


##转账
cleos transfer <转出账户名>  <转入账户名>  '0.0001 EOS' 'memo'

##竞拍短名（少于12字符的短账户名需竞拍，每24小时只成交一个。目前只能出价，主网激活14天后才正式交易）
# 查询短名出价情况
cleos system bidnameinfo  <短名> 
# 参与竞拍
cleos system bidname <本人账户名>  <短名>  '0.0001 EOS'


atop htop 
bash -c "echo a.sh | at now"

nmcli connection show
nmcli connection show eth0
nmcli connection modify eth0 \
connection.autoconnect yes \
ipv4.method manual \
ipv4.address $ip/$netmask \
ipv4.gateway $gateway \
ipv4.dns $dns
nmcli connection modify eth0 connection.autoconnect yes ipv4.method auto
nmcli connection up eth0

hostnamectl
hostnamectl set-hostname $hostname  #cat /etc/hostname

timedatectl
timedatectl list-timezone
timedatectl set-timezone  "Asia/Shanghai"
timedatectl set-time "2020-02-05 11:01"    # date && hwclock -w
timedatectl set-ntp 
ntpdate tock.stdtime.gov.tw && hwclock -w

localectl
localectl set-locale LANG=en-US.utf8



dmidecode -t [1|4|9|17]  #1SYS 4CPU 9PCI 17MEM

dd if=/dev/sda of=/dev/sdb #不必格式化，速度较慢
find / -print | cpio -covB > /dev/back &&  cpio -iduv < /dev/back
xfsdump 
xfsrestore
tar --exclude --exclude /proc -jcvp -f back.tar.bz2 /

tar --exclude --exclude /proc -N ‘2020-02-05’ -jcvp -f back.tar.bz2 /
rsync -av $src $dst

locate updatedb生效
man    mandb生效
tmpwatch 删除暂存文件

systemctl enabled/restart/status atd
at $time
>echo "hhh" > /dev/tty1  #at环境的默认输出都到/var/spool/mail PATH也会变，所以使用绝对路径
>sync                    #多指令
>sync
>shutdown -h now
>ctrl-d  #显示为EOT
时间格式$time
	HH:MM  04:00
	HH:MM YYYY-MM-DD 04:00 2020-02-20
	HH:MM[am|pm] [Month] [Date]  04pm July 30
	HH:MM[am|pm] + number [minutes|houres|days|weeks]  ex>now+5munutes
atq       #at -l  列出有哪些任务
at -c $jobNumber #列出job具体内容
atrm $jobNumber #at -d  删除任务job

batch 没时间限制的在CPU不忙的情况下执行 是一个shell脚本，本质上就是at


systemctl restart crond
cron  /var/spool/cron/$user文件中 日志在/var/log/cron
	-u  $user
	-e  #edit */5 3,6 3-6 
	-l  #list all items
	-r  #remove all items
minute hour day month week action

如何查找怪异进程：找crontab或怪异进程的父进程pid，然后kill -9 $ppid



man -a signal 
man 7 signal       
kill -l
stty -a 

ctrl-c sigint 2
ctrl-z sigsup 
ctrl-s sigstop 19

ctrl-s 发送stop信号，未放弃fg控制权 ctrl-q 发送start信号
& ctrl-z 发送suspend信号 放弃前台控制权，放入后台 不接受输入，不能ctrl-c， 可以使用bg/fg
jobs -l # -表示最近最后倒数第二个 +表示最近最后一个 只能管理自身这个bash pid直接产生的后台进程， 间接产生的都管理不了
kill -9 %{$jobNumber} %{$jobNumer}   #eg kill -9 %1
fg %{$jobNumber}
bg %{jobNumber}  将前台进程由于ctrl-z状态为暂停变成后台进程运行，自动添加了一个&

ps axjf
top 
	-d $intervalSeconds  #默认3秒刷新一次
	-b -n $displayNumber > a.txt 
	-p $pid
    ?/h 显示按键帮助
	P CPU M Mem N PID T Time+ 排序默认CPU
pstree 
	-A  线
	-u  在括号中显示用户
	-p  在括号中显示pid
free -hw
fuser -v $file/$dir #eg .

systemctl 
	daemon-reload 
	disable 实质是删除链接
	mask    实质就是链接指空     ln -s /dev/null /etc/systemd/system/$service
	unmask  实质就是删除指空链接 rm /etc/systemd/system/$service
	
	
	show ssh #查看服务的配置文件
	/usr/lib/systemd/a.service/               #存放a服务的配置文件 
	/etc/systemd/system/a.service.d/a.conf
	/etc/systemd/system/a.service.d/wants/    #存放a服务启动后需要启动的服务脚本
	/etc/systemd/system/a.service.d/requires/ #存放a服务启动前需要启动的服务脚本
	
	get-default 
	set-default multi-user.target 
	isoloate graphical.target #切换到target  操作隔离等级使用isolate而不是start/stop
	poweroff #操作等级的快捷方式
	reboot
	suspend    #未关机 当唤醒时从内存中读取数据
	hibernate  #数据保存到硬盘然后关机， 当唤醒时从硬盘读取数据
	rescue     #root无法登录
	emergency  #允许root登录
	
	list-dependencies [$target]            #target默认为get-default获取， target中有哪些unit
	list-dependencies [$target] --reverse  #有哪些unit依赖这个target
	list-dependencies $service             #service依赖哪些unit
	list-dependencies $service --reverse  #有哪些unit依赖这个service

客户端命令行 man 1 logger
客户端API    man 3 syslog
服务端       rsyslog.service rsyslogd /etc/rsyslog.conf


/var/log/boot.log 本次启动
/var/log/dmesg

/var/log/lastlog 所有账号最近一次登录
/var/log/wtmp 正确登录
/var/log/faillog 错误登录
/var/log/secure  所有涉及账号密码登录 包括系统的login程序 图形接口登录gdm程序 su sudo ssh telnet

/var/log/messages 
/var/log/cron

logger -p $serviceName.$loglevel "$msg"
logrotate -vf /etc/logrotate.conf  #-v尝试进行一次详细的lograte  -f强制进行一次logrotate
journalctl [-nrpf] [--since TIME] [--until TIME] _optional
	-n 5   #最近几条 类似于head -n 5
	-r     #反向输出 类似于ls -rt 
	-p err #优先级
	-f     #类似于tail -f 
	TIME   #today tomorrow "2020-02-05 12:00:00"
	_SYSTEMD_UNIT=a.service #只显示a.service 
	_COMM=bash              #只显示与命令有关的
	_PID=pid                #只显示pid有关的
	SYSLOG_FACILITY=[0-23]  #使用syslog.h中的服务序号
logwatch 是一分析syslog的工具  是一perl脚本
mail     #读取邮件发送邮件 mail -s ”$subject" $user < $mail_content.txt

dmidecode -t $type
	1  #SYS
	4  #CPU
	9  #主版插槽
	17 #MEM
lspci [-v|-vv] #列出pci接口
lsusb [-t]#以tree形式列出usb
smartctl -t short /dev/sda  #检测磁盘坏道和寿命 t short for test /dev/sda物理磁盘名
smartctl -a       /dev/sda  #a short for all display all info  self-monitoring analysis and report technology system 


tar.gz == tgz
tar.bz2       #(bzip2)
xz

#patch因为不是源码的全部，而是diff出来的， 所以体积小 便于下载存储
patch -p$number < a.patch #给源码打补丁即diff文件 然后重新make && make install
#ldconfig 预先加载so到内存中以便加速访问
echo "/usr/lib/mmysqlclid" >> /etc/ld.so.conf.d/mmysql.conf #配置哪些so需要预先加载
ldconfig [-f /etc/ld.so.conf] [-C /etc/ld.so.cache]  #加载配置文件中定义
ldconfig -p #打印已加载的so
ldd [-v|-d|-r] $exe | $lib.so  #load dependency
	-v #列出所有内容信息
	-d #重新将有丢失的link点show出来
	-r #显示将elf有关的错误
pldd $pid #正在运行的程序      #process load dependencies


SELinux  cat /etc/selinux/config 
DAC(Discretionary Access Control)自主式访问控制 依据进程的拥有者与文件资源的rwx权限来决定有无存取能力
MAC(Madatory Access Control)委任式控制          设定进程和文件资源的权限

主体(Subject|process) <------policy---securityContext---rwx---->目标(Object|filesystem)
##是否启动SE
getenforce        #获取SE模式级别  enforcing|1强制模式  permissive|0 宽容模式   disable 
setenforce [0|1]  #设置SE模式级别
##policy政策,是rule规则的集合  (targeted minimum mls三个主要的政策)
sestatus   #policy
	-v  #校验/etc/sestatus.conf中的文件与进程的安全性文本内容
	-b  #政策中的规则rule是否启动（0|1)
seinfo  #规则统计
	-A #all
	-u #about user
	-r #role
	-t #type
	-b #bool
getsebool -a                 #列出所有规则名ruleName及其值on/off
getsebool $ruleName          #查看某规则值on/off
setsebool [-P] $ruleName 0|1 #persist  否则重启失效
semanage boolean -l |grep $ruleName  #查看规则rule的当前stateValue 默认值defaultValue 描述description
sesearch [-A] [-s $subjectType] [-t objectType] [-b $ruleName]
	-A --allow 
	-s NAME, --source=NAME
	-t NAME, --target=NAME
	-b NAME, --bool=NAME
sesearch -A -b $ruleName     #查看规则内容 一个rule可能有多条item
##securityContext安全性文本 格式user_id:role:typeForFilesystem_OR_DomainForProcess:rest...
ls -Z
ps -eZ  #查看第一个字段中的第三小字段domain值，若是unconfined_t则是不受限的，否则就是受限的
chcon [-R] [-u user] [-r role] [-t type] [-v] $file #改变change file se context  R short for recursive
chcon [-R] [-v] --reference=$范例文件 $file|dir     #参考范例文件一样设置
restorecon [-Rv] $file|dir                          #恢复restore se context 
semanage {login|user|port|interface|translation|fcontext} -l | grep -E "^/etc|^/etc/cron" #list
semanage fcontext -{a|d|m} [-frst] file_spec                 #add|delete|modify
#eg semanage fcontext -a -t system_cron_spool_t "/srv/mycron(/.*)?"
#   semanage fcontext -l | grep "^/srv/mycron"
yum install setroublshoot setroubleshoot-server
systemctl restart auditd  #由audit服务启动setroubleshoot




quota配额
作用对象
	组group          #group与project/dir从文件系统/etc/fstab上就互斥
	非root用户       #四海之内莫非王土 root对所有硬盘都有使用权
	project/dir      #ext文件系统只能针对挂载点，xfs可以针对具体目录
	                 #inode(限制文件数量) block(限制文件夹大小， 单位可以kMG)
					 #有soft和hard之分 类似于低水位和高水位
xfs_quota -x -c "print"  #查看支持quota的挂载点moutpoint -xExpertMode cCmder
xfs_quota -x -c "disable|enable|off|remove -ugp"  #启用关闭quota
xfs_quota -x -c "state"  #查看quota是否启动
#设置user或group或project的block的软硬值 inode的软硬值
xfs_quota -x -c "limit [-ugp] [useName|groupName|prjectName] b[soft|hard]=$N1 i[soft|hard]=$N2" [$mountPoint] 
#设置user或group的宽限时间graceTime
xfs_quota -x -c "timer [-ug] [useName|groupName] [-bir] $Ndays" [$mountPoint]  
#查看设置项uUser gGroup pProject block inode humanreadable
xfs_quota -x -c "report -u|g|p -bih" [$mountPoint]

echo "$userDefinedRandomID:$absoutPathDir" >> /etc/projects
echo "$prjectName:$userDefinedRandomID" >> /etc/projid
xfs_quota -x -c "project -s $projectName"#初始化project
xfs_quota -x -c "limit -p $prjectName bhard=1000M bsoft=100M" /mountPoint

设定流程	        xfs                                   ext
设置文件/etc/fstab  usrquota/grpquota/prjquota            usrquota/grpquota
配置文件                                                  quotacheck 
启动关闭quota       xfs_quota -c "disable|enable -ugp"    quotaon|quotaoff
启动关闭状态        xfs_quota -c "status"
设置user/group      xfs_quota -c "limit "                 edquota|setquota
设置project         xfs_quota -c "limit "
设置grace时间       xfs_quota -c "timer "                 edquota
查看设置项          xfs_quota -c "report"                 repquota|quota
发送警告给用户                                            warnquota


mount | grep quota #查看fs支持哪些quota
mount -a #挂在所有配置在/etc/fstab中的配置的文件系统
unmount $mountPoint|device 


命令
	locate quota | grep bin 等价于 locate *quota* | grep bin  说明支持正则locate $includeCharacters
	locate quota #只要绝对路径名中包含字符串都显示 根据文件名查找比find快多了
	whereis quota 不支持 whereis *quota* 说明whereis不支持正则
	whereis nano  #只查找bin 源文件*.h /usr/share参考文档和脚本  man/info文档
	小结: locate $reg-fileName && whereis $noReg-fileName




vi中     30%跳到文件行数的30%
shell中  ctrl-u 取消当前命令
zgrep
apt install speedtest-cli | pip3 install speedtest-cli  speedtest  #测试的是speedtest.net 
npm install --global fast-cli  fast #默认下载 fast -u #上行        #netflix提供
apt install iperf  #测试局域网window/linux/mac CS模型
server： iperf -s 
cli：    iperf -c $serverIP

mkdir /swapfile
cd /swapfile
dd if=/dev/zero of=swap bs=1G count=1
mkswap -f swap 
swapon swap

sysctl -a #打印所有的kernal变量
taskset   #set/display cpu亲和性
time timeout watch

curl ipconfig.co  #curl ifconfig.me

ipcs   #inter process communication show
ipcmk  #ipc make
ipcrm  #ipc rm
 

dpkg -L tldr | sed -n '2,$p' | xargs ls -ld | awk /^d/ ''   #行首非目录怎么表示     ???

	
 

 


apt-cache madison nginx              #查看有哪些版本
ap-cache  show    nginx | grep -i version  
apt-get install -s $pkgName=$version #模拟安装指定版本 apt-get install nginx=1.14.2-1~xenial
apt-cache policy nginx               #查看已安装的版本号






	
疑问
1 如何由应用bin得知serviceName


systemctl start sysstat && sar #Ubuntu默认没启动 sed 's/false/true/' /etc/default/sysstat 
pkill nginx
echo "" >> /etc/crontab
service crond restart
service keepalived restart 



grep | 尽可能多 ?+*只是前一个单位(单个字符或小括号或中括号为单位)
tmux  ctrl-b q  #显示pane数字
             x  #kill pane
			 m  #mark current pane 加粗
			 o  #select next pane
			 ;  #last pane
			 
			 c  #create window
			 &  #kill current window
			 p  #pre window
			 n  #next window
			 l  #last windows 
			 '  #输入windows index
			 w  #choose window
			 0-9 #choose window
			 
			 - _     #水平竖直切分出pane
			 hjkl    #切换pane 
			 c-h c-l #切换窗口
			 HJKL    #resize pane
			 c       #create window
			 +       #pane -> window
			 x       #kill pane
			 &       #kill window
			 



https://blog.51cto.com/7424593/2174156

GET http://$ip/v1/versions
{
	"code":200,
	"description":"",
	"data":{
		"windows":["1.0","2.0"],
		"linux":["1.0","2.0"],
		"android":["1.0","2.0"]
	}
}

GET http://$ip/v1/hosts
{
	"code":200,
	"description":"fail reason",
	"data":{
		"windows":[$ip,$ip],
		"linux":[$ip,$ip],
		"android":[$ip,$ip]
	}
}

POST http://$ip/api/v1/deploy              #部署节点
{
	"ip": "192.168.1.8",                   #部署节点机器ip
	"os": "windows|linux|android",         #部署节点的操作系统
	"deployLocation":"/data/ipfs",         #部署位置
	"deployVersion":"1.0",                 #部署版本
}

{
	"code": 200,
	"reason": "fail reeson",
	"data":{
		"nodeid":1,                        #返回节点id
	}
}


POST http://$ip/api/v1/start?nodeid=1       #启动节点
{
	"code":200,
	"reason":"fail reason",
	"data":{}
}


POST http://$ip/api/v1/stop?nodeid=1        #停止节点
{
	"code":200,
	"reason":"fail reason",
	"data":{}
}


POST http://$ip/api/v1/restart?nodeid=1     #重启节点
{
	"code":200,
	"reason":"fail reason",
	"data":{}
}


GET http://$ip/api/v1/nodesstatus           #查询所有节点状态
{
	"code": 200,                            #http返回码
	"reason": "failed reason",              #失败原因
	"data": [
		{
			"ip": "192.168.1.8",
			"runningStatus":2,              #运行状态stop:0 launching running:2
			"deployLocation": "/data/ipfs", #部署位置
			"deployVersion": "1.0",         #部署版本
			"diskspace":"100M",             #占用磁盘空间
		},
		{

		}
	]
}

GET htttp://$ip/api/v1/nodestatus?nodeid=1   #查询单节点状态
{
	"code":200,
	"reason":"",
	"data":{
		"runningStatus":2,
		"deployLocation": "/data/ipfs",
		"deployVersion": "1.0",
		"diskspace":"100M",
	}
}

POST　http://$ip/api/ipfs/v1/updatenode?nodeid=1
{
	"os":2,
	"preDeployLocation":"",
	"preDeployVersion":"",
	"deployLocation":"",
	"deployVersion":"1.0"
}

{
	
}




redis
百度redis 命令参考  doc.redisfans.com  redisdoc.com


>object idletime $key #lru时间

rdb方式(真实数据)
人工主动执行命令  save 阻塞执行
                  bgsave 后台执行
配置被动执行命令  save 900 1 

aof方式(真实命令list/set/zset/hash64个元素)
增量
	什么时候人工主动执行?????????
	配置被动执行aof命令        appendfsync always|everysecond|no  #执行fsync或fdatasync的频率
		操作append_to_buf
全量  
	人工主动执行rewriteaof命令 bgrewriteaof
		操作append_to_rewrite_buf
		pid=fork();
		if pid > 0 {
			execute_cmd
			append_to_buf          -----> old.aof
			append_to_rewrite_buf  -----> new.aof
		} else if pid == 0 {
		}
	什么时候全量自动执行rewrieaof??????????????


replicate 
slaveof $master_ip $master_port
slaveof none
info replication   #offset lag最后一次主从通讯到现在的时间   类似于client list中idle字段

Master                                            slave
		   <-----ping ----------------------------
		   ------pong ---------------------------->
		   <-----auth $master_auth_passwd----------   slave配置文件中masterauth字段 也就是master配置文件中的requirepasswd 要一致  输入master密码
		   <-----replconf listening-port $port-----   向master报告自己的listen port
	       <-----psync $master_id offset --------     向master报告自己的replication offset
	bgsave
			-----send rdb  offset -------->              状态同步
			-----send replication backlog中的命令 ---->  命令传播cmder prograte
			<----replconf ack $offset --------------      headbeat


sentinel
在sentinel中使用raft协议选举sentinel leader
>slave of none
>slave of $master_ip $master_port


cluser  #gossip协议(检查节点是否断线和故障转移) 节点只能使用0号数据库
redis-cli -c $ip $port
>cluster meet $ip $port  #将节点加入cluster
>cluster nodes           #查看cluster nodes 
>cluster addslots 1 2 3 4 ... 1000  #分配好slot才可称为上线
>get $key                ########MOVED错误 这个slot根本就不在我这儿

#迁移slot
>cluster setslot $slotNumber importing $sourceID #通知target准备接收slot

>cluster setslot $slotNumber migrating $targetID #通知source准备迁移migrate slot
>cluser getkeysinslots $slotNumber $count 
>cluser migrate $targetIP $targetPort $keyName 0 $timeout #从source迁移key
>cluster setslot $slotNumber node $targetID   #通知cluster中的节点slot迁移到了$targetID
##########ASK错误                  #本来这个slot是在我这儿 但我正搬家呢
>asking

>cluster replicate $nodeID


>cluster info 
>set msg "dfd"          #返回MOVED错误，redirected to slot $slot at $ip:$port
>cluster keyslost $key  #返回key属于哪个slot
>cluster getkeysinslots $slotNumber $keysCount #返回槽号slotNumber中keyCount个key


Master                Slave
	                  slaveof $master_ip $master_port
	     <----sync----	   
(bgsave)

hotkey
bigkey

3.2
bitmap
geohash
4.0
boomfilter
unlink替换del flushdb flushall
redis-cell 漏斗限流
mix-persistence
psync2
memory 
swapdb
5.0 
stream


pipe
pubsub
tx
lua
sort (list set zset)
	sort 
		alpha asc/desc 
		by *_id 
		limit offset cout
		get *_name
		store $new_key  #默认是暂时排序 
bitmap getbit
client list/kill 
slowlog
monitor
info


watch $key1 $key2   #让服务器登记这个client要求在接下来的这段时间内服务器不能对这些key进行修改
multi               #begin 标记tx的开始
exec/discard        #commit 准备执行 首先检查watched key是否被修改，若被修改过，则直接返回错误
                    #discard 只能位于最后，不能位于中间  非rollback 表示放弃不执行
unwatch $key1 $key2 #让服务器取消登记

Atomic     原子性  不支持   遇见错误,也会继续往下执行
Consitence 一致性  
	什么是一致？       只有对比才可发现是否一致。那么对比什么呢？ 数据库
	一致的标准时什么？ 数据符合数据库标准的定义和标准，无无效或非法数据。
	
lua
redis-cli --eval "a.lua"
>script    load "return 0;"
>eval      "return 0" 0  
>evalsha   $hash $argCount $arg1 ...
>script    exists $hash1 $hash2
>script    kill    #lua_time_limit 还需要用户手动发起命令script kill或shutdown nosave
>script    flush

lua原生函数库
	base/core:  assert error pairs tostring pcall and so on,但loadfile因为安全被删
	string:     find format len reverse and so on
	table:      insert remove sort concat and so on
	math:       因为安全删掉原版的randomseed random    
	debug：     sethook gethook getinfo setmetable getmetable
	cjson       decode encode
	struct      pack unpack
	cmsgpack    pack unpack
redis封装的
	全局变量
		用户不能自定义全局变量，只能get/set由redis定义的全局变量
	函数  
		redis.call                  #eval "return redis.call('SMEMBERS', KEYS[1])" 1 sname  使用辅助函数__redis__compare__helper排序
		redis.pcall                 #若出现错误使用__redis__err__helper排序
		redis.status_reply  
		redis.error_reply
		redis.log(redis.LOG_DEBUG)  #VERBOSE NOTICE WARNING
		math.randomseed($seedValue) #修改版的randomseed,相同的seed产生相同的随机数  改变种子,参数默认值为0,返回空 
		math.random($var)           #修改版的random,返回随机数
		redis.sha1hex               #计算sha值
		__redis__err_helper         #辅助函数作用于redis.pcall打印具有行号的错误日志 
		__redis__compare_helper     #辅助函数作用于需要一致性的地方 smembers sunion sdiff smembers hkeys hvalues keys
	

	

gdb -ex "set pagination 0" -ex "thread apply all bt" -batch -p $pid
obdump -c -x #-c ascii -x hex



https://blog.csdn.net/qq_38472380/article/details/81039058
无人值守安装centos


实验： 
redis fork 查看内存是否倍增？？？？？？？？？？

mysqld_safe  &  启动mysql的文本文件


#https://blog.csdn.net/sixdaycoder/article/details/89947893
#https://blog.csdn.net/zxc024000/article/details/104168924
ctrl-shift-p 输入remote-ssh:setting ->勾选show login termial
ctrl-shift-p 输入remote-ssh:connect to host -> configure ssh host 

左侧 remote explore 选择对应的目标,连接  在弹出的额终端窗口中输入密码
左侧 remote explore 选择对应的目标,右击

免密码登录
    ssh-keygen -t rsa -b 4096         #产生的key位于 /c/Users/Administrator/.ssh/id_rsa.pub
    ssh-copy-id root@192.168.1.106
    ssh root@192.168.1.106 -p22



强制用户修改密码
chage -l $userName #查看用户密码的有效期
chage -d 0 $userName  #设置密码过期,下次登录必须修改密码
passwd -e  $userName  #设置密码过期,下次登录必须修改密码





https://stackoverflow.com/questions/3427872/whats-the-difference-between-and-in-bash/3427931#3427931
https://www.zsythink.net/archives/2252



5.1    2008-11
5.5    2010-12-03
5.6    2013-02-05
5.7    2015-12-07
8.0.0  2016-09-12
8.0.11 2018-04-19


https://www.docs4dev.com/docs/zh/mysql/5.7/reference/explain-output.html  mysql5.7中文文档
http://www.deituicms.com/mysql8cn/cn/web.html                             mysql8.0中文手册https://github.com/lrjxgl/mysql8cn

http://mysql.taobao.org/monthly/2016/03/07/  
https://github.com/percona/percona-xtrabackup    备份
https://github.com/percona/percona-toolkit       工具

https://www.aneasystone.com/archives/2017/10/solving-dead-locks-one.html
https://www.aneasystone.com/archives/2018/04/solving-dead-locks-four.html
https://zhuanlan.zhihu.com/p/67793185       详细
https://zhuanlan.zhihu.com/p/20832611
https://blog.csdn.net/u010841296/article/details/84204701

https://blog.csdn.net/qq_36431213/article/details/86497493

https://zhuanlan.zhihu.com/p/38214642
https://www.zhihu.com/people/kayaklee/posts

http://oserror.com/backend/transaction-isolation-first/
http://oserror.com/backend/transaction-isolation-second/


https://www.cnblogs.com/ivictor/p/9807284.html   各版本特性对比
https://www.cnblogs.com/ivictor/p/5324305.html   快速部署
https://www.cnblogs.com/ivictor/p/5305922.html   帮助
https://www.cnblogs.com/ivictor/p/5584398.html   cluster
https://www.cnblogs.com/ivictor/category/960851.html tools
https://www.cnblogs.com/ivictor/category/886997.html percona toolkit pt

https://blog.csdn.net/robinson_0612/article/details/41315139 percona toolkit pt简介


https://blog.csdn.net/xuheng8600/category_7557470.html
https://blog.csdn.net/xuheng8600/article/details/79916385

https://imysql.com/
https://www.zhihu.com/people/yejr



https://blog.csdn.net/majipeng19950610/article/details/81236248   


http://www.eimhe.com/forum.php?mod=viewthread&tid=146964&page=1&extra=#pid1135075
MySQL内核：InnoDB存储引擎   https://www.cnblogs.com/broadview/p/3756983.html
https://www.cnblogs.com/zengkefu/p/5600742.html  dba的博客
https://blog.csdn.net/youqika/article/details/42557511  各高可用的优缺点
https://www.jianshu.com/p/c04cd6a7e22e
https://www.sohu.com/a/141509827_610509
https://www.cnblogs.com/erisen/p/6068265.html 参数优化
https://blog.51cto.com/853056088/2160995  复制从5.6-8.0
https://www.kancloud.cn/thinkphp/mysql-parallel-applier/45909
https://www.jb51.net/article/137123.htm


https://blog.51cto.com/853056088/2426205

https://www.sohu.com/a/141509827_610509

https://www.zhihu.com/question/56172498?sort=created
http://kafka.apachecn.org/uses.html



pxc集群Percona XtraDB Cluster
mysqld --transaction-isolation
thread_cache_size connection数的大小
mysql-log-rotate 

备份
    方式
        运行时
            热备(hot/online backup)
            温备(warm backup)         使用全局读锁
        停止时
            冷备(cold/offline backup)
    备份后的文件
        逻辑备份
            mysql>select * into outfile
            mysqldump
        物理备份(裸文件备份)
            运行时
                ibbackup
                xtrabackup
            停止时
    备份后的内容
        全量
            mysql>set @@global.tx_isolation REPEATABLE-READ
            mysql>begin
            mysql>lock tables;
            mysql>show master status;
            mysql>select * into outfile t1.sql from t1;
            mysql>select * into outfile t2.sql from t2;
            mysql>commit 
        增量
            方式一：  由于官方没有提供，所以可以使用日志binlog方式
            方式二：  xtrabackup
                原理：
        日志

备份和恢复维护之myisam(.frm myd myi)
	备份
		全量备份
			lock tables && flush tables &&  cp 文件  && unlock tables;
			sql级别 select into outfile $outFileName from $t 或  backup table
			mysqldump > mysqldumpfullbackup.sql
			mysqlhotcopy $dbName $dstDir   只适合myisam,已经不再使用了
			snapshot 快照
				Client1                                Client2
				mysql>flush tables with read lock;
                                                       >mount vxvf snapshot;
                mysql>unlock tables; 
                									   从快照复制文件后unmount
		增量冷备份  自从上次mysqldump以来的binlog
			mysql>flush logs    或mysqladmin flush-logs #告诉服务器关闭当前的binlogN文件并创建下一个序号的binlogN+1
			停止mysqld                                  #每次重启也会创建下一个序号的binlog
			拷贝binlog到远处
			mysqld --log-bin[=安全媒介如raid/san目录,不同于普通的mysql数据目录]启动.
		主从之从还需要备份master.info relay-log.info
	恢复  repair table myisamchk -r
		全量
			sql级别 load data infile $inFileName replace 
			mysql < mysqldumpfullbackup.sql
		增量冷备份
			mysql < mysqldumpfullbackup.sql
			mysqlbinlog mysqld-bin.* | mysql         #正常bin日志,肯定可以恢复  也可以mysqlbinlog bin.1 bin.2 | mysql
			mysqlbinlog 崩溃raid目录下的mysqld-bin.* | mysql   #崩溃bin日志 尽可能恢复
	维护
		检查 check table $tableName; repair table $tableName;
		优化 optimize table $tableName;
		分析 analyze table $tableName;
备份和恢复之innodb   innochecksum
	不将表的内容保存到数据库目录中
	不需要加锁,可以在线备份
	备份
		全量备份
			mysqldump --single-transaction --flush-logs --delete-master-logs --all-databases > backup.sql 
				#--single-transaction使用一致性地读,并且保证mysqldump所看见的数据不会更改
				#--delete-master-logs  删除binlog 有可能从服务器还没有复制完,慎用
		增量备份
			mysql>flush logs;
	恢复
		全量
			mysql < mysqldumpfullbackup.sql
		增量
		    #查看binlog的保存位置
		    mysql>show binlog events;

			mysqlbinlog  --stop-date="2005-04-20 9:59:59"  -v mysqld-bin.1 | mysql
				--no-defaults
				--database=$dbName 
				--base64-output=decode-rows
				-o $skipNumber
				--server-id=$serverID
				-s --short-form              #只显示语句,不显示附加信息
				-R -h $host/$ip -p           #获取远程服务器的
			mysqlbinlog --start-date="2005-04-20 10:01:00" mysqld-bin.1 | mysql

			mysqlbinlog --stop-position="368312" mysqld-bin.1 | mysql
			mysqlbinlog --start-position="368315" mysqld-bin.1 | mysql
	维护
		检查 check table $tableName; 
		优化 optimize table $tableName;
		分析 analyze table $tableName;


xtraBackup #https://www.percona.com/downloads/Percona-XtraBackup-LATEST/
	innobackupex --defaults-file=/data/mysql/mysql3307/my3307.cnf -S /tmp/mysql3307.sock -proot --stream=tar ./ | gzip -> `date +%F%H%M%S`.tar.gz
	mkdir 2019-03-26092718 && tar -zxvf 2019-03-26092718.tar.gz -C 2019-03-26092718/
	cd 2019-03-26092718/
	cat xtrabackup_binlog_info   # mysql-binlog.000181   12921798           ## mysql-binlog.000181 为备份到binlog文件名称，12921798 为备份到的position点
	innobackupex --apply-log ./
	innobackupex --defaults-file=/data/mysql/mysql3306/my3306.cnf --copy-back /root/2019-03-26092718/
	chown -R mysql:mysql /data/
	mysqld --defaults-file=/data/mysql/mysql3306/my3306.cnf &




实际情景模拟
    ANSI SQL标准涉及的场景 1读1写：
    ANSI SQL标准扩展涉及的场景 双写（丢失更新） 
并发可能导致的问题
    描述符号解释  R(read) W(write) 1(T1) 2(T2) X(record某条记录) P(predict谓词 包括范围的多条记录)  C(commit) A(abort/rollback)

    ANSISQL标准（ANSI sql isolation levels defined in terms of the three orignal phenomena),都是一个事务写,另一个事务读   一个事务的写导致了另外一个事务的读取错误
        P1.脏读       W1(X)…R2(X)…A1…R2(X)（A事务中对同一条数据，一次读取了B事务尚未提交的数据，且B事务回滚数据） 
        P2.不可重复读  R1(X)…W2(X)…C2…R1(X) (A事务中对同一条数据，两次读取的数据内容不一致，重点在update）
        P3.幻读       R1(P)…W2(P)…C2…R1(P)  (A事务中对同一范围内的，两次读取的数据量不一致，重点在insert，delete)
    ANSI标准扩展,双写(lost update)
        丢失数据修改 （修改的数据被其它线程事务覆盖）
            P0回滚覆盖  第二类丢失更新   脏写  W1(X)…W2(X)…A1
            P4提交覆盖  第一类丢失更新         R1(X)…R2(X)…W2(X)…C2…W1(X)…C1

解决并发问题的工具
    锁
        悲观乐观 是一种上锁的思想
            乐观(Optimistic Lock) 一开始不加锁    不能避免脏读   适用于读多写少
                时间戳Basic Time Ordering，把Basic Time Ordering达到的隔离级别称为Snapshot级别。
                    事务T1开始时，先申请一个时间戳，记做Start-Timestamp
                    事务T1的读不会阻塞，因为，它会读其Start-Timestamp之前的版本，其他事务在Start-Timestamp之后的修改，对该事务是不可见的
                    事务T1本身的修改，包括更新，插入和删除，都会保存在事务的上下文中，方便事务本身重复读取修改过的数据
                    当事务T1要提交时，它会获取一个Commit-Timestamp，此Commit-Timestamp要保证比现有的所有其他事务的Start-Timestmap和Commit-Timestmap要大，
                        如果存在其他事务Commit-Timestamp在事务T1的[Start-Timestamp, Commit-Timestamp]之内，且该事务修改了事务T1修改的数据，那么，事务T1会被终止，否则，事务提交
                MVCC  最大特点:  读不加锁，读写不冲突
                    快照读(snapshot read) 读取的是可见版本(有可能是历史版本)，不用加锁
                        select
                    当前读(current read)  读取的是记录的最新版本，并且，当前读返回的记录，都会加上锁，保证其他事务不会再并发修改这条记录。
                        select in share mode;
                        select for update;
                        insert/delete/update;  #先找到记录，然后在记录上加锁
            悲观(Pessimistic Lock) 一开始就加锁 传统的加锁控制  适用于读少写多  基于锁的并发控制Lock-Based Concurrent Control(LBCC)  封锁协议(Locking protocol)
                锁的兼容性 lock_mode
                    /* Basic lock modes */
                    enum lock_mode {
                        LOCK_IS = 0,   /* intension shared */
                        LOCK_IX,       /* intension exclusive */
                        LOCK_S,        /* shared */
                        LOCK_X,        /* exclusive */
                        LOCK_AUTO_INC, /* locks the auto-inc counter of a table in an exclusive mode*/
                    }
                    
                    行级读写锁
                        为提高读的并发性
                        (这里的读是当前读，而不是快照读，快照读是无需加锁的，记录上无论有没有锁，都可以快照读)

                    表级读写锁
                    表级意向共享锁(IS) 表级意向排他锁(IX)
                        只会应用在表锁上，方便表锁与行锁之间的冲突检测。
                    表级自增锁(AI一般见不到，只有在 innodb_autoinc_lock_mode = 0 或者 Bulk inserts 时才可能有）
                        是一种特殊的表锁
                        
                        不遵循2段锁协议，也就是说并不是事务结束时释放，而是在insert执行时释放，这样提高并发性。
                        一旦分配就会自增1，如果回滚，自增值也不会减回去，所以自增值可能出现中断。
                        innodb_autoinc_lock_mode
                            ==0时  5.1.22版本之前 表锁实现 select max(auto_inc_col) from t for update;
                            ==1时  默认值
                                对于simple insert，即插入前就可以知道需要插入的行数的语句,
                                    如insert,replace,不包括insert...on duplacte key update
                                    使用mutex
                                对于bulk insert,即插入前不可知会插入的行数，
                                    如insert...select, replace...select, load data
                                    使用传统的表锁auto-inc locking，
                                    优点： 如果不考虑回滚，值的增长还是连续的；基于statementReplication可以很好工作。
                                对于mixed-mode来说，有一部分是确定的有一部分是不确定的
                                    如insert into t(c1,c2) values (1,'a'),(null,'b')
                                      insert...on duplicate key update
                            ==2时 完全使用mutex 性能最高
                                优点 性能最高
                                缺点
                                    因为并发插入的存在，每次插入时，自增长的值可能不是连续的
                                    基于statement-base replication会出现问题，当使用这个模式时，最好使用rowBaseReplication
                                    这样才能保证最大的并发性和replication数据的同步
                    DDL(alter create等) 隐式提交，不能回滚

                    更新锁(U update lock)  SQL Server 支持， mysql不支持
                        防止通常形式的死锁，两个拥有共享锁的事务要同时更新数据时，需要将共享锁升级为排他锁，
                        所以他们都需要X锁并且要等待对方释放s锁（x锁和其它事务的S锁不兼容），会发生死锁

                    锁升级(Lock Escalation) 是指将当前锁的粒度降低，减少锁的开销，但降低并发性。如页级升级为表级。
                        SQLServer表现为
                            由一条单独的sql语句在一个对象上持有的锁数量超过阈值(默认为5000)。如果是不同对象的话，则不会发生锁升级。
                            锁占有的内存资源超过了激活内存的40%，则也会发生锁升级。
                        innodb/oracle
                            不存在锁升级

                    ps:先加表级别意向锁，再加行级别行锁。 如获取意向锁失败，则不能再往下加行锁。
                       意向锁之间是完全兼容的。因为意向锁只代表想往下获取锁，但具体是哪些记录是不确定的，因此完全兼容。
                       即使其他事务已经加了某种意向锁，事务还是可以成功加意向锁。

                锁的范围粒度 lock_type   
                    行锁  都是加在索引上的，最终会落在聚簇索引，加锁的过程是一条一条加的  根据锁住的对象
                        #define LOCK_ROW 32
                        普通锁：读写记录锁(S X)
                            #define LOCK_REC_NOT_GAP 1024
                        谓词锁: 避免幻读
                            间隙锁(GapLock) (S X)
                                #define LOCK_GAP 512
                                记录锁只能对已经存在的记录并发控制(update/delete),不能对要插入的记录控制(insert),所以需要间隙锁(GapLock)
                                GapLock不锁住任何记录,锁住的是不占任何实体的左开右开区间(previousKey,thisKey)，或加在第一条索引之前，或最后一条索引之后。
                                间隙锁和间隙锁之间是互不冲突的，间隙锁唯一的作用就是为了防止其他事务的插入，所以加间隙 S 锁和加间隙 X 锁没有任何区别。
                                一事务为了防止插入，获取了某条记录的间隙锁；
                                另一事务，为了插入，需要获取插入意向锁(insert intension lock),如果需要插入的间隙有间隙锁，则获取插入意向锁会失败必须进行锁等待，从而实现了阻塞插入.
                            后码锁Next-key Lock = GapLock+RecordLock (S X)
                                #define LOCK_ORDINARY 0
                                更新非唯一索引对应的记录会加上这个锁
                                假如表主键为10,11,20, 则（-∞,10] (10,11] (11,20]是nextkeyLock (20,+∞)是gapLock   （Infimum-∞ Supremum+∞） 
                             插入意向锁(insert intension lock)  插入记录时使用，是LOCK_GAP的特例， 有时可以简称II GAP
                                #define LOCK_INSERT_INTENSION 2048
                                同一gap不同的tx中可以同时插入互不冲突的不同索引的记录
                    表锁(实际实现为意向锁intension lock)
                        #define LOCK_TABLE 16
                        读写锁(S X)
                        读写意向锁(IS IX)
                        自增锁(AI)
                    
                锁的持续时间
                    临时锁(short duration):  没有持续到事务结束
                    持续锁(long duration):   持续到事务结束(commit或rollback)


                锁的2阶段
                    two-phase read(write)是当有一个或多个read(write) lock被释放后，不能再加新的read(write) lock。如果一个事务在释放一个或多个锁后，不再加其他的锁，那么称该事务是two-phase的
                    一句话： 在一个事务中，加锁阶段和解锁阶段是互不交叉互不重叠的。
                    Expanding phase：加锁阶段，此阶段只加锁，不释放锁
                    Shrinking phase：解锁阶段，此阶段只解锁，不加锁

                    经典的死锁的案例， 互相持有对方的资源
                        T1       T2
                        R1(X)   R2(Y)
                        W1(Y)   W2(X)
                        解决方案：
                            死锁检测并消除： 有一个单独的线程检测事务的锁等待图，如果图构成了一个环，那么，说明发生了死锁，此时，需要选择环中的一个事务进行回滚，并释放锁，使得其他事务能够继续运行下去
                            锁等待一段时间阈值后，对事务进行回滚，并释放所有锁： 表明，每次发生死锁时，都会先回滚最早开始执行的事务，使得其他的事务能够继续运行下去
                well-formed read(write)
                    是指在read(write)一个数据项或者查询条件时，会先对数据项或者查询条件加read(write) lock。如果一个事务的所有读写都是well-formed，那称事务是well-formed

                根据数据库的基础理论，采用well-formed two-phase locking方式调度事务的话，是能够保证serializability的


        
解决并发的途径：
    理论界，设置ANSI SQL标准下的事务隔离级别  主要是Read，没有涉及到写操作的隔离性，所以有所限制，需要工业界扩展
        P0脏写 
            表现形式: W1(X)…W2(X)…A1
            分析: 如果需要禁止P0，即禁止多个事务同时能修改一个数据项或谓词条件，则需要修改数据时，加写锁，并且是long duration的，此时，隔离级别满足Read Uncommitted。
            解决方案： 当写时，加long duration的写锁
            设置隔离级别：读未提交RU(read uncommit)
        P1脏读 也是读未提交  
            表现形式:  W1(X)…R2(X)…A1…R2(X)
            分析：如果需要禁止P1，即禁止读取到其他事务修改的中间状态的数据，在禁止P0的条件下，则需要，对读加锁，short duration的就能够满足条件，此时，隔离级别满足Read Committed
            设置隔离级别：读已提交RC(read commit)
            			 select lock in share mod; 
            			 select for update;
        P4
            表现形式： R1(X)…R2(X)…W2(X)…C2…W1(X)…C1
            分析：如果需要禁止P4，即禁止事务读取并且修改某个数据项后，需要禁止其他事务再次修改，但如果只是读取的话，不影响，这里，需要一种特殊的锁，称为Cursor Lock，会对事务当前处理的行进行加锁，
                 如果行记录被修改，那么锁会是long duration的，直到事务结束，如果，行未被修改，则锁会提前被释放，此时，隔离级别满足Curstor stability
            设置隔离级别：[Cursor Stability]
        P2不可重复读        
            表现形式： R1(X)…W2(X)…C2…R1(X)
            分析： 如果需要禁止P2，即要禁止到读到某个数据项后，该数据还可能被其他事务修改，因此，需要对读加锁，且一直加锁到事务结束，即long duration，此时，隔离级别满足Repeatable Read
            设置隔离级别：可重复读RR(read repeated) [Snapshot]
                         select lock in share mod; 
            			 select for update;
            			 next-key lock;
        P3幻读 
            表现形式： R1(P)…W2(P)…C2…R1(P)            
            分析： 如果需要禁止P3，即要禁止读到某个谓词条件后，满足该谓词条件的数据还被其他事务修改，因此，需要对谓词条件加读锁，且是long duration的，此时，隔离级别满足SERIALIZABLE
            设置隔离级别: 串行化  
            	所有的select 转化成 select lock in share mod,一致性的非锁定读不再支持;
                指的是并发调度执行的结果等于这些事务某个串行执行的结果。
                主要用于innodb的分布式事务。
                例如，有三个并发执行的事务T1，T2和T3，如果其执行结果和其某个串行执行((T1,T2,T3),(T1,T3,T2),(T2,T1,T3),(T2,T3,T1),(T3,T1,T2),(T3,T2,T1))的结果相同

    工业界



        （1）读未提交(RU) 脏读(dirty read 读取未提交的update)：事务写阻塞其它事务的写不阻塞读（加“持续-X锁”实现）
          ---避免丢失数据修改
        （2）读已提交(RC) 不可重复读(unrepeated read/ fuzzy read 读取未提交之前的update和读取update已提交的 这2次读取获得的数据不一致)：事务写会阻塞其它事务的读和写（写操作加“持续-X”锁，读操作加“临时-S锁”实现）
         ---避免丢失数据修改和脏读
        （3）可重复读(RR)：事务读会阻塞其它事务的写，不会阻塞读，事务写会阻塞其它事务读写（写操作加“持续-X”锁，读操作加“持续-S锁”实现）    
         ---避免丢失数据修改和脏读和不可重复读和幻读(phantom read)
         不可重复读： 是读重一条记录在update之前和update之后
         幻读：      是读取某一范围内的在insert/delte前后的差别
        （4）串行化：事务的最高级别，在每个读的数据行上，加上锁，使之不可能相互冲突，因此，会导致大量的超时现象
         ---解决了所有问题
        锁就保证了数据操作的串行化，但大大降低了事务的并发能力
    三级加锁协议
        一级加锁协议：读数据不加锁，修改数据前加X锁（解决丢失数据修改）
        二级加锁协议：读取时加s锁，修改时加x锁（解决丢失数据修改+脏读）
        三级加锁协议：全程加x锁和s锁（解决所有问题）


表级锁兼容矩阵
     IS  IX  S  X  AI   
IS   Y   Y   Y     Y
IX   Y   Y         Y
S    Y       Y
X
AI   Y   Y
    意向锁之间互不冲突；
    S 锁只和 S/IS 锁兼容，和其他锁都冲突；
    X 锁和其他所有锁都冲突；
    AI 锁只和意向锁兼容；
row锁兼容矩阵
             record    gap     next-key   II gap (已有的锁)
Record                 Y                  Y
Gap          Y         Y       Y          Y
next-key               Y                  Y
II GAP       Y                            Y
(想加的锁)
    一个事务已经获取了插入意向锁，对其他事务是没有任何影响的
    一个事务想要获取插入意向锁，如果有其他事务已经加了间隙锁或 Next-key 锁，则会阻塞




             隔离级别    回滚覆盖    脏读    不可重复读     提交覆盖     幻读
一级封锁协议  读未提交    Y           N      N             N           N
二级封锁协议  读已提交    Y           Y      N             N           N
三级封锁协议  可重复读    Y           Y      Y             ?           N
四级封锁协议  序列化      Y           Y      Y             Y           Y
             隔离级别越高，并发性越低

隔离级别的实现
    悲观的传统的基于锁的并发控制Lock-Based Concurrent Control(LBCC)  封锁协议(Locking protocol)
        读未提交：  事务读不阻塞其他事务读和写，事务写阻塞其他事务写但不阻塞读；通过对写操作加 “持续X锁”，对读操作不加锁 实现
        读已提交：  事务读不会阻塞其他事务读和写，事务写会阻塞其他事务读和写；通过对写操作加 “持续X锁”，对读操作加 “临时S锁” 实现；不会出现脏读
                   只加记录锁
        可重复读：  事务读会阻塞其他事务事务写但不阻塞读，事务写会阻塞其他事务读和写；通过对写操作加 “持续X锁”，对读操作加 “持续S锁” 实现
                   记录锁+间隙锁
        序列化：    为了解决幻读问题，行级锁做不到，需使用表级锁
    乐观的无锁的并发控制，如时间戳、MVCC,主要是MVCC


聚簇索引
    单条
        命中
        未命中
    范围查询
二级索引
    单条
        唯一索引
            命中
            未命中
        非唯一索引
            命中
            未命中
    范围查询
修改索引
无索引










hexdump -C -v a.exe
file $file #包括exe .so .a, 若最后显示with debug_info, not stripped; 若最后显示stripped则没有debug
gdb  $file #包括exe .so .a, 若最后显示Reading symbols from  done; 若最后显示Reading symbols from (no debugging symbols found) done

readelf -a $elf-file

nm 列出地址 类型type 符号symbol

objdump -a .exe
objdump -a .so
objdump -a .a   #查看包含了哪些文件

ldd  是一个shell脚本


devC++ 是由delphi开发的
setting——>code style——>Groovy——>Wrapping and baces——>field groups——>align in columns  按等号对齐
setting-->code style-->c++   -->code generation -> general -> line/block comment at first column 取消掉
cygwin  [cygnus天鹅 solution 公司]
mingw   [minimalist gnufor windows] 完全用windows api实现了posix接口
hyper-v


cat >> ~/.ssh/config << EOF
Host gitlab.com
    ProxyCommand=nc -X 5 -x 127.0.0.1:7778 %h %p
    HostName gitlab.com
    User git
EOF
git config --global core.compression=0

git clone --depth=1 git://github.com:example/awesome-project
git fetch --unshallow
git pull --all

https://www.avtb7788.com/56164/%E7%A4%BE%E4%BA%A4%E5%B9%B3%E5%8F%B0%E9%9D%9E%E5%B8%B8%E7%81%AB%E7%9A%84%E7%BD%91%E7%BA%A2%E9%9B%AA%E4%B9%B3%E6%AD%A3%E5%A6%B9%E7%B3%BB%E5%88%97%E6%9E%81%E5%93%81%E8%B6%85%E7%BA%A7%E5%B7%A8%E4%B9%B3%E8%9B%AE%E8%85%B0%E7%BF%98%E8%87%80%E7%99%BD%E8%99%8E%E5%AB%A9%E7%A9%B4%E5%8F%AB%E5%A3%B0%E5%8F%88%E7%94%9C%E4%B9%B3%E4%BA%A4%E6%89%93%E7%82%AE%E5%AE%85%E7%94%B7%E6%89%93%E9%A3%9E%E6%9C%BA%E7%A5%9E%E5%99%A8/
https://www.avtb2020.com/222445/%E9%9C%B2%E8%84%B8%E5%A4%A7%E5%A5%B6%E5%B0%91%E5%A6%87%E5%8F%A3%E6%9D%A1%E8%B6%85%E7%BA%A7%E5%8E%89%E5%AE%B3-%E6%AF%92%E9%BE%99-%E4%B9%B3%E4%BA%A4-%E5%8F%A3%E4%BA%A4-%E5%A5%B3%E4%B8%8A%E5%A4%B9%E6%A3%92%E7%8B%82%E6%8F%92-%E6%93%8D%E7%9A%84%E5%91%BB%E5%90%9F%E4%B8%8D%E6%96%AD/



激活码  https://www.41sh.cn/?id=101
EFM5ESULZQ-eyJsaWNlbnNlSWQiOiJFRk01RVNVTFpRIiwibGljZW5zZWVOYW1lIjoi5rC45LmF5r+A5rS7IGlkZWEubWVkZW1pbmcuY29tIiwiYXNzaWduZWVOYW1lIjoiIiwiYXNzaWduZWVFbWFpbCI6IiIsImxpY2Vuc2VSZXN0cmljdGlvbiI6IiIsImNoZWNrQ29uY3VycmVudFVzZSI6ZmFsc2UsInByb2R1Y3RzIjpbeyJjb2RlIjoiSUkiLCJwYWlkVXBUbyI6IjIwMjAtMDUtMjMifSx7ImNvZGUiOiJBQyIsInBhaWRVcFRvIjoiMjAyMC0wNS0yMyJ9LHsiY29kZSI6IkRQTiIsInBhaWRVcFRvIjoiMjAyMC0wNS0yMyJ9LHsiY29kZSI6IlJTQyIsInBhaWRVcFRvIjoiMjAyMC0wNS0yMyJ9LHsiY29kZSI6IlBTIiwicGFpZFVwVG8iOiIyMDIwLTA1LTIzIn0seyJjb2RlIjoiUlNGIiwicGFpZFVwVG8iOiIyMDIwLTA1LTIzIn0seyJjb2RlIjoiR08iLCJwYWlkVXBUbyI6IjIwMjAtMDUtMjMifSx7ImNvZGUiOiJETSIsInBhaWRVcFRvIjoiMjAyMC0wNS0yMyJ9LHsiY29kZSI6IkNMIiwicGFpZFVwVG8iOiIyMDIwLTA1LTIzIn0seyJjb2RlIjoiUlMwIiwicGFpZFVwVG8iOiIyMDIwLTA1LTIzIn0seyJjb2RlIjoiUkMiLCJwYWlkVXBUbyI6IjIwMjAtMDUtMjMifSx7ImNvZGUiOiJSRCIsInBhaWRVcFRvIjoiMjAyMC0wNS0yMyJ9LHsiY29kZSI6IlBDIiwicGFpZFVwVG8iOiIyMDIwLTA1LTIzIn0seyJjb2RlIjoiUlNWIiwicGFpZFVwVG8iOiIyMDIwLTA1LTIzIn0seyJjb2RlIjoiUlNVIiwicGFpZFVwVG8iOiIyMDIwLTA1LTIzIn0seyJjb2RlIjoiUk0iLCJwYWlkVXBUbyI6IjIwMjAtMDUtMjMifSx7ImNvZGUiOiJXUyIsInBhaWRVcFRvIjoiMjAyMC0wNS0yMyJ9LHsiY29kZSI6IkRCIiwicGFpZFVwVG8iOiIyMDIwLTA1LTIzIn0seyJjb2RlIjoiREMiLCJwYWlkVXBUbyI6IjIwMjAtMDUtMjMifSx7ImNvZGUiOiJQREIiLCJwYWlkVXBUbyI6IjIwMjAtMDUtMjMifSx7ImNvZGUiOiJQV1MiLCJwYWlkVXBUbyI6IjIwMjAtMDUtMjMifSx7ImNvZGUiOiJQR08iLCJwYWlkVXBUbyI6IjIwMjAtMDUtMjMifSx7ImNvZGUiOiJQUFMiLCJwYWlkVXBUbyI6IjIwMjAtMDUtMjMifSx7ImNvZGUiOiJQUEMiLCJwYWlkVXBUbyI6IjIwMjAtMDUtMjMifSx7ImNvZGUiOiJQUkIiLCJwYWlkVXBUbyI6IjIwMjAtMDUtMjMifSx7ImNvZGUiOiJQU1ciLCJwYWlkVXBUbyI6IjIwMjAtMDUtMjMifSx7ImNvZGUiOiJEUCIsInBhaWRVcFRvIjoiMjAyMC0wNS0yMyJ9LHsiY29kZSI6IlJTIiwicGFpZFVwVG8iOiIyMDIwLTA1LTIzIn0seyJjb2RlIjoiRFBBIiwicGFpZFVwVG8iOiIyMDIwLTA1LTIzIn1dLCJoYXNoIjoiMTc3NTkzMDEvMDotNDMzNDA1NjEyIiwiZ3JhY2VQZXJpb2REYXlzIjo3LCJhdXRvUHJvbG9uZ2F0ZWQiOmZhbHNlLCJpc0F1dG9Qcm9sb25nYXRlZCI6ZmFsc2V9-Tf3EaEW1arDVVf71Vl+rA6dVg2yABCNU7wxllAOhB8QwkYYIpMyTxcoOc4lwPO4eutY0JZ1QR9yNu4WM5UciZ4Sob69LSN8FYFQ2IM5OyRARgxgvYbxOXEUqsofmOL0qNMpiAKWeX1PR+kPqV71p22jWpVQoVgvobCI/Un9UQjfM63nEcEC7PQQEjB15Zcz00vP1ycT7KSpNtS/q7j1P69A6o4reTuvlbxzvaxWvbRV6ofCyRDhvNa0mi3JLTz8vQA0WXd/2+N0yEOCuJMZJgWb8rusTt3wQrnGTvmiQZqlGEWeuik7YkdXmlJwxFak9ewgvGIylivlEpRdxBzUoKw==-MIIElTCCAn2gAwIBAgIBCTANBgkqhkiG9w0BAQsFADAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBMB4XDTE4MTEwMTEyMjk0NloXDTIwMTEwMjEyMjk0NlowaDELMAkGA1UEBhMCQ1oxDjAMBgNVBAgMBU51c2xlMQ8wDQYDVQQHDAZQcmFndWUxGTAXBgNVBAoMEEpldEJyYWlucyBzLnIuby4xHTAbBgNVBAMMFHByb2QzeS1mcm9tLTIwMTgxMTAxMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAxcQkq+zdxlR2mmRYBPzGbUNdMN6OaXiXzxIWtMEkrJMO/5oUfQJbLLuMSMK0QHFmaI37WShyxZcfRCidwXjot4zmNBKnlyHodDij/78TmVqFl8nOeD5+07B8VEaIu7c3E1N+e1doC6wht4I4+IEmtsPAdoaj5WCQVQbrI8KeT8M9VcBIWX7fD0fhexfg3ZRt0xqwMcXGNp3DdJHiO0rCdU+Itv7EmtnSVq9jBG1usMSFvMowR25mju2JcPFp1+I4ZI+FqgR8gyG8oiNDyNEoAbsR3lOpI7grUYSvkB/xVy/VoklPCK2h0f0GJxFjnye8NT1PAywoyl7RmiAVRE/EKwIDAQABo4GZMIGWMAkGA1UdEwQCMAAwHQYDVR0OBBYEFGEpG9oZGcfLMGNBkY7SgHiMGgTcMEgGA1UdIwRBMD+AFKOetkhnQhI2Qb1t4Lm0oFKLl/GzoRykGjAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBggkA0myxg7KDeeEwEwYDVR0lBAwwCgYIKwYBBQUHAwEwCwYDVR0PBAQDAgWgMA0GCSqGSIb3DQEBCwUAA4ICAQAF8uc+YJOHHwOFcPzmbjcxNDuGoOUIP+2h1R75Lecswb7ru2LWWSUMtXVKQzChLNPn/72W0k+oI056tgiwuG7M49LXp4zQVlQnFmWU1wwGvVhq5R63Rpjx1zjGUhcXgayu7+9zMUW596Lbomsg8qVve6euqsrFicYkIIuUu4zYPndJwfe0YkS5nY72SHnNdbPhEnN8wcB2Kz+OIG0lih3yz5EqFhld03bGp222ZQCIghCTVL6QBNadGsiN/lWLl4JdR3lJkZzlpFdiHijoVRdWeSWqM4y0t23c92HXKrgppoSV18XMxrWVdoSM3nuMHwxGhFyde05OdDtLpCv+jlWf5REAHHA201pAU6bJSZINyHDUTB+Beo28rRXSwSh3OUIvYwKNVeoBY+KwOJ7WnuTCUq1meE6GkKc4D/cXmgpOyW/1SmBz3XjVIi/zprZ0zf3qH5mkphtg6ksjKgKjmx1cXfZAAX6wcDBNaCL+Ortep1Dh8xDUbqbBVNBL4jbiL3i3xsfNiyJgaZ5sX7i8tmStEpLbPwvHcByuf59qJhV/bZOl8KqJBETCDJcY6O2aqhTUy+9x93ThKs1GKrRPePrWPluud7ttlgtRveit/pcBrnQcXOl1rHq7ByB8CFAxNotRUYL9IF5n3wJOgkPojMy6jetQA5Ogc8Sm7RG6vg1yow==

LFYIPH70PI-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-WxhtYAWNy0b/BAVgnd9lkga0QS4Idmi58G4IcxrydvMH90Q9uKptYu6mm3iU+bCqpfIZy8foEMqQNdYky18lcwDg9ghaJEG/Ly4ZgkQFpuGsG2cwT3toImpki+FyFhAM97j6IpmP4i0yCcLR1rGd5xNKWxVulITxKde/aTCF+tDhiUP3C70GsgoI3Q4HqLvloPC0XjmcPf3lgk/IXrjcH5MoHeq4lcI3SI8hND3aBNh9q/UPyXv65vH7qs93icpR/E7R/AH2ebj5Vjfa3HTIOLvEepQBxqLB53P4W1evsiN+svg5OAzAn6vWDTKj7klIO9KTKw0brGdeae0XCs2PQw==-MIIElTCCAn2gAwIBAgIBCTANBgkqhkiG9w0BAQsFADAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBMB4XDTE4MTEwMTEyMjk0NloXDTIwMTEwMjEyMjk0NlowaDELMAkGA1UEBhMCQ1oxDjAMBgNVBAgMBU51c2xlMQ8wDQYDVQQHDAZQcmFndWUxGTAXBgNVBAoMEEpldEJyYWlucyBzLnIuby4xHTAbBgNVBAMMFHByb2QzeS1mcm9tLTIwMTgxMTAxMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAxcQkq+zdxlR2mmRYBPzGbUNdMN6OaXiXzxIWtMEkrJMO/5oUfQJbLLuMSMK0QHFmaI37WShyxZcfRCidwXjot4zmNBKnlyHodDij/78TmVqFl8nOeD5+07B8VEaIu7c3E1N+e1doC6wht4I4+IEmtsPAdoaj5WCQVQbrI8KeT8M9VcBIWX7fD0fhexfg3ZRt0xqwMcXGNp3DdJHiO0rCdU+Itv7EmtnSVq9jBG1usMSFvMowR25mju2JcPFp1+I4ZI+FqgR8gyG8oiNDyNEoAbsR3lOpI7grUYSvkB/xVy/VoklPCK2h0f0GJxFjnye8NT1PAywoyl7RmiAVRE/EKwIDAQABo4GZMIGWMAkGA1UdEwQCMAAwHQYDVR0OBBYEFGEpG9oZGcfLMGNBkY7SgHiMGgTcMEgGA1UdIwRBMD+AFKOetkhnQhI2Qb1t4Lm0oFKLl/GzoRykGjAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBggkA0myxg7KDeeEwEwYDVR0lBAwwCgYIKwYBBQUHAwEwCwYDVR0PBAQDAgWgMA0GCSqGSIb3DQEBCwUAA4ICAQAF8uc+YJOHHwOFcPzmbjcxNDuGoOUIP+2h1R75Lecswb7ru2LWWSUMtXVKQzChLNPn/72W0k+oI056tgiwuG7M49LXp4zQVlQnFmWU1wwGvVhq5R63Rpjx1zjGUhcXgayu7+9zMUW596Lbomsg8qVve6euqsrFicYkIIuUu4zYPndJwfe0YkS5nY72SHnNdbPhEnN8wcB2Kz+OIG0lih3yz5EqFhld03bGp222ZQCIghCTVL6QBNadGsiN/lWLl4JdR3lJkZzlpFdiHijoVRdWeSWqM4y0t23c92HXKrgppoSV18XMxrWVdoSM3nuMHwxGhFyde05OdDtLpCv+jlWf5REAHHA201pAU6bJSZINyHDUTB+Beo28rRXSwSh3OUIvYwKNVeoBY+KwOJ7WnuTCUq1meE6GkKc4D/cXmgpOyW/1SmBz3XjVIi/zprZ0zf3qH5mkphtg6ksjKgKjmx1cXfZAAX6wcDBNaCL+Ortep1Dh8xDUbqbBVNBL4jbiL3i3xsfNiyJgaZ5sX7i8tmStEpLbPwvHcByuf59qJhV/bZOl8KqJBETCDJcY6O2aqhTUy+9x93ThKs1GKrRPePrWPluud7ttlgtRveit/pcBrnQcXOl1rHq7ByB8CFAxNotRUYL9IF5n3wJOgkPojMy6jetQA5Ogc8Sm7RG6vg1yow==



cppreference.com
cplusplus.com
learncpp.com
tutorialspoint.com
https://github.com/fffaraz/awesome-cpp



assert.hpp  资产
struct assert {
    int64_t amount;
    symbol  symbol;
}

symbol.hpp  货币单位
struct symbol_code {
    uint64_t value;
}
struct symbol {
    uint64_t value;  
    uint64_t raw() {return value;}
    uint64_t code() {return value >> 8;}
    uint8_t  precision() { return value &0xFFull;}
}

name 账户
struct name{
    uint64_t value = 0;
}

https://blog.csdn.net/hhye_l/article/details/80602196
https://www.cnblogs.com/Evsward/p/multi_index.html
https://segmentfault.com/a/1190000016088076
http://sns.hwcrazy.com/boost_1_41_0/libs/multi_index/doc/tutorial/key_extraction.html
multi_index
    typedef eosio::multi_index<$tabName, $typeName,
        indexed_by<$indexName, const_mem_func<$typeName, $retType, $funcName> > > table(code, scope)
        // indexName 最多13个字符 12(a-z 1-5 .) 13(a-p .)

    构造函数  (code, scope)
        不支持拷贝构造函数  不支持赋值构造函数
    成员访问
             uint64_t get_code() const
             uint64_t get_scope() const
    工具函数
        uint64_t available_primary_key() const  返回一个可用的未使用的主键值， 用于主键严格自增的表 它不会被设置为自定义值
    迭代器
        begin() cbegin()  rbegin() crbegin()
        end()   cend()    rend()   crend()
        const_it = mi.lower_bound(pk)
        const_it = mi.upper_bound(pk)

        const_it iterator_to(const obj&) const   #返回给定对象的迭代器
        second_index get_index<indeName>() const #返回一个适当类型的二级索引
    创建     
        const_it = mi.emplace(owner, [&](auto& rec){})  需要marshall
    删除     
        const_it = mi.erase(it)                         退还由于存储而产生的费用
        void       mi.erase(const ob&)
    查找     
        const_it   = mi.find(pk)     若未找到返回end()迭代器
        const_it   = mi.require(pk)  若未找到则抛出异常
        const_obj& = mi.get(pk)      若未找到则抛出异常
    修改     
        void mi.modify(const_it, uint64_t payer,[&](auto& updater){})   需要marshall
        void mi.modify(obj&, uint64_t payer,[&](auto& updater){})       需要marshall
            payer:  为更新而付费的账户  当更新账户和创建账户相同时可以为0
            如果payer与该对象的payer，则需要退还费用给现有的payer
            如果payer与该对象的payer，只需为现有对象和更新对象的不同部分付费。如果差额为负，则退还费用



win7/10 ctrl-alt--> 旋转   在任务栏找到显卡 右击属性 快捷键 -> 禁用

windows7的允许远程桌面连接
服务
    我的电脑   管理   服务与应用程序 服务 RemoteDesktopService
允许远程连接
    我的电脑   属性   远程选项卡  允许运行任意版本的远程桌面的计算机连接
防火墙 
    控制面板 系统安全  防火墙  允许程序或功能通过防火墙  远程桌面RemoteFX


https://lexiangla.com/docs/b20524eefa4f11e9a6b10a58ac131389?company_from=c1ee04f4854f11e9ae505254002f1020


go build [-o output] [-i] [build flags] [pkgs]
    build flags
        -gcflags='' -ldflags=''
        #gcflags是传递给go compiler的参数，可以使用 go tool compile --help查看所有参数
        #    -m 检查代码的优化情况， 包括逃逸情况和函数是否内联
        #    如过只在编译特定包时传递参数，格式应该遵守"$pkgName=参数列表" go build -gcflags='log=-N -l' main.go
        #ldflags是传递给go linker的参数，可以使用go tool link --help查看所有参数
        #    -X用来指定特定版本才编译 例如代码中定义var buildVer string，然后在编译时用go build -ldflags "-X main.buildVer=1.0" ... 来赋值。注意-X只能给string类型变量赋值
    pkgs
        默认为当前目录，可以省略。  如果提供想对，则是相对于GOROOT GOPATH环境变量
        go build mydir      #只编译mydir这个包
        go build mydir/...  #...代表所有字符串 所以编译mydir下的所有pkg



/*
        ipfs--
            bin
                ipfs -> ipfs-Linux-x86_64-v2.3.5-20200418170759-51328808-2f200cec806226bd9f7625fdc5995e5c
                ipfs-Linux-x86_64-v2.3.5-20200418170759-51328808-2f200cec806226bd9f7625fdc5995e5c
                conf.ext-$size-$md5
                swarm.key-$size-$md5
            data
                conf.done
                conf
                swarm.key
    */
   



https://blog.51cto.com/arthur376/2114026
https://blog.51cto.com/arthur376/1772177
https://blog.51cto.com/arthur376/1792551

http://blog.itpub.net/23718752/viewspace-2134001/
https://blog.csdn.net/hzsunshine/article/details/69132225
https://blog.csdn.net/d6619309/article/details/53691352
https://www.cnblogs.com/maoyanqing/p/11724696.html
https://www.cnblogs.com/monkeybron/p/9597818.html
https://cloud.tencent.com/developer/article/1501860



https://blog.51cto.com/14089205/2477697?source=drh
https://blog.51cto.com/14089205/2477055                 不错

https://blog.51cto.com/14089205/2476323                 redis集群

 


<div style="background-color:#C7EDCC">
document.querySelector('body').style = 'background: #C7EDCC;'


Greenplum










python3 -m http.server     8000
python -m SimpleHTTPServer 8000


gops
go-ps

https://www.cnblogs.com/zhoujinyi/p/6477133.html